INFO 2025-05-06 12:06:40,682 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-05-06 12:06:40,691 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-06 12:06:40,691 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_14132_JVCNYIYEOHPZTTWN
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_13508_1262719628=1
EFC_13508_1592913036=1
EFC_13508_2775293581=1
EFC_13508_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=1316
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=41644
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\17baf841131aa23349f217ca7c570c76ee87b957
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.99.3-main-sock
VSCODE_L10N_BUNDLE_LOCATION=
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=14132
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-06 12:06:40,692 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:06:40,694 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_unchangedConfig/tensorboard
INFO 2025-05-06 12:06:42,145 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-06 12:06:42,150 trainer.py:1059: ====================
INFO 2025-05-06 12:06:42,150 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-06 12:06:42,153 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-06 12:06:42,154 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-06 12:06:42,154 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-06 12:06:42,154 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-06 12:06:42,154 trainer.py:1069: ====================
INFO 2025-05-06 12:06:42,159 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:06:42,160 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:06:42,786 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:06:42,809 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias'}
INFO 2025-05-06 12:06:42,811 optimizer.py: 248: Matches for param_name [*bias*]: {'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.1.linear2.bias', 'mask_downsample.bias', 'image_encoder.neck.convs.1.conv.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'memory_attention.layers.2.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'memory_attention.layers.1.linear1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'memory_attention.layers.3.linear1.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.norm.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias'}
INFO 2025-05-06 12:06:42,812 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'memory_attention.layers.2.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'memory_attention.norm.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.0.norm3.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.3.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.norm.bias', 'memory_attention.layers.3.norm1.weight', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.bias'} 
INFO 2025-05-06 12:06:44,844 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-06 12:07:30,326 train_utils.py: 108: MACHINE SEED: 4920
INFO 2025-05-06 12:07:30,334 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-06 12:07:30,334 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_14132_JVCNYIYEOHPZTTWN
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_13508_1262719628=1
EFC_13508_1592913036=1
EFC_13508_2775293581=1
EFC_13508_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=1316
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=25590
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\17baf841131aa23349f217ca7c570c76ee87b957
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.99.3-main-sock
VSCODE_L10N_BUNDLE_LOCATION=
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=14132
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-06 12:07:30,334 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:07:30,336 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_unchangedConfig/tensorboard
INFO 2025-05-06 12:07:31,221 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-06 12:07:31,226 trainer.py:1059: ====================
INFO 2025-05-06 12:07:31,226 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-06 12:07:31,231 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-06 12:07:31,232 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-06 12:07:31,232 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-06 12:07:31,232 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-06 12:07:31,232 trainer.py:1069: ====================
INFO 2025-05-06 12:07:31,238 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:07:31,238 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:07:31,425 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:07:31,452 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias'}
INFO 2025-05-06 12:07:31,454 optimizer.py: 248: Matches for param_name [*bias*]: {'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'memory_attention.layers.0.norm2.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'memory_attention.layers.2.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'memory_attention.layers.1.linear1.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'memory_encoder.pix_feat_proj.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.1.linear2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'obj_ptr_tpos_proj.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'memory_attention.norm.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.neck.convs.1.conv.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'sam_mask_decoder.conv_s1.bias', 'memory_attention.layers.0.linear1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'memory_attention.layers.0.norm1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'memory_attention.layers.2.linear1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'memory_attention.layers.2.linear2.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias'}
INFO 2025-05-06 12:07:31,455 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'memory_attention.layers.2.norm3.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'memory_attention.layers.2.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'memory_attention.layers.3.norm3.weight', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'memory_attention.norm.weight', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.weight'} 
INFO 2025-05-06 12:07:33,291 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-06 12:07:33,547 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': '../checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
ERROR 2025-05-06 12:07:50,889 sam2_datasets.py:  63: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\sam2\training\dataset\utils.py", line 104, in __getitem__
    return self.dataset[self.epoch_ids[idx]]
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Lib\site-packages\torch\utils\data\dataset.py", line 346, in __getitem__
    return self.datasets[dataset_idx][sample_idx]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\sam2\training\dataset\vos_dataset.py", line 132, in __getitem__
    return self._get_datapoint(idx)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\sam2\training\dataset\vos_dataset.py", line 74, in _get_datapoint
    datapoint = self.construct(video, sampled_frms_and_objs, segment_loader)
                               ^^^^^
UnboundLocalError: cannot access local variable 'sampled_frms_and_objs' where it is not associated with a value

INFO 2025-05-06 12:10:49,389 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-05-06 12:10:49,398 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-06 12:10:49,398 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_14132_JVCNYIYEOHPZTTWN
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_13508_1262719628=1
EFC_13508_1592913036=1
EFC_13508_2775293581=1
EFC_13508_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=1316
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=21781
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\17baf841131aa23349f217ca7c570c76ee87b957
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.99.3-main-sock
VSCODE_L10N_BUNDLE_LOCATION=
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=14132
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-06 12:10:49,398 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:10:49,399 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_unchangedConfig/tensorboard
INFO 2025-05-06 12:10:50,324 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-06 12:10:50,328 trainer.py:1059: ====================
INFO 2025-05-06 12:10:50,329 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-06 12:10:50,332 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-06 12:10:50,332 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-06 12:10:50,333 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-06 12:10:50,333 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-06 12:10:50,333 trainer.py:1069: ====================
INFO 2025-05-06 12:10:50,339 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-06 12:10:50,339 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:10:50,453 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-06 12:10:50,478 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.weight'}
INFO 2025-05-06 12:10:50,480 optimizer.py: 248: Matches for param_name [*bias*]: {'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'memory_attention.layers.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'memory_attention.layers.3.norm2.bias', 'memory_attention.layers.0.linear2.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.2.linear2.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'memory_attention.layers.1.norm2.bias', 'mask_downsample.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'obj_ptr_tpos_proj.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.2.linear1.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.neck.convs.1.conv.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'memory_attention.norm.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'sam_mask_decoder.conv_s1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'memory_encoder.out_proj.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.3.norm3.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'obj_ptr_proj.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias'}
INFO 2025-05-06 12:10:50,481 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_attention.layers.3.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.2.norm2.weight', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.norm.bias', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.3.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'memory_attention.layers.2.norm3.weight', 'memory_attention.layers.1.norm1.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.weight'} 
INFO 2025-05-06 12:10:52,322 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-06 12:10:52,583 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': '../checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-05-06 12:11:17,678 train_utils.py: 271: Train Epoch: [0][ 0/40] | Batch Time: 24.82 (24.82) | Data Time: 11.46 (11.46) | Mem (GB): 6.00 (6.00/6.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.00e+01 (1.00e+01)
INFO 2025-05-06 12:11:38,554 train_utils.py: 271: Train Epoch: [0][10/40] | Batch Time: 1.04 (4.15) | Data Time: 0.00 (1.05) | Mem (GB): 7.00 (6.91/7.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.22e+01 (1.58e+01)
INFO 2025-05-06 12:11:47,125 train_utils.py: 271: Train Epoch: [0][20/40] | Batch Time: 0.83 (2.58) | Data Time: 0.00 (0.55) | Mem (GB): 7.00 (6.95/7.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.14e+01 (1.31e+01)
INFO 2025-05-06 12:11:55,697 train_utils.py: 271: Train Epoch: [0][30/40] | Batch Time: 0.97 (2.03) | Data Time: 0.00 (0.37) | Mem (GB): 7.00 (6.97/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 5.64e+00 (1.18e+01)
INFO 2025-05-06 12:12:05,492 trainer.py: 950: Estimated time remaining: 00d 00h 57m
INFO 2025-05-06 12:12:05,495 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:12:05,496 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 11.070118975639343, 'Losses/train_all_loss_mask': 0.13159860795130954, 'Losses/train_all_loss_dice': 7.463248503208161, 'Losses/train_all_loss_iou': 0.9748869808390737, 'Losses/train_all_loss_class': 1.1642162432234926e-05, 'Losses/train_all_core_loss': 11.070118975639343, 'Trainer/where': 0.0195, 'Trainer/epoch': 0, 'Trainer/steps_train': 40}
INFO 2025-05-06 12:12:27,156 train_utils.py: 271: Train Epoch: [1][ 0/40] | Batch Time: 17.84 (17.84) | Data Time: 16.70 (16.70) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 8.31e+00 (8.31e+00)
INFO 2025-05-06 12:12:35,034 train_utils.py: 271: Train Epoch: [1][10/40] | Batch Time: 0.72 (2.34) | Data Time: 0.00 (1.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.33e+01 (9.51e+00)
INFO 2025-05-06 12:12:42,737 train_utils.py: 271: Train Epoch: [1][20/40] | Batch Time: 0.77 (1.59) | Data Time: 0.00 (0.80) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 8.91e+00 (8.89e+00)
INFO 2025-05-06 12:12:50,133 train_utils.py: 271: Train Epoch: [1][30/40] | Batch Time: 0.74 (1.32) | Data Time: 0.00 (0.54) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 9.55e+00 (8.74e+00)
INFO 2025-05-06 12:12:57,952 trainer.py: 950: Estimated time remaining: 00d 00h 37m
INFO 2025-05-06 12:12:57,952 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:12:57,953 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 8.726571822166443, 'Losses/train_all_loss_mask': 0.03861400107343797, 'Losses/train_all_loss_dice': 7.500398433208465, 'Losses/train_all_loss_iou': 0.4536822626949288, 'Losses/train_all_loss_class': 0.00021116981601470018, 'Losses/train_all_core_loss': 8.726571822166443, 'Trainer/where': 0.0395, 'Trainer/epoch': 1, 'Trainer/steps_train': 80}
INFO 2025-05-06 12:13:12,293 train_utils.py: 271: Train Epoch: [2][ 0/40] | Batch Time: 11.88 (11.88) | Data Time: 10.80 (10.80) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 7.93e+00 (7.93e+00)
INFO 2025-05-06 12:13:19,880 train_utils.py: 271: Train Epoch: [2][10/40] | Batch Time: 0.80 (1.77) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.09e+00 (8.64e+00)
INFO 2025-05-06 12:13:27,529 train_utils.py: 271: Train Epoch: [2][20/40] | Batch Time: 0.80 (1.29) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.06e+00 (8.61e+00)
INFO 2025-05-06 12:13:35,631 train_utils.py: 271: Train Epoch: [2][30/40] | Batch Time: 0.76 (1.14) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.76e+00 (8.35e+00)
INFO 2025-05-06 12:13:43,507 trainer.py: 950: Estimated time remaining: 00d 00h 32m
INFO 2025-05-06 12:13:43,508 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:13:43,508 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 8.32911719083786, 'Losses/train_all_loss_mask': 0.03439100562536623, 'Losses/train_all_loss_dice': 7.393140453100204, 'Losses/train_all_loss_iou': 0.24703905555070377, 'Losses/train_all_loss_class': 0.0011175910406848288, 'Losses/train_all_core_loss': 8.32911719083786, 'Trainer/where': 0.059500000000000004, 'Trainer/epoch': 2, 'Trainer/steps_train': 120}
INFO 2025-05-06 12:13:57,276 train_utils.py: 271: Train Epoch: [3][ 0/40] | Batch Time: 11.40 (11.40) | Data Time: 10.33 (10.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 7.41e+00 (7.41e+00)
INFO 2025-05-06 12:14:05,918 train_utils.py: 271: Train Epoch: [3][10/40] | Batch Time: 0.86 (1.82) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 8.26e+00 (7.76e+00)
INFO 2025-05-06 12:14:13,736 train_utils.py: 271: Train Epoch: [3][20/40] | Batch Time: 0.75 (1.33) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.14e+01 (7.69e+00)
INFO 2025-05-06 12:14:21,673 train_utils.py: 271: Train Epoch: [3][30/40] | Batch Time: 0.86 (1.15) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 7.94e+00 (7.94e+00)
INFO 2025-05-06 12:14:29,372 trainer.py: 950: Estimated time remaining: 00d 00h 32m
INFO 2025-05-06 12:14:29,372 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:14:29,372 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.9369899988174435, 'Losses/train_all_loss_mask': 0.021272483198481497, 'Losses/train_all_loss_dice': 7.447648394107818, 'Losses/train_all_loss_iou': 0.06381208094317117, 'Losses/train_all_loss_class': 7.987330211083332e-05, 'Losses/train_all_core_loss': 7.9369899988174435, 'Trainer/where': 0.0795, 'Trainer/epoch': 3, 'Trainer/steps_train': 160}
INFO 2025-05-06 12:14:43,688 train_utils.py: 271: Train Epoch: [4][ 0/40] | Batch Time: 11.32 (11.32) | Data Time: 10.08 (10.08) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.03e+01 (1.03e+01)
INFO 2025-05-06 12:14:51,967 train_utils.py: 271: Train Epoch: [4][10/40] | Batch Time: 0.79 (1.78) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.03e+00 (8.28e+00)
INFO 2025-05-06 12:14:59,650 train_utils.py: 271: Train Epoch: [4][20/40] | Batch Time: 0.75 (1.30) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.31e+00 (8.04e+00)
INFO 2025-05-06 12:15:07,297 train_utils.py: 271: Train Epoch: [4][30/40] | Batch Time: 0.79 (1.13) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.85e+00 (8.02e+00)
INFO 2025-05-06 12:15:15,205 trainer.py: 950: Estimated time remaining: 00d 00h 31m
INFO 2025-05-06 12:15:15,206 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:15:15,206 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.955873024463654, 'Losses/train_all_loss_mask': 0.027196310719591565, 'Losses/train_all_loss_dice': 7.3713669896125795, 'Losses/train_all_loss_iou': 0.040540499775670466, 'Losses/train_all_loss_class': 3.93597102458898e-05, 'Losses/train_all_core_loss': 7.955873024463654, 'Trainer/where': 0.09949999999999999, 'Trainer/epoch': 4, 'Trainer/steps_train': 200}
INFO 2025-05-06 12:15:28,331 train_utils.py: 271: Train Epoch: [5][ 0/40] | Batch Time: 11.28 (11.28) | Data Time: 10.35 (10.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 1.01e+01 (1.01e+01)
INFO 2025-05-06 12:15:35,535 train_utils.py: 271: Train Epoch: [5][10/40] | Batch Time: 0.71 (1.68) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 5.46e+00 (7.67e+00)
INFO 2025-05-06 12:15:42,783 train_utils.py: 271: Train Epoch: [5][20/40] | Batch Time: 0.75 (1.23) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.01e+00 (7.65e+00)
INFO 2025-05-06 12:15:50,092 train_utils.py: 271: Train Epoch: [5][30/40] | Batch Time: 0.73 (1.07) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 7.98e+00 (7.79e+00)
INFO 2025-05-06 12:15:57,481 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-05-06 12:15:57,481 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:15:57,481 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.713245296478272, 'Losses/train_all_loss_mask': 0.021138020500075072, 'Losses/train_all_loss_dice': 7.235592943429947, 'Losses/train_all_loss_iou': 0.054880560189121755, 'Losses/train_all_loss_class': 1.1419168161097559e-05, 'Losses/train_all_core_loss': 7.713245296478272, 'Trainer/where': 0.1195, 'Trainer/epoch': 5, 'Trainer/steps_train': 240}
INFO 2025-05-06 12:16:11,355 train_utils.py: 271: Train Epoch: [6][ 0/40] | Batch Time: 11.01 (11.01) | Data Time: 10.04 (10.04) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 6.68e+00 (6.68e+00)
INFO 2025-05-06 12:16:18,567 train_utils.py: 271: Train Epoch: [6][10/40] | Batch Time: 0.69 (1.66) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 8.09e+00 (7.35e+00)
INFO 2025-05-06 12:16:25,843 train_utils.py: 271: Train Epoch: [6][20/40] | Batch Time: 0.72 (1.21) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 4.56e+00 (7.25e+00)
INFO 2025-05-06 12:16:32,957 train_utils.py: 271: Train Epoch: [6][30/40] | Batch Time: 0.74 (1.05) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 8.83e+00 (7.41e+00)
INFO 2025-05-06 12:16:40,495 trainer.py: 950: Estimated time remaining: 00d 00h 28m
INFO 2025-05-06 12:16:40,496 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:16:40,496 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.426462268829345, 'Losses/train_all_loss_mask': 0.013435622929682723, 'Losses/train_all_loss_dice': 7.140339636802674, 'Losses/train_all_loss_iou': 0.017393272405388415, 'Losses/train_all_loss_class': 1.6959562142915274e-05, 'Losses/train_all_core_loss': 7.426462268829345, 'Trainer/where': 0.13949999999999999, 'Trainer/epoch': 6, 'Trainer/steps_train': 280}
INFO 2025-05-06 12:16:55,018 train_utils.py: 271: Train Epoch: [7][ 0/40] | Batch Time: 11.51 (11.51) | Data Time: 10.32 (10.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.89e+00 (7.89e+00)
INFO 2025-05-06 12:17:02,683 train_utils.py: 271: Train Epoch: [7][10/40] | Batch Time: 0.73 (1.74) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.84e+00 (7.66e+00)
INFO 2025-05-06 12:17:10,566 train_utils.py: 271: Train Epoch: [7][20/40] | Batch Time: 0.80 (1.29) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 8.01e+00 (7.69e+00)
INFO 2025-05-06 12:17:18,228 train_utils.py: 271: Train Epoch: [7][30/40] | Batch Time: 0.77 (1.12) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.51e+00 (7.66e+00)
INFO 2025-05-06 12:17:25,883 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-05-06 12:17:25,884 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:17:25,884 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.570271575450898, 'Losses/train_all_loss_mask': 0.018155527746057488, 'Losses/train_all_loss_dice': 7.180947840213776, 'Losses/train_all_loss_iou': 0.026198733624914892, 'Losses/train_all_loss_class': 1.4512801002197761e-05, 'Losses/train_all_core_loss': 7.570271575450898, 'Trainer/where': 0.1595, 'Trainer/epoch': 7, 'Trainer/steps_train': 320}
INFO 2025-05-06 12:17:40,579 train_utils.py: 271: Train Epoch: [8][ 0/40] | Batch Time: 11.59 (11.59) | Data Time: 10.57 (10.57) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 8.05e+00 (8.05e+00)
INFO 2025-05-06 12:17:48,022 train_utils.py: 271: Train Epoch: [8][10/40] | Batch Time: 0.78 (1.73) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.50e+00 (7.32e+00)
INFO 2025-05-06 12:17:55,663 train_utils.py: 271: Train Epoch: [8][20/40] | Batch Time: 0.72 (1.27) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 5.01e+00 (7.53e+00)
INFO 2025-05-06 12:18:02,867 train_utils.py: 271: Train Epoch: [8][30/40] | Batch Time: 0.69 (1.09) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.59e+00 (7.47e+00)
INFO 2025-05-06 12:18:10,255 trainer.py: 950: Estimated time remaining: 00d 00h 27m
INFO 2025-05-06 12:18:10,255 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:18:10,255 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.546712076663971, 'Losses/train_all_loss_mask': 0.01239486394042615, 'Losses/train_all_loss_dice': 7.292927074432373, 'Losses/train_all_loss_iou': 0.005877068237168714, 'Losses/train_all_loss_class': 1.0626199967145311e-05, 'Losses/train_all_core_loss': 7.546712076663971, 'Trainer/where': 0.1795, 'Trainer/epoch': 8, 'Trainer/steps_train': 360}
INFO 2025-05-06 12:18:23,279 train_utils.py: 271: Train Epoch: [9][ 0/40] | Batch Time: 11.19 (11.19) | Data Time: 10.17 (10.17) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 5.37e+00 (5.37e+00)
INFO 2025-05-06 12:18:30,838 train_utils.py: 271: Train Epoch: [9][10/40] | Batch Time: 0.85 (1.70) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 7.70e+00 (7.24e+00)
INFO 2025-05-06 12:18:38,503 train_utils.py: 271: Train Epoch: [9][20/40] | Batch Time: 0.70 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 7.72e+00 (7.42e+00)
INFO 2025-05-06 12:18:45,696 train_utils.py: 271: Train Epoch: [9][30/40] | Batch Time: 0.68 (1.08) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.01e+00 (7.47e+00)
INFO 2025-05-06 12:18:52,955 trainer.py: 950: Estimated time remaining: 00d 00h 26m
INFO 2025-05-06 12:18:52,956 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:18:52,956 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.363995659351349, 'Losses/train_all_loss_mask': 0.01637169875757536, 'Losses/train_all_loss_dice': 7.029054290056228, 'Losses/train_all_loss_iou': 0.00749545753642451, 'Losses/train_all_loss_class': 1.1991118451959437e-05, 'Losses/train_all_core_loss': 7.363995659351349, 'Trainer/where': 0.19949999999999998, 'Trainer/epoch': 9, 'Trainer/steps_train': 400}
INFO 2025-05-06 12:19:06,925 train_utils.py: 271: Train Epoch: [10][ 0/40] | Batch Time: 11.10 (11.10) | Data Time: 10.01 (10.01) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.86e+00 (7.86e+00)
INFO 2025-05-06 12:19:14,151 train_utils.py: 271: Train Epoch: [10][10/40] | Batch Time: 0.71 (1.67) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.95e+00 (7.82e+00)
INFO 2025-05-06 12:19:21,376 train_utils.py: 271: Train Epoch: [10][20/40] | Batch Time: 0.73 (1.22) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.33e+00 (7.74e+00)
INFO 2025-05-06 12:19:28,626 train_utils.py: 271: Train Epoch: [10][30/40] | Batch Time: 0.74 (1.06) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 6.60e+00 (7.40e+00)
INFO 2025-05-06 12:19:36,233 trainer.py: 950: Estimated time remaining: 00d 00h 25m
INFO 2025-05-06 12:19:36,234 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:19:36,234 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.842531460523605, 'Losses/train_all_loss_mask': 0.028266674003680235, 'Losses/train_all_loss_dice': 7.266219466924667, 'Losses/train_all_loss_iou': 0.010966380530589959, 'Losses/train_all_loss_class': 1.2117899669306097e-05, 'Losses/train_all_core_loss': 7.842531460523605, 'Trainer/where': 0.2195, 'Trainer/epoch': 10, 'Trainer/steps_train': 440}
INFO 2025-05-06 12:19:50,938 train_utils.py: 271: Train Epoch: [11][ 0/40] | Batch Time: 11.61 (11.61) | Data Time: 10.42 (10.42) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.97e+00 (7.97e+00)
INFO 2025-05-06 12:19:58,535 train_utils.py: 271: Train Epoch: [11][10/40] | Batch Time: 0.75 (1.75) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.47e+00 (8.41e+00)
INFO 2025-05-06 12:20:06,060 train_utils.py: 271: Train Epoch: [11][20/40] | Batch Time: 0.72 (1.27) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 6.16e+00 (7.87e+00)
INFO 2025-05-06 12:20:13,257 train_utils.py: 271: Train Epoch: [11][30/40] | Batch Time: 0.74 (1.09) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 8.11e+00 (7.85e+00)
INFO 2025-05-06 12:20:21,454 trainer.py: 950: Estimated time remaining: 00d 00h 26m
INFO 2025-05-06 12:20:21,455 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:20:21,455 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.6230742812156675, 'Losses/train_all_loss_mask': 0.022081726275064283, 'Losses/train_all_loss_dice': 7.131791281700134, 'Losses/train_all_loss_iou': 0.049642949422559465, 'Losses/train_all_loss_class': 5.564365184085318e-06, 'Losses/train_all_core_loss': 7.6230742812156675, 'Trainer/where': 0.2395, 'Trainer/epoch': 11, 'Trainer/steps_train': 480}
INFO 2025-05-06 12:20:36,324 train_utils.py: 271: Train Epoch: [12][ 0/40] | Batch Time: 11.85 (11.85) | Data Time: 10.73 (10.73) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.79e+00 (7.79e+00)
INFO 2025-05-06 12:20:44,150 train_utils.py: 271: Train Epoch: [12][10/40] | Batch Time: 0.82 (1.79) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 5.29e+00 (7.34e+00)
INFO 2025-05-06 12:20:52,062 train_utils.py: 271: Train Epoch: [12][20/40] | Batch Time: 0.79 (1.31) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.47e+00 (7.18e+00)
INFO 2025-05-06 12:20:59,824 train_utils.py: 271: Train Epoch: [12][30/40] | Batch Time: 0.77 (1.14) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.72e+00 (7.27e+00)
INFO 2025-05-06 12:21:07,685 trainer.py: 950: Estimated time remaining: 00d 00h 26m
INFO 2025-05-06 12:21:07,686 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:21:07,686 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.25102082490921, 'Losses/train_all_loss_mask': 0.01171252755302703, 'Losses/train_all_loss_dice': 6.989954054355621, 'Losses/train_all_loss_iou': 0.02680949586138013, 'Losses/train_all_loss_class': 6.729083637679878e-06, 'Losses/train_all_core_loss': 7.25102082490921, 'Trainer/where': 0.2595, 'Trainer/epoch': 12, 'Trainer/steps_train': 520}
INFO 2025-05-06 12:21:21,171 train_utils.py: 271: Train Epoch: [13][ 0/40] | Batch Time: 11.11 (11.11) | Data Time: 10.00 (10.00) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.90e+00 (7.90e+00)
INFO 2025-05-06 12:21:29,164 train_utils.py: 271: Train Epoch: [13][10/40] | Batch Time: 0.79 (1.74) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.36e+00 (7.07e+00)
INFO 2025-05-06 12:21:36,995 train_utils.py: 271: Train Epoch: [13][20/40] | Batch Time: 0.78 (1.28) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 5.52e+00 (7.16e+00)
INFO 2025-05-06 12:21:44,960 train_utils.py: 271: Train Epoch: [13][30/40] | Batch Time: 0.82 (1.13) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 5.41e+00 (7.19e+00)
INFO 2025-05-06 12:21:52,810 trainer.py: 950: Estimated time remaining: 00d 00h 25m
INFO 2025-05-06 12:21:52,811 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:21:52,811 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.206873404979706, 'Losses/train_all_loss_mask': 0.008398232536274008, 'Losses/train_all_loss_dice': 7.021433866024017, 'Losses/train_all_loss_iou': 0.017467440287873615, 'Losses/train_all_loss_class': 7.437198032533843e-06, 'Losses/train_all_core_loss': 7.206873404979706, 'Trainer/where': 0.27949999999999997, 'Trainer/epoch': 13, 'Trainer/steps_train': 560}
INFO 2025-05-06 12:22:07,349 train_utils.py: 271: Train Epoch: [14][ 0/40] | Batch Time: 11.50 (11.50) | Data Time: 10.32 (10.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.05e+00 (8.05e+00)
INFO 2025-05-06 12:22:15,175 train_utils.py: 271: Train Epoch: [14][10/40] | Batch Time: 0.79 (1.76) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.03e+00 (6.62e+00)
INFO 2025-05-06 12:22:23,058 train_utils.py: 271: Train Epoch: [14][20/40] | Batch Time: 0.78 (1.30) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 7.84e+00 (7.22e+00)
INFO 2025-05-06 12:22:31,011 train_utils.py: 271: Train Epoch: [14][30/40] | Batch Time: 0.80 (1.13) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.16e+00 (7.26e+00)
INFO 2025-05-06 12:22:38,723 trainer.py: 950: Estimated time remaining: 00d 00h 24m
INFO 2025-05-06 12:22:38,724 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:22:38,724 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.300611937046051, 'Losses/train_all_loss_mask': 0.012035798746728688, 'Losses/train_all_loss_dice': 7.004784899950027, 'Losses/train_all_loss_iou': 0.05509790132782655, 'Losses/train_all_loss_class': 1.3149682293800425e-05, 'Losses/train_all_core_loss': 7.300611937046051, 'Trainer/where': 0.2995, 'Trainer/epoch': 14, 'Trainer/steps_train': 600}
INFO 2025-05-06 12:22:53,153 train_utils.py: 271: Train Epoch: [15][ 0/40] | Batch Time: 11.37 (11.37) | Data Time: 10.28 (10.28) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 3.79e+00 (3.79e+00)
INFO 2025-05-06 12:23:01,177 train_utils.py: 271: Train Epoch: [15][10/40] | Batch Time: 0.81 (1.76) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 5.20e+00 (7.04e+00)
INFO 2025-05-06 12:23:09,455 train_utils.py: 271: Train Epoch: [15][20/40] | Batch Time: 0.80 (1.32) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 6.19e+00 (7.57e+00)
INFO 2025-05-06 12:23:17,782 train_utils.py: 271: Train Epoch: [15][30/40] | Batch Time: 0.80 (1.16) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 7.98e+00 (7.53e+00)
INFO 2025-05-06 12:23:25,947 trainer.py: 950: Estimated time remaining: 00d 00h 24m
INFO 2025-05-06 12:23:25,947 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:23:25,948 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.425289410352707, 'Losses/train_all_loss_mask': 0.017450540048594122, 'Losses/train_all_loss_dice': 7.042691689729691, 'Losses/train_all_loss_iou': 0.033581233429868004, 'Losses/train_all_loss_class': 5.76396910254573e-06, 'Losses/train_all_core_loss': 7.425289410352707, 'Trainer/where': 0.3195, 'Trainer/epoch': 15, 'Trainer/steps_train': 640}
INFO 2025-05-06 12:23:41,503 train_utils.py: 271: Train Epoch: [16][ 0/40] | Batch Time: 11.58 (11.58) | Data Time: 10.43 (10.43) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 9.20e+00 (9.20e+00)
INFO 2025-05-06 12:23:49,578 train_utils.py: 271: Train Epoch: [16][10/40] | Batch Time: 0.81 (1.79) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.87e+00 (7.48e+00)
INFO 2025-05-06 12:23:57,696 train_utils.py: 271: Train Epoch: [16][20/40] | Batch Time: 0.82 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 5.37e+00 (7.54e+00)
INFO 2025-05-06 12:24:05,769 train_utils.py: 271: Train Epoch: [16][30/40] | Batch Time: 0.79 (1.16) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.02e+00 (7.40e+00)
INFO 2025-05-06 12:24:13,798 trainer.py: 950: Estimated time remaining: 00d 00h 23m
INFO 2025-05-06 12:24:13,798 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:24:13,798 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.515242075920105, 'Losses/train_all_loss_mask': 0.014881125573447207, 'Losses/train_all_loss_dice': 7.192204147577286, 'Losses/train_all_loss_iou': 0.025410169914721337, 'Losses/train_all_loss_class': 5.363927651558242e-06, 'Losses/train_all_core_loss': 7.515242075920105, 'Trainer/where': 0.3395, 'Trainer/epoch': 16, 'Trainer/steps_train': 680}
INFO 2025-05-06 12:24:28,542 train_utils.py: 271: Train Epoch: [17][ 0/40] | Batch Time: 11.79 (11.79) | Data Time: 10.52 (10.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.94e+00 (7.94e+00)
INFO 2025-05-06 12:24:36,678 train_utils.py: 271: Train Epoch: [17][10/40] | Batch Time: 0.80 (1.81) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.58e+00 (7.79e+00)
INFO 2025-05-06 12:24:44,745 train_utils.py: 271: Train Epoch: [17][20/40] | Batch Time: 0.80 (1.33) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.11e+00 (7.57e+00)
INFO 2025-05-06 12:24:52,877 train_utils.py: 271: Train Epoch: [17][30/40] | Batch Time: 0.82 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.56e+00 (7.50e+00)
INFO 2025-05-06 12:25:00,927 trainer.py: 950: Estimated time remaining: 00d 00h 23m
INFO 2025-05-06 12:25:00,928 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:25:00,928 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.4604461073875425, 'Losses/train_all_loss_mask': 0.014641078482964077, 'Losses/train_all_loss_dice': 7.140776228904724, 'Losses/train_all_loss_iou': 0.026841932014212942, 'Losses/train_all_loss_class': 6.434302503066647e-06, 'Losses/train_all_core_loss': 7.4604461073875425, 'Trainer/where': 0.35950000000000004, 'Trainer/epoch': 17, 'Trainer/steps_train': 720}
INFO 2025-05-06 12:25:15,743 train_utils.py: 271: Train Epoch: [18][ 0/40] | Batch Time: 11.72 (11.72) | Data Time: 10.42 (10.42) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 7.53e+00 (7.53e+00)
INFO 2025-05-06 12:25:23,745 train_utils.py: 271: Train Epoch: [18][10/40] | Batch Time: 0.79 (1.79) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 7.63e+00 (7.65e+00)
INFO 2025-05-06 12:25:31,751 train_utils.py: 271: Train Epoch: [18][20/40] | Batch Time: 0.78 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.80e+00 (7.34e+00)
INFO 2025-05-06 12:25:39,886 train_utils.py: 271: Train Epoch: [18][30/40] | Batch Time: 0.83 (1.16) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.62e+00 (7.45e+00)
INFO 2025-05-06 12:25:47,845 trainer.py: 950: Estimated time remaining: 00d 00h 22m
INFO 2025-05-06 12:25:47,845 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:25:47,846 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.4822596430778505, 'Losses/train_all_loss_mask': 0.009911912253301125, 'Losses/train_all_loss_dice': 7.2440059065818785, 'Losses/train_all_loss_iou': 0.04000875173242093, 'Losses/train_all_loss_class': 6.77559006057038e-06, 'Losses/train_all_core_loss': 7.4822596430778505, 'Trainer/where': 0.3795, 'Trainer/epoch': 18, 'Trainer/steps_train': 760}
INFO 2025-05-06 12:26:02,446 train_utils.py: 271: Train Epoch: [19][ 0/40] | Batch Time: 11.47 (11.47) | Data Time: 10.44 (10.44) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.00e+00 (8.00e+00)
INFO 2025-05-06 12:26:10,499 train_utils.py: 271: Train Epoch: [19][10/40] | Batch Time: 0.80 (1.77) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 7.68e+00 (7.86e+00)
INFO 2025-05-06 12:26:18,598 train_utils.py: 271: Train Epoch: [19][20/40] | Batch Time: 0.80 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 9.30e+00 (7.60e+00)
INFO 2025-05-06 12:26:26,624 train_utils.py: 271: Train Epoch: [19][30/40] | Batch Time: 0.79 (1.15) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.24e+00 (7.45e+00)
INFO 2025-05-06 12:26:34,666 trainer.py: 950: Estimated time remaining: 00d 00h 21m
INFO 2025-05-06 12:26:34,667 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:26:34,667 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.375670433044434, 'Losses/train_all_loss_mask': 0.015354900644888403, 'Losses/train_all_loss_dice': 7.043369603157044, 'Losses/train_all_loss_iou': 0.025185529651935212, 'Losses/train_all_loss_class': 1.728652392927188e-05, 'Losses/train_all_core_loss': 7.375670433044434, 'Trainer/where': 0.3995, 'Trainer/epoch': 19, 'Trainer/steps_train': 800}
INFO 2025-05-06 12:26:48,913 train_utils.py: 271: Train Epoch: [20][ 0/40] | Batch Time: 11.68 (11.68) | Data Time: 10.49 (10.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.00e+00 (8.00e+00)
INFO 2025-05-06 12:26:57,179 train_utils.py: 271: Train Epoch: [20][10/40] | Batch Time: 0.81 (1.81) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 7.78e+00 (7.61e+00)
INFO 2025-05-06 12:27:05,372 train_utils.py: 271: Train Epoch: [20][20/40] | Batch Time: 0.83 (1.34) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 7.90e+00 (7.58e+00)
INFO 2025-05-06 12:27:13,554 train_utils.py: 271: Train Epoch: [20][30/40] | Batch Time: 0.83 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 8.21e+00 (7.46e+00)
INFO 2025-05-06 12:27:22,001 trainer.py: 950: Estimated time remaining: 00d 00h 21m
INFO 2025-05-06 12:27:22,002 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:27:22,002 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.391752350330353, 'Losses/train_all_loss_mask': 0.012452663970907451, 'Losses/train_all_loss_dice': 7.123035705089569, 'Losses/train_all_loss_iou': 0.019647458105100667, 'Losses/train_all_loss_class': 1.5798593115334824e-05, 'Losses/train_all_core_loss': 7.391752350330353, 'Trainer/where': 0.41950000000000004, 'Trainer/epoch': 20, 'Trainer/steps_train': 840}
INFO 2025-05-06 12:27:38,088 train_utils.py: 271: Train Epoch: [21][ 0/40] | Batch Time: 11.74 (11.74) | Data Time: 10.51 (10.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 5.07e+00 (5.07e+00)
INFO 2025-05-06 12:27:46,269 train_utils.py: 271: Train Epoch: [21][10/40] | Batch Time: 0.82 (1.81) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 4.00e+00 (6.92e+00)
INFO 2025-05-06 12:27:54,492 train_utils.py: 271: Train Epoch: [21][20/40] | Batch Time: 0.84 (1.34) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 5.30e+00 (7.00e+00)
INFO 2025-05-06 12:28:02,675 train_utils.py: 271: Train Epoch: [21][30/40] | Batch Time: 0.83 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 7.64e+00 (7.13e+00)
INFO 2025-05-06 12:28:10,737 trainer.py: 950: Estimated time remaining: 00d 00h 20m
INFO 2025-05-06 12:28:10,738 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:28:10,738 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.177791810035705, 'Losses/train_all_loss_mask': 0.009154371960903518, 'Losses/train_all_loss_dice': 6.968333232402801, 'Losses/train_all_loss_iou': 0.026313867678800305, 'Losses/train_all_loss_class': 5.726331205799795e-05, 'Losses/train_all_core_loss': 7.177791810035705, 'Trainer/where': 0.4395, 'Trainer/epoch': 21, 'Trainer/steps_train': 880}
INFO 2025-05-06 12:28:26,063 train_utils.py: 271: Train Epoch: [22][ 0/40] | Batch Time: 11.82 (11.82) | Data Time: 10.55 (10.55) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 8.01e+00 (8.01e+00)
INFO 2025-05-06 12:28:34,649 train_utils.py: 271: Train Epoch: [22][10/40] | Batch Time: 0.80 (1.85) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 5.34e+00 (7.37e+00)
INFO 2025-05-06 12:28:42,511 train_utils.py: 271: Train Epoch: [22][20/40] | Batch Time: 0.79 (1.35) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 8.08e+00 (7.38e+00)
INFO 2025-05-06 12:28:50,510 train_utils.py: 271: Train Epoch: [22][30/40] | Batch Time: 0.80 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 7.90e+00 (7.39e+00)
INFO 2025-05-06 12:28:58,446 trainer.py: 950: Estimated time remaining: 00d 00h 19m
INFO 2025-05-06 12:28:58,447 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:28:58,447 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.315818053483963, 'Losses/train_all_loss_mask': 0.011092442498193123, 'Losses/train_all_loss_dice': 7.073425376415253, 'Losses/train_all_loss_iou': 0.020538441427561338, 'Losses/train_all_loss_class': 5.435138745468748e-06, 'Losses/train_all_core_loss': 7.315818053483963, 'Trainer/where': 0.4595, 'Trainer/epoch': 22, 'Trainer/steps_train': 920}
INFO 2025-05-06 12:29:13,342 train_utils.py: 271: Train Epoch: [23][ 0/40] | Batch Time: 11.87 (11.87) | Data Time: 10.86 (10.86) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 5.36e+00 (5.36e+00)
INFO 2025-05-06 12:29:21,408 train_utils.py: 271: Train Epoch: [23][10/40] | Batch Time: 0.79 (1.81) | Data Time: 0.00 (0.99) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 8.33e+00 (7.46e+00)
INFO 2025-05-06 12:29:29,264 train_utils.py: 271: Train Epoch: [23][20/40] | Batch Time: 0.77 (1.32) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 8.38e+00 (7.58e+00)
INFO 2025-05-06 12:29:37,195 train_utils.py: 271: Train Epoch: [23][30/40] | Batch Time: 0.80 (1.15) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 7.89e+00 (7.28e+00)
INFO 2025-05-06 12:29:45,261 trainer.py: 950: Estimated time remaining: 00d 00h 18m
INFO 2025-05-06 12:29:45,261 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:29:45,261 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.315509259700775, 'Losses/train_all_loss_mask': 0.014455714634095784, 'Losses/train_all_loss_dice': 6.982262921333313, 'Losses/train_all_loss_iou': 0.04412425321024784, 'Losses/train_all_loss_class': 7.82120185132129e-06, 'Losses/train_all_core_loss': 7.315509259700775, 'Trainer/where': 0.47950000000000004, 'Trainer/epoch': 23, 'Trainer/steps_train': 960}
INFO 2025-05-06 12:30:00,133 train_utils.py: 271: Train Epoch: [24][ 0/40] | Batch Time: 11.79 (11.79) | Data Time: 10.70 (10.70) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.95e+00 (7.95e+00)
INFO 2025-05-06 12:30:07,805 train_utils.py: 271: Train Epoch: [24][10/40] | Batch Time: 0.73 (1.77) | Data Time: 0.00 (0.97) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 8.06e+00 (7.24e+00)
INFO 2025-05-06 12:30:15,490 train_utils.py: 271: Train Epoch: [24][20/40] | Batch Time: 0.78 (1.29) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.43e+00 (7.02e+00)
INFO 2025-05-06 12:30:23,067 train_utils.py: 271: Train Epoch: [24][30/40] | Batch Time: 0.74 (1.12) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.96e+00 (7.10e+00)
INFO 2025-05-06 12:30:30,758 trainer.py: 950: Estimated time remaining: 00d 00h 17m
INFO 2025-05-06 12:30:30,759 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:30:30,759 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.26828578710556, 'Losses/train_all_loss_mask': 0.012859936775930692, 'Losses/train_all_loss_dice': 6.936239397525787, 'Losses/train_all_loss_iou': 0.07483694637048757, 'Losses/train_all_loss_class': 1.0758131455013142e-05, 'Losses/train_all_core_loss': 7.26828578710556, 'Trainer/where': 0.49950000000000006, 'Trainer/epoch': 24, 'Trainer/steps_train': 1000}
INFO 2025-05-06 12:30:44,328 train_utils.py: 271: Train Epoch: [25][ 0/40] | Batch Time: 11.15 (11.15) | Data Time: 10.16 (10.16) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.92e+00 (7.92e+00)
INFO 2025-05-06 12:30:51,944 train_utils.py: 271: Train Epoch: [25][10/40] | Batch Time: 0.72 (1.71) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.91e+00 (7.58e+00)
INFO 2025-05-06 12:30:59,497 train_utils.py: 271: Train Epoch: [25][20/40] | Batch Time: 0.78 (1.25) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.49e+00 (7.39e+00)
INFO 2025-05-06 12:31:06,991 train_utils.py: 271: Train Epoch: [25][30/40] | Batch Time: 0.73 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 5.33e+00 (7.38e+00)
INFO 2025-05-06 12:31:14,492 trainer.py: 950: Estimated time remaining: 00d 00h 16m
INFO 2025-05-06 12:31:14,493 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:31:14,493 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.19477424621582, 'Losses/train_all_loss_mask': 0.0107581250849762, 'Losses/train_all_loss_dice': 6.924935805797577, 'Losses/train_all_loss_iou': 0.054663771609011744, 'Losses/train_all_loss_class': 1.2196278051845865e-05, 'Losses/train_all_core_loss': 7.19477424621582, 'Trainer/where': 0.5195000000000001, 'Trainer/epoch': 25, 'Trainer/steps_train': 1040}
INFO 2025-05-06 12:31:27,920 train_utils.py: 271: Train Epoch: [26][ 0/40] | Batch Time: 11.11 (11.11) | Data Time: 10.12 (10.12) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.94e+00 (7.94e+00)
INFO 2025-05-06 12:31:35,551 train_utils.py: 271: Train Epoch: [26][10/40] | Batch Time: 0.76 (1.70) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.93e+00 (7.21e+00)
INFO 2025-05-06 12:31:43,008 train_utils.py: 271: Train Epoch: [26][20/40] | Batch Time: 0.72 (1.25) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 8.30e+00 (7.52e+00)
INFO 2025-05-06 12:31:50,450 train_utils.py: 271: Train Epoch: [26][30/40] | Batch Time: 0.73 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 8.00e+00 (7.51e+00)
INFO 2025-05-06 12:31:57,964 trainer.py: 950: Estimated time remaining: 00d 00h 15m
INFO 2025-05-06 12:31:57,964 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:31:57,964 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.456307947635651, 'Losses/train_all_loss_mask': 0.01124967420619214, 'Losses/train_all_loss_dice': 7.211522948741913, 'Losses/train_all_loss_iou': 0.019784772159255226, 'Losses/train_all_loss_class': 6.668077377725012e-06, 'Losses/train_all_core_loss': 7.456307947635651, 'Trainer/where': 0.5395, 'Trainer/epoch': 26, 'Trainer/steps_train': 1080}
INFO 2025-05-06 12:32:12,096 train_utils.py: 271: Train Epoch: [27][ 0/40] | Batch Time: 11.18 (11.18) | Data Time: 10.15 (10.15) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.09e+00 (7.09e+00)
INFO 2025-05-06 12:32:19,881 train_utils.py: 271: Train Epoch: [27][10/40] | Batch Time: 0.78 (1.72) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.69e+00 (7.18e+00)
INFO 2025-05-06 12:32:27,739 train_utils.py: 271: Train Epoch: [27][20/40] | Batch Time: 0.86 (1.28) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.96e+00 (6.99e+00)
INFO 2025-05-06 12:32:35,353 train_utils.py: 271: Train Epoch: [27][30/40] | Batch Time: 0.80 (1.11) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 8.03e+00 (7.31e+00)
INFO 2025-05-06 12:32:43,110 trainer.py: 950: Estimated time remaining: 00d 00h 15m
INFO 2025-05-06 12:32:43,111 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:32:43,111 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.320213985443115, 'Losses/train_all_loss_mask': 0.014174740976886823, 'Losses/train_all_loss_dice': 7.002888977527618, 'Losses/train_all_loss_iou': 0.03382327603612793, 'Losses/train_all_loss_class': 6.925258599110862e-06, 'Losses/train_all_core_loss': 7.320213985443115, 'Trainer/where': 0.5595, 'Trainer/epoch': 27, 'Trainer/steps_train': 1120}
INFO 2025-05-06 12:32:57,487 train_utils.py: 271: Train Epoch: [28][ 0/40] | Batch Time: 11.42 (11.42) | Data Time: 10.26 (10.26) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.84e+00 (7.84e+00)
INFO 2025-05-06 12:33:05,064 train_utils.py: 271: Train Epoch: [28][10/40] | Batch Time: 0.78 (1.73) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.77e+00 (8.02e+00)
INFO 2025-05-06 12:33:12,545 train_utils.py: 271: Train Epoch: [28][20/40] | Batch Time: 0.74 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.52e+00 (7.69e+00)
INFO 2025-05-06 12:33:20,040 train_utils.py: 271: Train Epoch: [28][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.86e+00 (7.63e+00)
INFO 2025-05-06 12:33:27,592 trainer.py: 950: Estimated time remaining: 00d 00h 14m
INFO 2025-05-06 12:33:27,592 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:33:27,592 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.526504611968994, 'Losses/train_all_loss_mask': 0.013473322594654747, 'Losses/train_all_loss_dice': 7.226633656024933, 'Losses/train_all_loss_iou': 0.03040109850408044, 'Losses/train_all_loss_class': 3.421383641644127e-06, 'Losses/train_all_core_loss': 7.526504611968994, 'Trainer/where': 0.5795, 'Trainer/epoch': 28, 'Trainer/steps_train': 1160}
INFO 2025-05-06 12:33:40,680 train_utils.py: 271: Train Epoch: [29][ 0/40] | Batch Time: 11.15 (11.15) | Data Time: 10.17 (10.17) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.60e+00 (7.60e+00)
INFO 2025-05-06 12:33:48,479 train_utils.py: 271: Train Epoch: [29][10/40] | Batch Time: 0.77 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 5.74e+00 (7.07e+00)
INFO 2025-05-06 12:33:55,848 train_utils.py: 271: Train Epoch: [29][20/40] | Batch Time: 0.76 (1.25) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.87e+00 (7.19e+00)
INFO 2025-05-06 12:34:03,404 train_utils.py: 271: Train Epoch: [29][30/40] | Batch Time: 0.75 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.57e+00 (7.29e+00)
INFO 2025-05-06 12:34:10,936 trainer.py: 950: Estimated time remaining: 00d 00h 13m
INFO 2025-05-06 12:34:10,936 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:34:10,936 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.417935109138488, 'Losses/train_all_loss_mask': 0.011637375975260511, 'Losses/train_all_loss_dice': 7.150033664703369, 'Losses/train_all_loss_iou': 0.03511762805737817, 'Losses/train_all_loss_class': 3.629473661312943e-05, 'Losses/train_all_core_loss': 7.417935109138488, 'Trainer/where': 0.5995, 'Trainer/epoch': 29, 'Trainer/steps_train': 1200}
INFO 2025-05-06 12:34:24,075 train_utils.py: 271: Train Epoch: [30][ 0/40] | Batch Time: 11.30 (11.30) | Data Time: 10.10 (10.10) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.60e+00 (7.60e+00)
INFO 2025-05-06 12:34:31,658 train_utils.py: 271: Train Epoch: [30][10/40] | Batch Time: 0.76 (1.72) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 4.96e+00 (7.28e+00)
INFO 2025-05-06 12:34:39,187 train_utils.py: 271: Train Epoch: [30][20/40] | Batch Time: 0.78 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 6.60e+00 (7.41e+00)
INFO 2025-05-06 12:34:46,784 train_utils.py: 271: Train Epoch: [30][30/40] | Batch Time: 0.74 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.72e+00 (7.43e+00)
INFO 2025-05-06 12:34:54,280 trainer.py: 950: Estimated time remaining: 00d 00h 12m
INFO 2025-05-06 12:34:54,280 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:34:54,280 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.424049758911133, 'Losses/train_all_loss_mask': 0.008575243993254844, 'Losses/train_all_loss_dice': 7.237179911136627, 'Losses/train_all_loss_iou': 0.01535711917495064, 'Losses/train_all_loss_class': 7.842157911319702e-06, 'Losses/train_all_core_loss': 7.424049758911133, 'Trainer/where': 0.6195, 'Trainer/epoch': 30, 'Trainer/steps_train': 1240}
INFO 2025-05-06 12:35:08,619 train_utils.py: 271: Train Epoch: [31][ 0/40] | Batch Time: 11.41 (11.41) | Data Time: 10.28 (10.28) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.80e+00 (7.80e+00)
INFO 2025-05-06 12:35:16,208 train_utils.py: 271: Train Epoch: [31][10/40] | Batch Time: 0.75 (1.73) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 8.06e+00 (7.16e+00)
INFO 2025-05-06 12:35:23,730 train_utils.py: 271: Train Epoch: [31][20/40] | Batch Time: 0.77 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.86e+00 (7.38e+00)
INFO 2025-05-06 12:35:31,171 train_utils.py: 271: Train Epoch: [31][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.73e+00 (7.33e+00)
INFO 2025-05-06 12:35:38,675 trainer.py: 950: Estimated time remaining: 00d 00h 12m
INFO 2025-05-06 12:35:38,676 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:35:38,676 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.276989865303039, 'Losses/train_all_loss_mask': 0.005445002685155487, 'Losses/train_all_loss_dice': 7.142256504297256, 'Losses/train_all_loss_iou': 0.02582859288554573, 'Losses/train_all_loss_class': 4.704470219962786e-06, 'Losses/train_all_core_loss': 7.276989865303039, 'Trainer/where': 0.6395000000000001, 'Trainer/epoch': 31, 'Trainer/steps_train': 1280}
INFO 2025-05-06 12:35:52,081 train_utils.py: 271: Train Epoch: [32][ 0/40] | Batch Time: 11.37 (11.37) | Data Time: 10.21 (10.21) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.77e+00 (7.77e+00)
INFO 2025-05-06 12:35:59,609 train_utils.py: 271: Train Epoch: [32][10/40] | Batch Time: 0.73 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.65e+00 (7.05e+00)
INFO 2025-05-06 12:36:07,149 train_utils.py: 271: Train Epoch: [32][20/40] | Batch Time: 0.77 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.82e+00 (7.12e+00)
INFO 2025-05-06 12:36:14,662 train_utils.py: 271: Train Epoch: [32][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.77e+00 (7.16e+00)
INFO 2025-05-06 12:36:22,146 trainer.py: 950: Estimated time remaining: 00d 00h 11m
INFO 2025-05-06 12:36:22,146 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:36:22,147 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.264893007278443, 'Losses/train_all_loss_mask': 0.005907002903404646, 'Losses/train_all_loss_dice': 7.136012673377991, 'Losses/train_all_loss_iou': 0.010729180686303153, 'Losses/train_all_loss_class': 1.1058426187293691e-05, 'Losses/train_all_core_loss': 7.264893007278443, 'Trainer/where': 0.6595, 'Trainer/epoch': 32, 'Trainer/steps_train': 1320}
INFO 2025-05-06 12:36:35,378 train_utils.py: 271: Train Epoch: [33][ 0/40] | Batch Time: 11.31 (11.31) | Data Time: 10.20 (10.20) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.73e+00 (7.73e+00)
INFO 2025-05-06 12:36:42,951 train_utils.py: 271: Train Epoch: [33][10/40] | Batch Time: 0.76 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.96e+00 (7.49e+00)
INFO 2025-05-06 12:36:50,538 train_utils.py: 271: Train Epoch: [33][20/40] | Batch Time: 0.75 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 5.31e+00 (7.45e+00)
INFO 2025-05-06 12:36:57,975 train_utils.py: 271: Train Epoch: [33][30/40] | Batch Time: 0.72 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 4.87e+00 (7.44e+00)
INFO 2025-05-06 12:37:05,672 trainer.py: 950: Estimated time remaining: 00d 00h 10m
INFO 2025-05-06 12:37:05,672 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:37:05,673 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.274829393625259, 'Losses/train_all_loss_mask': 0.012328154476563213, 'Losses/train_all_loss_dice': 7.01775324344635, 'Losses/train_all_loss_iou': 0.010503313530443847, 'Losses/train_all_loss_class': 9.646610927127598e-06, 'Losses/train_all_core_loss': 7.274829393625259, 'Trainer/where': 0.6795, 'Trainer/epoch': 33, 'Trainer/steps_train': 1360}
INFO 2025-05-06 12:37:19,056 train_utils.py: 271: Train Epoch: [34][ 0/40] | Batch Time: 11.17 (11.17) | Data Time: 10.12 (10.12) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.48e+00 (7.48e+00)
INFO 2025-05-06 12:37:26,730 train_utils.py: 271: Train Epoch: [34][10/40] | Batch Time: 0.76 (1.71) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 5.26e+00 (7.24e+00)
INFO 2025-05-06 12:37:34,285 train_utils.py: 271: Train Epoch: [34][20/40] | Batch Time: 0.76 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.92e+00 (7.41e+00)
INFO 2025-05-06 12:37:41,945 train_utils.py: 271: Train Epoch: [34][30/40] | Batch Time: 0.77 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.28e+00 (7.33e+00)
INFO 2025-05-06 12:37:49,605 trainer.py: 950: Estimated time remaining: 00d 00h 10m
INFO 2025-05-06 12:37:49,606 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:37:49,606 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.364873516559601, 'Losses/train_all_loss_mask': 0.012314582762337522, 'Losses/train_all_loss_dice': 7.0796364665031435, 'Losses/train_all_loss_iou': 0.038926952126075776, 'Losses/train_all_loss_class': 1.8400740428603514e-05, 'Losses/train_all_core_loss': 7.364873516559601, 'Trainer/where': 0.6995, 'Trainer/epoch': 34, 'Trainer/steps_train': 1400}
INFO 2025-05-06 12:38:03,349 train_utils.py: 271: Train Epoch: [35][ 0/40] | Batch Time: 11.16 (11.16) | Data Time: 10.22 (10.22) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 8.80e+00 (8.80e+00)
INFO 2025-05-06 12:38:10,863 train_utils.py: 271: Train Epoch: [35][10/40] | Batch Time: 0.72 (1.70) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 6.80e+00 (7.13e+00)
INFO 2025-05-06 12:38:18,362 train_utils.py: 271: Train Epoch: [35][20/40] | Batch Time: 0.75 (1.25) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.20e+00 (7.17e+00)
INFO 2025-05-06 12:38:25,823 train_utils.py: 271: Train Epoch: [35][30/40] | Batch Time: 0.76 (1.08) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.64e+00 (7.25e+00)
INFO 2025-05-06 12:38:33,394 trainer.py: 950: Estimated time remaining: 00d 00h 09m
INFO 2025-05-06 12:38:33,394 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:38:33,394 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.280297029018402, 'Losses/train_all_loss_mask': 0.007986364199314266, 'Losses/train_all_loss_dice': 7.1110015392303465, 'Losses/train_all_loss_iou': 0.009562968209866084, 'Losses/train_all_loss_class': 5.293044671361713e-06, 'Losses/train_all_core_loss': 7.280297029018402, 'Trainer/where': 0.7195, 'Trainer/epoch': 35, 'Trainer/steps_train': 1440}
INFO 2025-05-06 12:38:48,572 train_utils.py: 271: Train Epoch: [36][ 0/40] | Batch Time: 11.53 (11.53) | Data Time: 10.53 (10.53) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.85e+00 (7.85e+00)
INFO 2025-05-06 12:38:56,545 train_utils.py: 271: Train Epoch: [36][10/40] | Batch Time: 0.72 (1.77) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.97e+00 (7.98e+00)
INFO 2025-05-06 12:39:04,171 train_utils.py: 271: Train Epoch: [36][20/40] | Batch Time: 0.73 (1.29) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.91e+00 (7.72e+00)
INFO 2025-05-06 12:39:11,457 train_utils.py: 271: Train Epoch: [36][30/40] | Batch Time: 0.70 (1.11) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.77e+00 (7.48e+00)
INFO 2025-05-06 12:39:18,889 trainer.py: 950: Estimated time remaining: 00d 00h 08m
INFO 2025-05-06 12:39:18,889 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:39:18,890 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.555176150798798, 'Losses/train_all_loss_mask': 0.01288242990267463, 'Losses/train_all_loss_dice': 7.274849772453308, 'Losses/train_all_loss_iou': 0.022634643933452027, 'Losses/train_all_loss_class': 4.3146945482774866e-05, 'Losses/train_all_core_loss': 7.555176150798798, 'Trainer/where': 0.7395, 'Trainer/epoch': 36, 'Trainer/steps_train': 1480}
INFO 2025-05-06 12:39:33,124 train_utils.py: 271: Train Epoch: [37][ 0/40] | Batch Time: 11.19 (11.19) | Data Time: 10.19 (10.19) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.65e+00 (6.65e+00)
INFO 2025-05-06 12:39:40,443 train_utils.py: 271: Train Epoch: [37][10/40] | Batch Time: 0.73 (1.68) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.67e+00 (7.19e+00)
INFO 2025-05-06 12:39:47,644 train_utils.py: 271: Train Epoch: [37][20/40] | Batch Time: 0.71 (1.22) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.95e+00 (7.19e+00)
INFO 2025-05-06 12:39:54,717 train_utils.py: 271: Train Epoch: [37][30/40] | Batch Time: 0.69 (1.06) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.44e+00 (7.28e+00)
INFO 2025-05-06 12:40:02,029 trainer.py: 950: Estimated time remaining: 00d 00h 07m
INFO 2025-05-06 12:40:02,030 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:40:02,030 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.376134437322617, 'Losses/train_all_loss_mask': 0.010417016674546175, 'Losses/train_all_loss_dice': 7.143240231275558, 'Losses/train_all_loss_iou': 0.024540197888381955, 'Losses/train_all_loss_class': 1.3603407724716021e-05, 'Losses/train_all_core_loss': 7.376134437322617, 'Trainer/where': 0.7595000000000001, 'Trainer/epoch': 37, 'Trainer/steps_train': 1520}
INFO 2025-05-06 12:40:16,121 train_utils.py: 271: Train Epoch: [38][ 0/40] | Batch Time: 11.07 (11.07) | Data Time: 9.95 (9.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 8.08e+00 (8.08e+00)
INFO 2025-05-06 12:40:23,350 train_utils.py: 271: Train Epoch: [38][10/40] | Batch Time: 0.72 (1.66) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.92e+00 (7.81e+00)
INFO 2025-05-06 12:40:30,519 train_utils.py: 271: Train Epoch: [38][20/40] | Batch Time: 0.68 (1.21) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.94e+00 (7.48e+00)
INFO 2025-05-06 12:40:37,622 train_utils.py: 271: Train Epoch: [38][30/40] | Batch Time: 0.69 (1.05) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.58e+00 (7.51e+00)
INFO 2025-05-06 12:40:44,734 trainer.py: 950: Estimated time remaining: 00d 00h 07m
INFO 2025-05-06 12:40:44,734 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:40:44,734 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.470002073049545, 'Losses/train_all_loss_mask': 0.011916998600645457, 'Losses/train_all_loss_dice': 7.211084812879562, 'Losses/train_all_loss_iou': 0.020568156977424222, 'Losses/train_all_loss_class': 9.049650366677042e-06, 'Losses/train_all_core_loss': 7.470002073049545, 'Trainer/where': 0.7795000000000001, 'Trainer/epoch': 38, 'Trainer/steps_train': 1560}
INFO 2025-05-06 12:40:58,444 train_utils.py: 271: Train Epoch: [39][ 0/40] | Batch Time: 10.90 (10.90) | Data Time: 9.92 (9.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 6.92e+00 (6.92e+00)
INFO 2025-05-06 12:41:05,656 train_utils.py: 271: Train Epoch: [39][10/40] | Batch Time: 0.70 (1.65) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 8.06e+00 (7.36e+00)
INFO 2025-05-06 12:41:12,751 train_utils.py: 271: Train Epoch: [39][20/40] | Batch Time: 0.74 (1.20) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.85e+00 (7.49e+00)
INFO 2025-05-06 12:41:19,910 train_utils.py: 271: Train Epoch: [39][30/40] | Batch Time: 0.74 (1.04) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.08e+00 (7.21e+00)
INFO 2025-05-06 12:41:27,177 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-05-06 12:41:27,179 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:41:27,179 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.388305974006653, 'Losses/train_all_loss_mask': 0.010740681507741101, 'Losses/train_all_loss_dice': 7.151839554309845, 'Losses/train_all_loss_iou': 0.021648986059881282, 'Losses/train_all_loss_class': 3.7947830598739073e-06, 'Losses/train_all_core_loss': 7.388305974006653, 'Trainer/where': 0.7995, 'Trainer/epoch': 39, 'Trainer/steps_train': 1600}
INFO 2025-05-06 12:41:41,374 train_utils.py: 271: Train Epoch: [40][ 0/40] | Batch Time: 11.54 (11.54) | Data Time: 10.35 (10.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.21e+00 (7.21e+00)
INFO 2025-05-06 12:41:49,342 train_utils.py: 271: Train Epoch: [40][10/40] | Batch Time: 0.81 (1.77) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 7.76e+00 (7.30e+00)
INFO 2025-05-06 12:41:57,857 train_utils.py: 271: Train Epoch: [40][20/40] | Batch Time: 0.92 (1.33) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 7.46e+00 (7.34e+00)
INFO 2025-05-06 12:42:06,219 train_utils.py: 271: Train Epoch: [40][30/40] | Batch Time: 0.92 (1.17) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 4.87e+00 (7.36e+00)
INFO 2025-05-06 12:42:15,163 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-05-06 12:42:15,164 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:42:15,164 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.396766662597656, 'Losses/train_all_loss_mask': 0.007179220429679845, 'Losses/train_all_loss_dice': 7.233652210235595, 'Losses/train_all_loss_iou': 0.019517217456177606, 'Losses/train_all_loss_class': 1.2794001144555977e-05, 'Losses/train_all_core_loss': 7.396766662597656, 'Trainer/where': 0.8195, 'Trainer/epoch': 40, 'Trainer/steps_train': 1640}
INFO 2025-05-06 12:42:35,136 train_utils.py: 271: Train Epoch: [41][ 0/40] | Batch Time: 15.64 (15.64) | Data Time: 14.54 (14.54) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 8.01e+00 (8.01e+00)
INFO 2025-05-06 12:42:43,530 train_utils.py: 271: Train Epoch: [41][10/40] | Batch Time: 0.82 (2.18) | Data Time: 0.00 (1.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 8.01e+00 (7.51e+00)
INFO 2025-05-06 12:42:51,925 train_utils.py: 271: Train Epoch: [41][20/40] | Batch Time: 0.91 (1.54) | Data Time: 0.00 (0.69) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.92e+00 (7.40e+00)
INFO 2025-05-06 12:43:00,348 train_utils.py: 271: Train Epoch: [41][30/40] | Batch Time: 0.85 (1.32) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 5.30e+00 (7.23e+00)
INFO 2025-05-06 12:43:09,392 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-05-06 12:43:09,392 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:43:09,393 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.2961758852005, 'Losses/train_all_loss_mask': 0.009207852588588139, 'Losses/train_all_loss_dice': 7.088075745105743, 'Losses/train_all_loss_iou': 0.023938872406597513, 'Losses/train_all_loss_class': 4.232779541979426e-06, 'Losses/train_all_core_loss': 7.2961758852005, 'Trainer/where': 0.8395, 'Trainer/epoch': 41, 'Trainer/steps_train': 1680}
INFO 2025-05-06 12:43:28,115 train_utils.py: 271: Train Epoch: [42][ 0/40] | Batch Time: 15.35 (15.35) | Data Time: 14.24 (14.24) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.96e+00 (7.96e+00)
INFO 2025-05-06 12:43:36,289 train_utils.py: 271: Train Epoch: [42][10/40] | Batch Time: 0.84 (2.14) | Data Time: 0.00 (1.30) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 8.03e+00 (7.01e+00)
INFO 2025-05-06 12:43:44,491 train_utils.py: 271: Train Epoch: [42][20/40] | Batch Time: 0.83 (1.51) | Data Time: 0.00 (0.68) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 6.66e+00 (7.22e+00)
INFO 2025-05-06 12:43:52,708 train_utils.py: 271: Train Epoch: [42][30/40] | Batch Time: 0.82 (1.29) | Data Time: 0.00 (0.46) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.16e+00 (7.26e+00)
INFO 2025-05-06 12:44:01,717 trainer.py: 950: Estimated time remaining: 00d 00h 05m
INFO 2025-05-06 12:44:01,718 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:44:01,718 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.185935652256012, 'Losses/train_all_loss_mask': 0.010560710517165717, 'Losses/train_all_loss_dice': 6.972957330942154, 'Losses/train_all_loss_iou': 0.0017560172489538672, 'Losses/train_all_loss_class': 8.079020137508053e-06, 'Losses/train_all_core_loss': 7.185935652256012, 'Trainer/where': 0.8595, 'Trainer/epoch': 42, 'Trainer/steps_train': 1720}
INFO 2025-05-06 12:44:22,965 train_utils.py: 271: Train Epoch: [43][ 0/40] | Batch Time: 17.12 (17.12) | Data Time: 15.94 (15.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 4.52e+00 (4.52e+00)
INFO 2025-05-06 12:44:31,092 train_utils.py: 271: Train Epoch: [43][10/40] | Batch Time: 0.83 (2.30) | Data Time: 0.00 (1.45) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.97e+00 (6.57e+00)
INFO 2025-05-06 12:44:39,482 train_utils.py: 271: Train Epoch: [43][20/40] | Batch Time: 0.76 (1.60) | Data Time: 0.00 (0.76) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.08e+00 (7.10e+00)
INFO 2025-05-06 12:44:46,814 train_utils.py: 271: Train Epoch: [43][30/40] | Batch Time: 0.74 (1.32) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.94e+00 (7.28e+00)
INFO 2025-05-06 12:44:54,849 trainer.py: 950: Estimated time remaining: 00d 00h 04m
INFO 2025-05-06 12:44:54,849 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:44:54,850 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.396651554107666, 'Losses/train_all_loss_mask': 0.008120661620341706, 'Losses/train_all_loss_dice': 7.225486719608307, 'Losses/train_all_loss_iou': 0.00874031905987067, 'Losses/train_all_loss_class': 1.1299404575737527e-05, 'Losses/train_all_core_loss': 7.396651554107666, 'Trainer/where': 0.8795000000000001, 'Trainer/epoch': 43, 'Trainer/steps_train': 1760}
INFO 2025-05-06 12:45:13,398 train_utils.py: 271: Train Epoch: [44][ 0/40] | Batch Time: 14.39 (14.39) | Data Time: 13.31 (13.31) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.69e+00 (7.69e+00)
INFO 2025-05-06 12:45:20,825 train_utils.py: 271: Train Epoch: [44][10/40] | Batch Time: 0.73 (1.98) | Data Time: 0.00 (1.21) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.93e+00 (7.56e+00)
INFO 2025-05-06 12:45:28,102 train_utils.py: 271: Train Epoch: [44][20/40] | Batch Time: 0.72 (1.39) | Data Time: 0.00 (0.63) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.92e+00 (7.46e+00)
INFO 2025-05-06 12:45:35,377 train_utils.py: 271: Train Epoch: [44][30/40] | Batch Time: 0.69 (1.17) | Data Time: 0.00 (0.43) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 8.02e+00 (7.50e+00)
INFO 2025-05-06 12:45:43,406 trainer.py: 950: Estimated time remaining: 00d 00h 03m
INFO 2025-05-06 12:45:43,407 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:45:43,407 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.375905299186707, 'Losses/train_all_loss_mask': 0.014356273831799627, 'Losses/train_all_loss_dice': 7.030859804153442, 'Losses/train_all_loss_iou': 0.05791444253891313, 'Losses/train_all_loss_class': 5.6345127084966865e-06, 'Losses/train_all_core_loss': 7.375905299186707, 'Trainer/where': 0.8995000000000001, 'Trainer/epoch': 44, 'Trainer/steps_train': 1800}
INFO 2025-05-06 12:46:01,867 train_utils.py: 271: Train Epoch: [45][ 0/40] | Batch Time: 14.94 (14.94) | Data Time: 13.89 (13.89) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 8.03e+00 (8.03e+00)
INFO 2025-05-06 12:46:09,316 train_utils.py: 271: Train Epoch: [45][10/40] | Batch Time: 0.73 (2.04) | Data Time: 0.00 (1.26) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 7.95e+00 (7.17e+00)
INFO 2025-05-06 12:46:16,749 train_utils.py: 271: Train Epoch: [45][20/40] | Batch Time: 0.72 (1.42) | Data Time: 0.00 (0.66) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 4.78e+00 (7.02e+00)
INFO 2025-05-06 12:46:23,913 train_utils.py: 271: Train Epoch: [45][30/40] | Batch Time: 0.71 (1.19) | Data Time: 0.00 (0.45) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 7.92e+00 (7.08e+00)
INFO 2025-05-06 12:46:31,770 trainer.py: 950: Estimated time remaining: 00d 00h 02m
INFO 2025-05-06 12:46:31,771 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:46:31,771 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.128007864952087, 'Losses/train_all_loss_mask': 0.008849016736348858, 'Losses/train_all_loss_dice': 6.9343440473079685, 'Losses/train_all_loss_iou': 0.016678811999554455, 'Losses/train_all_loss_class': 4.6443563348930185e-06, 'Losses/train_all_core_loss': 7.128007864952087, 'Trainer/where': 0.9195, 'Trainer/epoch': 45, 'Trainer/steps_train': 1840}
INFO 2025-05-06 12:46:47,836 train_utils.py: 271: Train Epoch: [46][ 0/40] | Batch Time: 13.22 (13.22) | Data Time: 12.13 (12.13) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 5.31e+00 (5.31e+00)
INFO 2025-05-06 12:46:55,281 train_utils.py: 271: Train Epoch: [46][10/40] | Batch Time: 0.73 (1.88) | Data Time: 0.00 (1.10) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.92e+00 (7.24e+00)
INFO 2025-05-06 12:47:02,384 train_utils.py: 271: Train Epoch: [46][20/40] | Batch Time: 0.69 (1.32) | Data Time: 0.00 (0.58) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.94e+00 (7.18e+00)
INFO 2025-05-06 12:47:09,594 train_utils.py: 271: Train Epoch: [46][30/40] | Batch Time: 0.69 (1.13) | Data Time: 0.00 (0.39) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 8.96e+00 (7.09e+00)
INFO 2025-05-06 12:47:16,833 trainer.py: 950: Estimated time remaining: 00d 00h 02m
INFO 2025-05-06 12:47:16,833 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:47:16,833 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.100126564502716, 'Losses/train_all_loss_mask': 0.01252208777004853, 'Losses/train_all_loss_dice': 6.814909541606903, 'Losses/train_all_loss_iou': 0.034760635161546816, 'Losses/train_all_loss_class': 1.46248140863392e-05, 'Losses/train_all_core_loss': 7.100126564502716, 'Trainer/where': 0.9395, 'Trainer/epoch': 46, 'Trainer/steps_train': 1880}
INFO 2025-05-06 12:47:29,940 train_utils.py: 271: Train Epoch: [47][ 0/40] | Batch Time: 11.02 (11.02) | Data Time: 9.92 (9.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.82e+00 (7.82e+00)
INFO 2025-05-06 12:47:37,088 train_utils.py: 271: Train Epoch: [47][10/40] | Batch Time: 0.72 (1.65) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 8.00e+00 (7.63e+00)
INFO 2025-05-06 12:47:44,361 train_utils.py: 271: Train Epoch: [47][20/40] | Batch Time: 0.76 (1.21) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.91e+00 (7.53e+00)
INFO 2025-05-06 12:47:52,053 train_utils.py: 271: Train Epoch: [47][30/40] | Batch Time: 0.75 (1.07) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 5.70e+00 (7.61e+00)
INFO 2025-05-06 12:47:59,667 trainer.py: 950: Estimated time remaining: 00d 00h 01m
INFO 2025-05-06 12:47:59,667 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:47:59,667 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.5116276979446415, 'Losses/train_all_loss_mask': 0.010245646073599346, 'Losses/train_all_loss_dice': 7.27198293209076, 'Losses/train_all_loss_iou': 0.03255526575649128, 'Losses/train_all_loss_class': 0.00217662357365036, 'Losses/train_all_core_loss': 7.5116276979446415, 'Trainer/where': 0.9595, 'Trainer/epoch': 47, 'Trainer/steps_train': 1920}
INFO 2025-05-06 12:48:14,241 train_utils.py: 271: Train Epoch: [48][ 0/40] | Batch Time: 12.02 (12.02) | Data Time: 10.96 (10.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 7.59e+00 (7.59e+00)
INFO 2025-05-06 12:48:21,862 train_utils.py: 271: Train Epoch: [48][10/40] | Batch Time: 0.77 (1.79) | Data Time: 0.00 (1.00) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 8.00e+00 (7.65e+00)
INFO 2025-05-06 12:48:29,273 train_utils.py: 271: Train Epoch: [48][20/40] | Batch Time: 0.76 (1.29) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 7.79e+00 (7.70e+00)
INFO 2025-05-06 12:48:37,040 train_utils.py: 271: Train Epoch: [48][30/40] | Batch Time: 0.83 (1.12) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 4.65e+00 (7.23e+00)
INFO 2025-05-06 12:48:45,510 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-05-06 12:48:45,511 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:48:45,511 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.180913537740707, 'Losses/train_all_loss_mask': 0.012643473758726032, 'Losses/train_all_loss_dice': 6.894251072406769, 'Losses/train_all_loss_iou': 0.033784508199505583, 'Losses/train_all_loss_class': 8.503132722381679e-06, 'Losses/train_all_core_loss': 7.180913537740707, 'Trainer/where': 0.9795, 'Trainer/epoch': 48, 'Trainer/steps_train': 1960}
INFO 2025-05-06 12:49:00,727 train_utils.py: 271: Train Epoch: [49][ 0/40] | Batch Time: 11.97 (11.97) | Data Time: 10.77 (10.77) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 8.04e+00 (8.04e+00)
INFO 2025-05-06 12:49:08,476 train_utils.py: 271: Train Epoch: [49][10/40] | Batch Time: 0.75 (1.79) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 7.33e+00 (7.56e+00)
INFO 2025-05-06 12:49:15,794 train_utils.py: 271: Train Epoch: [49][20/40] | Batch Time: 0.73 (1.29) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 7.15e+00 (7.15e+00)
INFO 2025-05-06 12:49:23,023 train_utils.py: 271: Train Epoch: [49][30/40] | Batch Time: 0.70 (1.11) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 5.31e+00 (6.96e+00)
INFO 2025-05-06 12:49:30,273 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-05-06 12:49:30,274 trainer.py: 892: Synchronizing meters
INFO 2025-05-06 12:49:30,274 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.011944925785064, 'Losses/train_all_loss_mask': 0.007334709151473362, 'Losses/train_all_loss_dice': 6.847940272092819, 'Losses/train_all_loss_iou': 0.01729844883830083, 'Losses/train_all_loss_class': 1.2049677670233904e-05, 'Losses/train_all_core_loss': 7.011944925785064, 'Trainer/where': 0.9995, 'Trainer/epoch': 49, 'Trainer/steps_train': 2000}
