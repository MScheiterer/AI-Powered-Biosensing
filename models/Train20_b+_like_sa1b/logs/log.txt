INFO 2025-05-18 14:18:55,616 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-05-18 14:18:55,623 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-18 14:18:55,623 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_19024_VKRQLQBKKNIFXSML
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_13032_1262719628=1
EFC_13032_1592913036=1
EFC_13032_2283032206=1
EFC_13032_2775293581=1
EFC_13032_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=2380
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=18454
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_L10N_BUNDLE_LOCATION=
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=19024
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-18 14:18:55,623 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-18 14:18:55,625 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-18 14:18:56,398 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-18 14:18:56,402 trainer.py:1059: ====================
INFO 2025-05-18 14:18:56,402 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-18 14:18:56,405 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-18 14:18:56,405 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-18 14:18:56,405 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-18 14:18:56,405 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-18 14:18:56,405 trainer.py:1069: ====================
INFO 2025-05-18 14:18:56,410 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-18 14:18:56,410 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-18 14:18:56,544 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-18 14:18:56,566 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight'}
INFO 2025-05-18 14:18:56,569 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.23.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'memory_attention.layers.1.linear1.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'memory_attention.layers.0.linear2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'memory_attention.layers.2.linear1.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'memory_attention.layers.1.norm2.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'obj_ptr_tpos_proj.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'mask_downsample.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.3.linear1.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'memory_attention.layers.3.norm1.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.0.norm2.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'memory_attention.norm.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'memory_attention.layers.3.norm3.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'obj_ptr_proj.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_attention.layers.2.linear2.bias', 'memory_attention.layers.1.linear2.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias'}
INFO 2025-05-18 14:18:56,569 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.1.norm1.weight', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'memory_attention.norm.weight', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'memory_attention.layers.3.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'memory_attention.norm.bias', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'memory_attention.layers.0.norm1.bias', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'memory_attention.layers.3.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias'} 
INFO 2025-05-18 14:18:58,265 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-18 14:18:58,504 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': '../checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-05-18 14:19:15,719 train_utils.py: 271: Train Epoch: [0][ 0/20] | Batch Time: 17.01 (17.01) | Data Time: 10.41 (10.41) | Mem (GB): 13.00 (13.00/13.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.82e+00 (1.82e+00)
INFO 2025-05-18 14:19:55,733 train_utils.py: 271: Train Epoch: [0][10/20] | Batch Time: 3.41 (5.18) | Data Time: 0.00 (0.95) | Mem (GB): 14.00 (13.91/14.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.97e+00 (1.58e+00)
INFO 2025-05-18 14:20:26,120 trainer.py: 950: Estimated time remaining: 00d 01h 10m
INFO 2025-05-18 14:20:26,120 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 14:20:26,121 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3581043601036071, 'Losses/train_all_loss_mask': 0.004465097931097261, 'Losses/train_all_loss_dice': 0.7731039687991142, 'Losses/train_all_loss_iou': 0.49569508209824564, 'Losses/train_all_loss_class': 3.3696974011121483e-06, 'Losses/train_all_core_loss': 1.3581043601036071, 'Trainer/where': 0.019, 'Trainer/epoch': 0, 'Trainer/steps_train': 20}
INFO 2025-05-18 14:20:42,971 train_utils.py: 271: Train Epoch: [1][ 0/20] | Batch Time: 14.65 (14.65) | Data Time: 11.59 (11.59) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.22e+00 (1.22e+00)
INFO 2025-05-18 14:21:10,255 train_utils.py: 271: Train Epoch: [1][10/20] | Batch Time: 2.80 (3.81) | Data Time: 0.00 (1.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 7.58e-01 (9.19e-01)
INFO 2025-05-18 14:21:35,016 trainer.py: 950: Estimated time remaining: 00d 00h 52m
INFO 2025-05-18 14:21:35,017 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 14:21:35,017 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.944642522931099, 'Losses/train_all_loss_mask': 0.0025581524590961636, 'Losses/train_all_loss_dice': 0.6057858824729919, 'Losses/train_all_loss_iou': 0.2876935161650181, 'Losses/train_all_loss_class': 6.824120730719585e-08, 'Losses/train_all_core_loss': 0.944642522931099, 'Trainer/where': 0.039, 'Trainer/epoch': 1, 'Trainer/steps_train': 40}
INFO 2025-05-18 14:21:50,144 train_utils.py: 271: Train Epoch: [2][ 0/20] | Batch Time: 12.89 (12.89) | Data Time: 9.70 (9.70) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 5.09e-01 (5.09e-01)
INFO 2025-05-18 14:22:16,832 train_utils.py: 271: Train Epoch: [2][10/20] | Batch Time: 2.60 (3.60) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.11e+00 (8.45e-01)
INFO 2025-05-18 14:22:41,473 trainer.py: 950: Estimated time remaining: 00d 00h 49m
INFO 2025-05-18 14:22:41,474 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 14:22:41,474 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.895882323384285, 'Losses/train_all_loss_mask': 0.0014082690264331176, 'Losses/train_all_loss_dice': 0.5810605868697166, 'Losses/train_all_loss_iou': 0.28665627986192704, 'Losses/train_all_loss_class': 7.493587101947697e-08, 'Losses/train_all_core_loss': 0.895882323384285, 'Trainer/where': 0.059000000000000004, 'Trainer/epoch': 2, 'Trainer/steps_train': 60}
INFO 2025-05-18 14:22:56,168 train_utils.py: 271: Train Epoch: [3][ 0/20] | Batch Time: 12.58 (12.58) | Data Time: 9.62 (9.62) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 7.35e-01 (7.35e-01)
INFO 2025-05-18 14:23:24,227 train_utils.py: 271: Train Epoch: [3][10/20] | Batch Time: 2.87 (3.69) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.16e-01 (8.22e-01)
INFO 2025-05-18 14:24:00,159 trainer.py: 950: Estimated time remaining: 00d 00h 57m
INFO 2025-05-18 14:24:00,159 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 14:24:00,159 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.795666691660881, 'Losses/train_all_loss_mask': 0.0010784447629703208, 'Losses/train_all_loss_dice': 0.5162254646420479, 'Losses/train_all_loss_iou': 0.25787232145667077, 'Losses/train_all_loss_class': 2.7327298801615996e-08, 'Losses/train_all_core_loss': 0.795666691660881, 'Trainer/where': 0.079, 'Trainer/epoch': 3, 'Trainer/steps_train': 80}
INFO 2025-05-18 14:24:18,081 train_utils.py: 271: Train Epoch: [4][ 0/20] | Batch Time: 15.55 (15.55) | Data Time: 11.51 (11.51) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 6.57e-01 (6.57e-01)
INFO 2025-05-18 14:25:03,909 train_utils.py: 271: Train Epoch: [4][10/20] | Batch Time: 7.32 (5.58) | Data Time: 0.00 (1.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 6.10e-01 (8.66e-01)
INFO 2025-05-18 14:26:02,032 trainer.py: 950: Estimated time remaining: 00d 01h 28m
INFO 2025-05-18 14:26:02,032 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 14:26:02,033 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.8033390432596207, 'Losses/train_all_loss_mask': 0.001310754133737646, 'Losses/train_all_loss_dice': 0.5107403799891472, 'Losses/train_all_loss_iou': 0.26638357788324357, 'Losses/train_all_loss_class': 1.0734202671169868e-08, 'Losses/train_all_core_loss': 0.8033390432596207, 'Trainer/where': 0.099, 'Trainer/epoch': 4, 'Trainer/steps_train': 100}
INFO 2025-05-18 16:06:09,563 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-05-18 16:06:09,575 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-18 16:06:09,575 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_15764_TXCIXPLKEUKYOVJS
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_13032_1262719628=1
EFC_13032_1592913036=1
EFC_13032_2283032206=1
EFC_13032_2775293581=1
EFC_13032_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=1644
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=49409
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_L10N_BUNDLE_LOCATION=
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=15764
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-18 16:06:09,576 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-18 16:06:09,577 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-18 16:06:10,803 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-18 16:06:10,810 trainer.py:1059: ====================
INFO 2025-05-18 16:06:10,810 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-18 16:06:10,815 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-18 16:06:10,816 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-18 16:06:10,816 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-18 16:06:10,818 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-18 16:06:10,818 trainer.py:1069: ====================
INFO 2025-05-18 16:06:10,823 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-18 16:06:10,823 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-18 16:06:10,945 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-18 16:06:10,973 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias'}
INFO 2025-05-18 16:06:10,976 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'memory_attention.norm.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'memory_attention.layers.2.norm2.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'obj_ptr_proj.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'memory_attention.layers.3.linear2.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'memory_attention.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.1.linear1.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'obj_ptr_proj.layers.1.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'obj_ptr_tpos_proj.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'memory_encoder.out_proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'memory_attention.layers.2.norm3.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'memory_attention.layers.1.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.neck.convs.1.conv.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_attention.layers.0.linear2.bias'}
INFO 2025-05-18 16:06:10,977 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'memory_attention.layers.3.norm3.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'memory_attention.layers.2.norm2.weight', 'memory_attention.layers.0.norm1.bias', 'memory_attention.layers.1.norm3.weight', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'memory_attention.layers.1.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.layers.2.norm3.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'memory_attention.layers.3.norm3.bias'} 
INFO 2025-05-18 16:06:13,173 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-18 16:06:13,177 trainer.py: 423: Resuming training from C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/checkpoints\checkpoint.pt
INFO 2025-05-18 16:07:01,973 train_utils.py: 271: Train Epoch: [5][ 0/20] | Batch Time: 46.23 (46.23) | Data Time: 10.40 (10.40) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.00e-01 (8.00e-01)
INFO 2025-05-18 16:07:54,688 train_utils.py: 271: Train Epoch: [5][10/20] | Batch Time: 2.76 (9.00) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 1.05e+00 (7.64e-01)
INFO 2025-05-18 16:08:28,258 trainer.py: 950: Estimated time remaining: 00d 01h 35m
INFO 2025-05-18 16:08:28,262 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:08:28,263 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.75414177775383, 'Losses/train_all_loss_mask': 0.0009410346887307241, 'Losses/train_all_loss_dice': 0.4972305029630661, 'Losses/train_all_loss_iou': 0.23809057772159575, 'Losses/train_all_loss_class': 2.0330845162952472e-08, 'Losses/train_all_core_loss': 0.75414177775383, 'Trainer/where': 0.11900000000000001, 'Trainer/epoch': 5, 'Trainer/steps_train': 120}
INFO 2025-05-18 16:08:50,413 train_utils.py: 271: Train Epoch: [6][ 0/20] | Batch Time: 18.01 (18.01) | Data Time: 14.96 (14.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 9.30e-01 (9.30e-01)
INFO 2025-05-18 16:09:25,952 train_utils.py: 271: Train Epoch: [6][10/20] | Batch Time: 3.88 (4.87) | Data Time: 0.00 (1.36) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 6.88e-01 (8.40e-01)
INFO 2025-05-18 16:09:55,483 trainer.py: 950: Estimated time remaining: 00d 00h 58m
INFO 2025-05-18 16:09:55,483 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:09:55,483 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7601415485143661, 'Losses/train_all_loss_mask': 0.0011327502405038103, 'Losses/train_all_loss_dice': 0.49790665656328204, 'Losses/train_all_loss_iou': 0.2395798671990633, 'Losses/train_all_loss_class': 3.961233160376665e-08, 'Losses/train_all_core_loss': 0.7601415485143661, 'Trainer/where': 0.139, 'Trainer/epoch': 6, 'Trainer/steps_train': 140}
INFO 2025-05-18 16:10:12,674 train_utils.py: 271: Train Epoch: [7][ 0/20] | Batch Time: 14.31 (14.31) | Data Time: 9.88 (9.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 6.92e-01 (6.92e-01)
INFO 2025-05-18 16:10:44,359 train_utils.py: 271: Train Epoch: [7][10/20] | Batch Time: 2.64 (4.18) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.17e-01 (7.20e-01)
INFO 2025-05-18 16:11:16,312 trainer.py: 950: Estimated time remaining: 00d 00h 53m
INFO 2025-05-18 16:11:16,313 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:11:16,313 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7129025369882583, 'Losses/train_all_loss_mask': 0.0008536080888006837, 'Losses/train_all_loss_dice': 0.4700075164437294, 'Losses/train_all_loss_iou': 0.22582285702228547, 'Losses/train_all_loss_class': 1.0174418196839952e-08, 'Losses/train_all_core_loss': 0.7129025369882583, 'Trainer/where': 0.159, 'Trainer/epoch': 7, 'Trainer/steps_train': 160}
INFO 2025-05-18 16:11:32,963 train_utils.py: 271: Train Epoch: [8][ 0/20] | Batch Time: 13.65 (13.65) | Data Time: 10.21 (10.21) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 7.80e-01 (7.80e-01)
INFO 2025-05-18 16:12:05,928 train_utils.py: 271: Train Epoch: [8][10/20] | Batch Time: 2.64 (4.24) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.35e-01 (6.90e-01)
INFO 2025-05-18 16:12:32,948 trainer.py: 950: Estimated time remaining: 00d 00h 49m
INFO 2025-05-18 16:12:32,948 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:12:32,948 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7304491490125656, 'Losses/train_all_loss_mask': 0.0009463616865104995, 'Losses/train_all_loss_dice': 0.4741886854171753, 'Losses/train_all_loss_iou': 0.23733323067426682, 'Losses/train_all_loss_class': 7.733394491449274e-09, 'Losses/train_all_core_loss': 0.7304491490125656, 'Trainer/where': 0.179, 'Trainer/epoch': 8, 'Trainer/steps_train': 180}
INFO 2025-05-18 16:12:50,229 train_utils.py: 271: Train Epoch: [9][ 0/20] | Batch Time: 14.44 (14.44) | Data Time: 10.08 (10.08) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 6.70e-01 (6.70e-01)
INFO 2025-05-18 16:13:23,165 train_utils.py: 271: Train Epoch: [9][10/20] | Batch Time: 3.95 (4.31) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 5.10e-01 (7.12e-01)
INFO 2025-05-18 16:13:53,993 trainer.py: 950: Estimated time remaining: 00d 00h 51m
INFO 2025-05-18 16:13:53,994 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:13:53,994 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7267847657203674, 'Losses/train_all_loss_mask': 0.0008299992070533336, 'Losses/train_all_loss_dice': 0.4733931705355644, 'Losses/train_all_loss_iou': 0.23679161444306374, 'Losses/train_all_loss_class': 9.527787159235857e-09, 'Losses/train_all_core_loss': 0.7267847657203674, 'Trainer/where': 0.19899999999999998, 'Trainer/epoch': 9, 'Trainer/steps_train': 200}
INFO 2025-05-18 16:14:10,604 train_utils.py: 271: Train Epoch: [10][ 0/20] | Batch Time: 14.57 (14.57) | Data Time: 10.27 (10.27) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 5.34e-01 (5.34e-01)
INFO 2025-05-18 16:14:38,688 train_utils.py: 271: Train Epoch: [10][10/20] | Batch Time: 2.64 (3.88) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 7.80e-01 (7.42e-01)
INFO 2025-05-18 16:15:13,409 trainer.py: 950: Estimated time remaining: 00d 00h 49m
INFO 2025-05-18 16:15:13,409 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:15:13,410 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.698139664530754, 'Losses/train_all_loss_mask': 0.0008344885631231591, 'Losses/train_all_loss_dice': 0.46355583518743515, 'Losses/train_all_loss_iou': 0.2178940460085869, 'Losses/train_all_loss_class': 7.88856666655846e-09, 'Losses/train_all_core_loss': 0.698139664530754, 'Trainer/where': 0.21899999999999997, 'Trainer/epoch': 10, 'Trainer/steps_train': 220}
INFO 2025-05-18 16:15:30,106 train_utils.py: 271: Train Epoch: [11][ 0/20] | Batch Time: 13.81 (13.81) | Data Time: 10.67 (10.67) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 8.61e-01 (8.61e-01)
INFO 2025-05-18 16:16:03,042 train_utils.py: 271: Train Epoch: [11][10/20] | Batch Time: 2.65 (4.25) | Data Time: 0.00 (0.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 8.45e-01 (6.92e-01)
INFO 2025-05-18 16:16:35,489 trainer.py: 950: Estimated time remaining: 00d 00h 49m
INFO 2025-05-18 16:16:35,490 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:16:35,490 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7158972412347794, 'Losses/train_all_loss_mask': 0.0008229054365074262, 'Losses/train_all_loss_dice': 0.47536845207214357, 'Losses/train_all_loss_iou': 0.22407068088650703, 'Losses/train_all_loss_class': 1.0451664089750068e-08, 'Losses/train_all_core_loss': 0.7158972412347794, 'Trainer/where': 0.239, 'Trainer/epoch': 11, 'Trainer/steps_train': 240}
INFO 2025-05-18 16:16:53,054 train_utils.py: 271: Train Epoch: [12][ 0/20] | Batch Time: 14.63 (14.63) | Data Time: 10.11 (10.11) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 7.09e-01 (7.09e-01)
INFO 2025-05-18 16:17:24,794 train_utils.py: 271: Train Epoch: [12][10/20] | Batch Time: 2.65 (4.22) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 7.05e-01 (6.84e-01)
INFO 2025-05-18 16:17:56,958 trainer.py: 950: Estimated time remaining: 00d 00h 47m
INFO 2025-05-18 16:17:56,959 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:17:56,959 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7004300624132156, 'Losses/train_all_loss_mask': 0.0008757485411479138, 'Losses/train_all_loss_dice': 0.45658171474933623, 'Losses/train_all_loss_iou': 0.2263333797454834, 'Losses/train_all_loss_class': 9.98001151719663e-09, 'Losses/train_all_core_loss': 0.7004300624132156, 'Trainer/where': 0.259, 'Trainer/epoch': 12, 'Trainer/steps_train': 260}
INFO 2025-05-18 16:18:14,564 train_utils.py: 271: Train Epoch: [13][ 0/20] | Batch Time: 14.89 (14.89) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 6.60e-01 (6.60e-01)
INFO 2025-05-18 16:18:43,848 train_utils.py: 271: Train Epoch: [13][10/20] | Batch Time: 3.96 (4.02) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 5.69e-01 (7.98e-01)
INFO 2025-05-18 16:19:10,959 trainer.py: 950: Estimated time remaining: 00d 00h 42m
INFO 2025-05-18 16:19:10,959 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:19:10,959 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.8252832949161529, 'Losses/train_all_loss_mask': 0.0009443573770113289, 'Losses/train_all_loss_dice': 0.5424398049712181, 'Losses/train_all_loss_iou': 0.2639563225209713, 'Losses/train_all_loss_class': 1.9833254816248314e-08, 'Losses/train_all_core_loss': 0.8252832949161529, 'Trainer/where': 0.27899999999999997, 'Trainer/epoch': 13, 'Trainer/steps_train': 280}
INFO 2025-05-18 16:19:26,261 train_utils.py: 271: Train Epoch: [14][ 0/20] | Batch Time: 12.89 (12.89) | Data Time: 9.73 (9.73) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 5.57e-01 (5.57e-01)
INFO 2025-05-18 16:19:58,729 train_utils.py: 271: Train Epoch: [14][10/20] | Batch Time: 4.01 (4.12) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 6.25e-01 (7.55e-01)
INFO 2025-05-18 16:20:31,051 trainer.py: 950: Estimated time remaining: 00d 00h 44m
INFO 2025-05-18 16:20:31,051 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:20:31,051 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.8054437220096589, 'Losses/train_all_loss_mask': 0.0012034709798172116, 'Losses/train_all_loss_dice': 0.5320103242993355, 'Losses/train_all_loss_iou': 0.24936364889144896, 'Losses/train_all_loss_class': 3.467609805074545e-07, 'Losses/train_all_core_loss': 0.8054437220096589, 'Trainer/where': 0.299, 'Trainer/epoch': 14, 'Trainer/steps_train': 300}
INFO 2025-05-18 16:20:53,778 train_utils.py: 271: Train Epoch: [15][ 0/20] | Batch Time: 20.01 (20.01) | Data Time: 16.87 (16.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 5.78e-01 (5.78e-01)
INFO 2025-05-18 16:21:25,400 train_utils.py: 271: Train Epoch: [15][10/20] | Batch Time: 2.64 (4.69) | Data Time: 0.00 (1.53) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 8.41e-01 (7.05e-01)
INFO 2025-05-18 16:21:52,372 trainer.py: 950: Estimated time remaining: 00d 00h 44m
INFO 2025-05-18 16:21:52,373 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:21:52,373 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7570123389363289, 'Losses/train_all_loss_mask': 0.0008675357035826892, 'Losses/train_all_loss_dice': 0.5011577874422073, 'Losses/train_all_loss_iou': 0.23850377798080444, 'Losses/train_all_loss_class': 6.691482885567979e-08, 'Losses/train_all_core_loss': 0.7570123389363289, 'Trainer/where': 0.319, 'Trainer/epoch': 15, 'Trainer/steps_train': 320}
INFO 2025-05-18 16:22:09,659 train_utils.py: 271: Train Epoch: [16][ 0/20] | Batch Time: 14.36 (14.36) | Data Time: 10.01 (10.01) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 6.36e-01 (6.36e-01)
INFO 2025-05-18 16:22:41,520 train_utils.py: 271: Train Epoch: [16][10/20] | Batch Time: 3.93 (4.20) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 5.70e-01 (6.82e-01)
INFO 2025-05-18 16:23:12,377 trainer.py: 950: Estimated time remaining: 00d 00h 41m
INFO 2025-05-18 16:23:12,377 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:23:12,378 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6985764846205711, 'Losses/train_all_loss_mask': 0.0007935056040878407, 'Losses/train_all_loss_dice': 0.4638066291809082, 'Losses/train_all_loss_iou': 0.21889974661171435, 'Losses/train_all_loss_class': 1.2080961886429265e-08, 'Losses/train_all_core_loss': 0.6985764846205711, 'Trainer/where': 0.33899999999999997, 'Trainer/epoch': 16, 'Trainer/steps_train': 340}
INFO 2025-05-18 16:23:30,327 train_utils.py: 271: Train Epoch: [17][ 0/20] | Batch Time: 14.40 (14.40) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 8.46e-01 (8.46e-01)
INFO 2025-05-18 16:24:01,999 train_utils.py: 271: Train Epoch: [17][10/20] | Batch Time: 2.65 (4.19) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 5.92e-01 (7.38e-01)
INFO 2025-05-18 16:24:30,668 trainer.py: 950: Estimated time remaining: 00d 00h 39m
INFO 2025-05-18 16:24:30,668 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:24:30,668 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7295695513486862, 'Losses/train_all_loss_mask': 0.0007595621660584584, 'Losses/train_all_loss_dice': 0.4900748491287231, 'Losses/train_all_loss_iou': 0.2243034578859806, 'Losses/train_all_loss_class': 8.540326634776108e-09, 'Losses/train_all_core_loss': 0.7295695513486862, 'Trainer/where': 0.359, 'Trainer/epoch': 17, 'Trainer/steps_train': 360}
INFO 2025-05-18 16:24:47,041 train_utils.py: 271: Train Epoch: [18][ 0/20] | Batch Time: 14.28 (14.28) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 5.53e-01 (5.53e-01)
INFO 2025-05-18 16:25:17,368 train_utils.py: 271: Train Epoch: [18][10/20] | Batch Time: 2.68 (4.06) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 1.09e+00 (7.26e-01)
INFO 2025-05-18 16:25:48,169 trainer.py: 950: Estimated time remaining: 00d 00h 38m
INFO 2025-05-18 16:25:48,170 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:25:48,170 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.701656985282898, 'Losses/train_all_loss_mask': 0.0008296341024106368, 'Losses/train_all_loss_dice': 0.45432152301073075, 'Losses/train_all_loss_iou': 0.23074278607964516, 'Losses/train_all_loss_class': 7.585553496447517e-09, 'Losses/train_all_core_loss': 0.701656985282898, 'Trainer/where': 0.379, 'Trainer/epoch': 18, 'Trainer/steps_train': 380}
INFO 2025-05-18 16:26:05,274 train_utils.py: 271: Train Epoch: [19][ 0/20] | Batch Time: 14.23 (14.23) | Data Time: 10.86 (10.86) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 6.77e-01 (6.77e-01)
INFO 2025-05-18 16:26:43,344 train_utils.py: 271: Train Epoch: [19][10/20] | Batch Time: 2.93 (4.75) | Data Time: 0.00 (0.99) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.58e-01 (7.58e-01)
INFO 2025-05-18 16:27:13,662 trainer.py: 950: Estimated time remaining: 00d 00h 40m
INFO 2025-05-18 16:27:13,663 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:27:13,663 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7532160162925721, 'Losses/train_all_loss_mask': 0.0009334091344499029, 'Losses/train_all_loss_dice': 0.4878126114606857, 'Losses/train_all_loss_iou': 0.24673522636294365, 'Losses/train_all_loss_class': 1.2957268336055705e-08, 'Losses/train_all_core_loss': 0.7532160162925721, 'Trainer/where': 0.39899999999999997, 'Trainer/epoch': 19, 'Trainer/steps_train': 400}
INFO 2025-05-18 16:27:30,446 train_utils.py: 271: Train Epoch: [20][ 0/20] | Batch Time: 13.80 (13.80) | Data Time: 10.28 (10.28) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.72e-01 (7.72e-01)
INFO 2025-05-18 16:28:07,362 train_utils.py: 271: Train Epoch: [20][10/20] | Batch Time: 4.42 (4.61) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 6.75e-01 (6.62e-01)
INFO 2025-05-18 16:28:41,921 trainer.py: 950: Estimated time remaining: 00d 00h 40m
INFO 2025-05-18 16:28:41,922 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:28:41,922 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7381287962198257, 'Losses/train_all_loss_mask': 0.0009208213246893138, 'Losses/train_all_loss_dice': 0.48551505953073504, 'Losses/train_all_loss_iou': 0.234197261929512, 'Losses/train_all_loss_class': 6.158537635414518e-08, 'Losses/train_all_core_loss': 0.7381287962198257, 'Trainer/where': 0.419, 'Trainer/epoch': 20, 'Trainer/steps_train': 420}
INFO 2025-05-18 16:29:00,014 train_utils.py: 271: Train Epoch: [21][ 0/20] | Batch Time: 15.12 (15.12) | Data Time: 10.38 (10.38) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 6.82e-01 (6.82e-01)
INFO 2025-05-18 16:29:36,800 train_utils.py: 271: Train Epoch: [21][10/20] | Batch Time: 2.98 (4.72) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 1.28e+00 (7.31e-01)
INFO 2025-05-18 16:30:08,618 trainer.py: 950: Estimated time remaining: 00d 00h 38m
INFO 2025-05-18 16:30:08,619 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:30:08,619 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.710495439171791, 'Losses/train_all_loss_mask': 0.0008692318413523025, 'Losses/train_all_loss_dice': 0.4680962562561035, 'Losses/train_all_loss_iou': 0.22501450628042222, 'Losses/train_all_loss_class': 4.0526765221482464e-08, 'Losses/train_all_core_loss': 0.710495439171791, 'Trainer/where': 0.439, 'Trainer/epoch': 21, 'Trainer/steps_train': 440}
INFO 2025-05-18 16:30:26,996 train_utils.py: 271: Train Epoch: [22][ 0/20] | Batch Time: 15.56 (15.56) | Data Time: 10.56 (10.56) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 5.17e-01 (5.17e-01)
INFO 2025-05-18 16:31:06,161 train_utils.py: 271: Train Epoch: [22][10/20] | Batch Time: 3.08 (4.98) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.93e-01 (6.68e-01)
INFO 2025-05-18 16:31:39,026 trainer.py: 950: Estimated time remaining: 00d 00h 38m
INFO 2025-05-18 16:31:39,026 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:31:39,026 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7216467022895813, 'Losses/train_all_loss_mask': 0.0008597903768531978, 'Losses/train_all_loss_dice': 0.47680587470531466, 'Losses/train_all_loss_iou': 0.22764501422643663, 'Losses/train_all_loss_class': 1.1317800530097344e-08, 'Losses/train_all_core_loss': 0.7216467022895813, 'Trainer/where': 0.45899999999999996, 'Trainer/epoch': 22, 'Trainer/steps_train': 460}
INFO 2025-05-18 16:31:59,143 train_utils.py: 271: Train Epoch: [23][ 0/20] | Batch Time: 17.70 (17.70) | Data Time: 14.13 (14.13) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.23e-01 (7.23e-01)
INFO 2025-05-18 16:32:32,468 train_utils.py: 271: Train Epoch: [23][10/20] | Batch Time: 4.37 (4.64) | Data Time: 0.00 (1.28) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 6.96e-01 (7.57e-01)
INFO 2025-05-18 16:33:03,976 trainer.py: 950: Estimated time remaining: 00d 00h 35m
INFO 2025-05-18 16:33:03,977 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:33:03,977 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7968071341514588, 'Losses/train_all_loss_mask': 0.0021553378144744785, 'Losses/train_all_loss_dice': 0.5118285834789276, 'Losses/train_all_loss_iou': 0.24187179952859877, 'Losses/train_all_loss_class': 1.7127682827577928e-08, 'Losses/train_all_core_loss': 0.7968071341514588, 'Trainer/where': 0.479, 'Trainer/epoch': 23, 'Trainer/steps_train': 480}
INFO 2025-05-18 16:33:21,843 train_utils.py: 271: Train Epoch: [24][ 0/20] | Batch Time: 15.00 (15.00) | Data Time: 10.28 (10.28) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.55e-01 (7.55e-01)
INFO 2025-05-18 16:33:56,438 train_utils.py: 271: Train Epoch: [24][10/20] | Batch Time: 2.99 (4.51) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.22e-01 (7.11e-01)
INFO 2025-05-18 16:34:29,321 trainer.py: 950: Estimated time remaining: 00d 00h 34m
INFO 2025-05-18 16:34:29,322 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:34:29,322 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7218589007854461, 'Losses/train_all_loss_mask': 0.0008301420006318949, 'Losses/train_all_loss_dice': 0.4755282372236252, 'Losses/train_all_loss_iou': 0.22972782030701638, 'Losses/train_all_loss_class': 1.1151448631174787e-08, 'Losses/train_all_core_loss': 0.7218589007854461, 'Trainer/where': 0.499, 'Trainer/epoch': 24, 'Trainer/steps_train': 500}
INFO 2025-05-18 16:34:47,445 train_utils.py: 271: Train Epoch: [25][ 0/20] | Batch Time: 15.32 (15.32) | Data Time: 10.54 (10.54) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 5.46e-01 (5.46e-01)
INFO 2025-05-18 16:35:25,883 train_utils.py: 271: Train Epoch: [25][10/20] | Batch Time: 3.00 (4.89) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.66e-01 (6.46e-01)
INFO 2025-05-18 16:35:58,492 trainer.py: 950: Estimated time remaining: 00d 00h 34m
INFO 2025-05-18 16:35:58,493 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:35:58,493 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7025867357850075, 'Losses/train_all_loss_mask': 0.000775157344469335, 'Losses/train_all_loss_dice': 0.4574969232082367, 'Losses/train_all_loss_iou': 0.2295866549015045, 'Losses/train_all_loss_class': 1.1164084900983085e-08, 'Losses/train_all_core_loss': 0.7025867357850075, 'Trainer/where': 0.519, 'Trainer/epoch': 25, 'Trainer/steps_train': 520}
INFO 2025-05-18 16:36:15,260 train_utils.py: 271: Train Epoch: [26][ 0/20] | Batch Time: 13.80 (13.80) | Data Time: 10.36 (10.36) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 5.90e-01 (5.90e-01)
INFO 2025-05-18 16:36:54,381 train_utils.py: 271: Train Epoch: [26][10/20] | Batch Time: 4.35 (4.81) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 5.20e-01 (6.23e-01)
INFO 2025-05-18 16:37:25,796 trainer.py: 950: Estimated time remaining: 00d 00h 31m
INFO 2025-05-18 16:37:25,796 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:37:25,797 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6810559466481209, 'Losses/train_all_loss_mask': 0.000819788321678061, 'Losses/train_all_loss_dice': 0.4533159852027893, 'Losses/train_all_loss_iou': 0.21134419478476046, 'Losses/train_all_loss_class': 1.2034713881003967e-08, 'Losses/train_all_core_loss': 0.6810559466481209, 'Trainer/where': 0.539, 'Trainer/epoch': 26, 'Trainer/steps_train': 540}
INFO 2025-05-18 16:37:43,184 train_utils.py: 271: Train Epoch: [27][ 0/20] | Batch Time: 15.11 (15.11) | Data Time: 10.42 (10.42) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 9.50e-01 (9.50e-01)
INFO 2025-05-18 16:38:17,322 train_utils.py: 271: Train Epoch: [27][10/20] | Batch Time: 2.97 (4.48) | Data Time: 0.00 (0.95) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 39m | Losses/train_all_loss: 1.06e+00 (7.19e-01)
INFO 2025-05-18 16:38:51,737 trainer.py: 950: Estimated time remaining: 00d 00h 30m
INFO 2025-05-18 16:38:51,738 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:38:51,738 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7004286080598832, 'Losses/train_all_loss_mask': 0.0007707983822911046, 'Losses/train_all_loss_dice': 0.468949656188488, 'Losses/train_all_loss_iou': 0.21606297567486762, 'Losses/train_all_loss_class': 1.2760933443267675e-08, 'Losses/train_all_core_loss': 0.7004286080598832, 'Trainer/where': 0.5589999999999999, 'Trainer/epoch': 27, 'Trainer/steps_train': 560}
INFO 2025-05-18 16:39:07,537 train_utils.py: 271: Train Epoch: [28][ 0/20] | Batch Time: 13.58 (13.58) | Data Time: 10.33 (10.33) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 5.36e-01 (5.36e-01)
INFO 2025-05-18 16:39:45,696 train_utils.py: 271: Train Epoch: [28][10/20] | Batch Time: 4.40 (4.70) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 6.33e-01 (6.69e-01)
INFO 2025-05-18 16:40:18,700 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-05-18 16:40:18,700 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:40:18,700 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7120106741786003, 'Losses/train_all_loss_mask': 0.0007901794495410285, 'Losses/train_all_loss_dice': 0.46247063130140303, 'Losses/train_all_loss_iou': 0.23373643904924393, 'Losses/train_all_loss_class': 1.3399891007903619e-08, 'Losses/train_all_core_loss': 0.7120106741786003, 'Trainer/where': 0.579, 'Trainer/epoch': 28, 'Trainer/steps_train': 580}
INFO 2025-05-18 16:40:34,757 train_utils.py: 271: Train Epoch: [29][ 0/20] | Batch Time: 13.85 (13.85) | Data Time: 10.38 (10.38) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 7.29e-01 (7.29e-01)
INFO 2025-05-18 16:41:13,223 train_utils.py: 271: Train Epoch: [29][10/20] | Batch Time: 4.36 (4.76) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 8.40e-01 (6.65e-01)
INFO 2025-05-18 16:41:51,969 trainer.py: 950: Estimated time remaining: 00d 00h 30m
INFO 2025-05-18 16:41:51,970 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:41:51,970 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6299050852656365, 'Losses/train_all_loss_mask': 0.0007567143009509891, 'Losses/train_all_loss_dice': 0.42337383329868317, 'Losses/train_all_loss_iou': 0.19139695316553115, 'Losses/train_all_loss_class': 1.5237486161723268e-08, 'Losses/train_all_core_loss': 0.6299050852656365, 'Trainer/where': 0.599, 'Trainer/epoch': 29, 'Trainer/steps_train': 600}
INFO 2025-05-18 16:42:09,472 train_utils.py: 271: Train Epoch: [30][ 0/20] | Batch Time: 15.21 (15.21) | Data Time: 10.39 (10.39) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 4.41e-01 (4.41e-01)
INFO 2025-05-18 16:42:46,422 train_utils.py: 271: Train Epoch: [30][10/20] | Batch Time: 4.41 (4.74) | Data Time: 0.00 (0.95) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 6.18e-01 (6.63e-01)
INFO 2025-05-18 16:43:22,313 trainer.py: 950: Estimated time remaining: 00d 00h 27m
INFO 2025-05-18 16:43:22,313 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:43:22,313 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6696704342961312, 'Losses/train_all_loss_mask': 0.000741792275221087, 'Losses/train_all_loss_dice': 0.44487989544868467, 'Losses/train_all_loss_iou': 0.2099546879529953, 'Losses/train_all_loss_class': 1.3339172100224062e-08, 'Losses/train_all_core_loss': 0.6696704342961312, 'Trainer/where': 0.619, 'Trainer/epoch': 30, 'Trainer/steps_train': 620}
INFO 2025-05-18 16:43:39,899 train_utils.py: 271: Train Epoch: [31][ 0/20] | Batch Time: 15.19 (15.19) | Data Time: 10.39 (10.39) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 7.12e-01 (7.12e-01)
INFO 2025-05-18 16:44:16,829 train_utils.py: 271: Train Epoch: [31][10/20] | Batch Time: 4.37 (4.74) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 7.06e-01 (7.07e-01)
INFO 2025-05-18 16:44:51,613 trainer.py: 950: Estimated time remaining: 00d 00h 25m
INFO 2025-05-18 16:44:51,614 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:44:51,614 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7201479732990265, 'Losses/train_all_loss_mask': 0.000869124531163834, 'Losses/train_all_loss_dice': 0.4597697302699089, 'Losses/train_all_loss_iou': 0.24299575313925742, 'Losses/train_all_loss_class': 1.4734798114979241e-08, 'Losses/train_all_core_loss': 0.7201479732990265, 'Trainer/where': 0.639, 'Trainer/epoch': 31, 'Trainer/steps_train': 640}
INFO 2025-05-18 16:45:08,498 train_utils.py: 271: Train Epoch: [32][ 0/20] | Batch Time: 14.16 (14.16) | Data Time: 10.72 (10.72) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 5.95e-01 (5.95e-01)
INFO 2025-05-18 16:45:45,455 train_utils.py: 271: Train Epoch: [32][10/20] | Batch Time: 3.03 (4.65) | Data Time: 0.00 (0.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 9.10e-01 (6.42e-01)
INFO 2025-05-18 16:46:21,149 trainer.py: 950: Estimated time remaining: 00d 00h 24m
INFO 2025-05-18 16:46:21,150 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:46:21,150 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6346248492598534, 'Losses/train_all_loss_mask': 0.0007141755035263486, 'Losses/train_all_loss_dice': 0.41546425968408585, 'Losses/train_all_loss_iou': 0.2048770822584629, 'Losses/train_all_loss_class': 1.0557598306704107e-08, 'Losses/train_all_core_loss': 0.6346248492598534, 'Trainer/where': 0.659, 'Trainer/epoch': 32, 'Trainer/steps_train': 660}
INFO 2025-05-18 16:46:39,524 train_utils.py: 271: Train Epoch: [33][ 0/20] | Batch Time: 15.57 (15.57) | Data Time: 10.67 (10.67) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 47m | Losses/train_all_loss: 5.54e-01 (5.54e-01)
INFO 2025-05-18 16:47:18,092 train_utils.py: 271: Train Epoch: [33][10/20] | Batch Time: 4.39 (4.92) | Data Time: 0.00 (0.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 5.11e-01 (7.79e-01)
INFO 2025-05-18 16:47:51,501 trainer.py: 950: Estimated time remaining: 00d 00h 23m
INFO 2025-05-18 16:47:51,501 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:47:51,502 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.749511468410492, 'Losses/train_all_loss_mask': 0.0009236527563189157, 'Losses/train_all_loss_dice': 0.49194910675287246, 'Losses/train_all_loss_iou': 0.2390891645103693, 'Losses/train_all_loss_class': 1.5311492731484578e-07, 'Losses/train_all_core_loss': 0.749511468410492, 'Trainer/where': 0.679, 'Trainer/epoch': 33, 'Trainer/steps_train': 680}
INFO 2025-05-18 16:48:08,256 train_utils.py: 271: Train Epoch: [34][ 0/20] | Batch Time: 14.08 (14.08) | Data Time: 10.72 (10.72) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 8.48e-01 (8.48e-01)
INFO 2025-05-18 16:48:45,250 train_utils.py: 271: Train Epoch: [34][10/20] | Batch Time: 4.40 (4.64) | Data Time: 0.00 (0.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 7.22e-01 (6.79e-01)
INFO 2025-05-18 16:49:17,000 trainer.py: 950: Estimated time remaining: 00d 00h 20m
INFO 2025-05-18 16:49:17,000 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:49:17,000 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6949537426233292, 'Losses/train_all_loss_mask': 0.0007627981103723869, 'Losses/train_all_loss_dice': 0.45822408348321914, 'Losses/train_all_loss_iou': 0.2214735932648182, 'Losses/train_all_loss_class': 1.0803145406024228e-07, 'Losses/train_all_core_loss': 0.6949537426233292, 'Trainer/where': 0.6990000000000001, 'Trainer/epoch': 34, 'Trainer/steps_train': 700}
INFO 2025-05-18 16:49:35,708 train_utils.py: 271: Train Epoch: [35][ 0/20] | Batch Time: 15.67 (15.67) | Data Time: 10.72 (10.72) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 50m | Losses/train_all_loss: 4.26e-01 (4.26e-01)
INFO 2025-05-18 16:50:14,106 train_utils.py: 271: Train Epoch: [35][10/20] | Batch Time: 2.96 (4.91) | Data Time: 0.00 (0.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 7.88e-01 (6.75e-01)
INFO 2025-05-18 16:50:49,837 trainer.py: 950: Estimated time remaining: 00d 00h 20m
INFO 2025-05-18 16:50:49,838 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:50:49,838 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7026728451251983, 'Losses/train_all_loss_mask': 0.0008668959417263977, 'Losses/train_all_loss_dice': 0.457904127240181, 'Losses/train_all_loss_iou': 0.2274308018386364, 'Losses/train_all_loss_class': 1.2846138974786925e-08, 'Losses/train_all_core_loss': 0.7026728451251983, 'Trainer/where': 0.7190000000000001, 'Trainer/epoch': 35, 'Trainer/steps_train': 720}
INFO 2025-05-18 16:51:08,673 train_utils.py: 271: Train Epoch: [36][ 0/20] | Batch Time: 15.26 (15.26) | Data Time: 10.68 (10.68) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 5.17e-01 (5.17e-01)
INFO 2025-05-18 16:51:41,965 train_utils.py: 271: Train Epoch: [36][10/20] | Batch Time: 2.80 (4.41) | Data Time: 0.00 (0.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 6.06e-01 (7.18e-01)
INFO 2025-05-18 16:52:08,904 trainer.py: 950: Estimated time remaining: 00d 00h 16m
INFO 2025-05-18 16:52:08,904 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:52:08,904 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7476472854614258, 'Losses/train_all_loss_mask': 0.0008563512703403831, 'Losses/train_all_loss_dice': 0.486749991774559, 'Losses/train_all_loss_iou': 0.2437702775001526, 'Losses/train_all_loss_class': 9.736671380267126e-09, 'Losses/train_all_core_loss': 0.7476472854614258, 'Trainer/where': 0.7390000000000001, 'Trainer/epoch': 36, 'Trainer/steps_train': 740}
INFO 2025-05-18 16:52:24,731 train_utils.py: 271: Train Epoch: [37][ 0/20] | Batch Time: 13.61 (13.61) | Data Time: 10.31 (10.31) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 8.30e-01 (8.30e-01)
INFO 2025-05-18 16:52:56,977 train_utils.py: 271: Train Epoch: [37][10/20] | Batch Time: 2.82 (4.17) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 8.14e-01 (7.15e-01)
INFO 2025-05-18 16:53:30,656 trainer.py: 950: Estimated time remaining: 00d 00h 15m
INFO 2025-05-18 16:53:30,656 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:53:30,656 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6876701727509499, 'Losses/train_all_loss_mask': 0.0007723085829638876, 'Losses/train_all_loss_dice': 0.4575454980134964, 'Losses/train_all_loss_iou': 0.21467850394546986, 'Losses/train_all_loss_class': 1.1143133171742647e-08, 'Losses/train_all_core_loss': 0.6876701727509499, 'Trainer/where': 0.759, 'Trainer/epoch': 37, 'Trainer/steps_train': 760}
INFO 2025-05-18 16:53:46,093 train_utils.py: 271: Train Epoch: [38][ 0/20] | Batch Time: 13.17 (13.17) | Data Time: 9.90 (9.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 6.32e-01 (6.32e-01)
INFO 2025-05-18 16:54:25,227 train_utils.py: 271: Train Epoch: [38][10/20] | Batch Time: 4.08 (4.76) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 55m | Losses/train_all_loss: 6.39e-01 (6.69e-01)
INFO 2025-05-18 16:54:54,976 trainer.py: 950: Estimated time remaining: 00d 00h 14m
INFO 2025-05-18 16:54:54,976 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:54:54,976 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6665795639157295, 'Losses/train_all_loss_mask': 0.0008720383979380131, 'Losses/train_all_loss_dice': 0.43808369636535643, 'Losses/train_all_loss_iou': 0.21105509996414185, 'Losses/train_all_loss_class': 1.1815110734225697e-08, 'Losses/train_all_core_loss': 0.6665795639157295, 'Trainer/where': 0.779, 'Trainer/epoch': 38, 'Trainer/steps_train': 780}
INFO 2025-05-18 16:55:12,625 train_utils.py: 271: Train Epoch: [39][ 0/20] | Batch Time: 14.93 (14.93) | Data Time: 10.36 (10.36) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 7.80e-01 (7.80e-01)
INFO 2025-05-18 16:55:47,245 train_utils.py: 271: Train Epoch: [39][10/20] | Batch Time: 2.80 (4.50) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 9.30e-01 (6.88e-01)
INFO 2025-05-18 16:56:18,550 trainer.py: 950: Estimated time remaining: 00d 00h 13m
INFO 2025-05-18 16:56:18,550 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:56:18,551 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.79156314432621, 'Losses/train_all_loss_mask': 0.0009268025154597126, 'Losses/train_all_loss_dice': 0.525236289203167, 'Losses/train_all_loss_iou': 0.2477906569838524, 'Losses/train_all_loss_class': 1.560629742547448e-07, 'Losses/train_all_core_loss': 0.79156314432621, 'Trainer/where': 0.799, 'Trainer/epoch': 39, 'Trainer/steps_train': 800}
INFO 2025-05-18 16:56:36,117 train_utils.py: 271: Train Epoch: [40][ 0/20] | Batch Time: 15.14 (15.14) | Data Time: 10.63 (10.63) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 7.56e-01 (7.56e-01)
INFO 2025-05-18 16:57:09,629 train_utils.py: 271: Train Epoch: [40][10/20] | Batch Time: 2.80 (4.42) | Data Time: 0.00 (0.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 6.23e-01 (6.37e-01)
INFO 2025-05-18 16:57:42,127 trainer.py: 950: Estimated time remaining: 00d 00h 12m
INFO 2025-05-18 16:57:42,128 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:57:42,128 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6452929750084877, 'Losses/train_all_loss_mask': 0.0006650682567851618, 'Losses/train_all_loss_dice': 0.43207655698060987, 'Losses/train_all_loss_iou': 0.1999150410294533, 'Losses/train_all_loss_class': 1.2061224774484458e-08, 'Losses/train_all_core_loss': 0.6452929750084877, 'Trainer/where': 0.8190000000000001, 'Trainer/epoch': 40, 'Trainer/steps_train': 820}
INFO 2025-05-18 16:57:59,940 train_utils.py: 271: Train Epoch: [41][ 0/20] | Batch Time: 14.83 (14.83) | Data Time: 10.21 (10.21) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 5.41e-01 (5.41e-01)
INFO 2025-05-18 16:58:35,996 train_utils.py: 271: Train Epoch: [41][10/20] | Batch Time: 2.90 (4.63) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 5.93e-01 (6.46e-01)
INFO 2025-05-18 16:59:07,394 trainer.py: 950: Estimated time remaining: 00d 00h 10m
INFO 2025-05-18 16:59:07,395 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 16:59:07,395 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6770510390400887, 'Losses/train_all_loss_mask': 0.0008100191160337999, 'Losses/train_all_loss_dice': 0.4473813369870186, 'Losses/train_all_loss_iou': 0.21346931904554367, 'Losses/train_all_loss_class': 1.462396268525623e-08, 'Losses/train_all_core_loss': 0.6770510390400887, 'Trainer/where': 0.8390000000000001, 'Trainer/epoch': 41, 'Trainer/steps_train': 840}
INFO 2025-05-18 16:59:24,051 train_utils.py: 271: Train Epoch: [42][ 0/20] | Batch Time: 13.59 (13.59) | Data Time: 10.42 (10.42) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 1.11e+00 (1.11e+00)
INFO 2025-05-18 17:00:01,261 train_utils.py: 271: Train Epoch: [42][10/20] | Batch Time: 4.09 (4.62) | Data Time: 0.00 (0.95) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 5.83e-01 (6.55e-01)
INFO 2025-05-18 17:00:33,756 trainer.py: 950: Estimated time remaining: 00d 00h 09m
INFO 2025-05-18 17:00:33,756 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:00:33,757 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6730279833078384, 'Losses/train_all_loss_mask': 0.0008535620960174129, 'Losses/train_all_loss_dice': 0.4444916144013405, 'Losses/train_all_loss_iou': 0.21146512553095817, 'Losses/train_all_loss_class': 1.2229386481266146e-08, 'Losses/train_all_core_loss': 0.6730279833078384, 'Trainer/where': 0.8590000000000001, 'Trainer/epoch': 42, 'Trainer/steps_train': 860}
INFO 2025-05-18 17:00:49,417 train_utils.py: 271: Train Epoch: [43][ 0/20] | Batch Time: 13.40 (13.40) | Data Time: 10.27 (10.27) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 4.93e-01 (4.93e-01)
INFO 2025-05-18 17:01:25,864 train_utils.py: 271: Train Epoch: [43][10/20] | Batch Time: 2.89 (4.53) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 5.92e-01 (6.08e-01)
INFO 2025-05-18 17:01:55,747 trainer.py: 950: Estimated time remaining: 00d 00h 07m
INFO 2025-05-18 17:01:55,748 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:01:55,748 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7013492554426193, 'Losses/train_all_loss_mask': 0.0008179652621038258, 'Losses/train_all_loss_dice': 0.4557372644543648, 'Losses/train_all_loss_iou': 0.2292526662349701, 'Losses/train_all_loss_class': 2.8024839093809818e-08, 'Losses/train_all_core_loss': 0.7013492554426193, 'Trainer/where': 0.879, 'Trainer/epoch': 43, 'Trainer/steps_train': 880}
INFO 2025-05-18 17:02:11,867 train_utils.py: 271: Train Epoch: [44][ 0/20] | Batch Time: 13.35 (13.35) | Data Time: 10.19 (10.19) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 6.44e-01 (6.44e-01)
INFO 2025-05-18 17:02:43,962 train_utils.py: 271: Train Epoch: [44][10/20] | Batch Time: 2.79 (4.13) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 7.62e-01 (7.22e-01)
INFO 2025-05-18 17:03:16,404 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-05-18 17:03:16,406 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:03:16,406 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7032917246222496, 'Losses/train_all_loss_mask': 0.0008384004118852318, 'Losses/train_all_loss_dice': 0.4589138701558113, 'Losses/train_all_loss_iou': 0.2276098422706127, 'Losses/train_all_loss_class': 1.0191224619759964e-08, 'Losses/train_all_core_loss': 0.7032917246222496, 'Trainer/where': 0.899, 'Trainer/epoch': 44, 'Trainer/steps_train': 900}
INFO 2025-05-18 17:03:34,385 train_utils.py: 271: Train Epoch: [45][ 0/20] | Batch Time: 15.34 (15.34) | Data Time: 10.73 (10.73) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 6.75e-01 (6.75e-01)
INFO 2025-05-18 17:04:10,306 train_utils.py: 271: Train Epoch: [45][10/20] | Batch Time: 4.09 (4.66) | Data Time: 0.00 (0.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 4.86e-01 (6.36e-01)
INFO 2025-05-18 17:04:42,695 trainer.py: 950: Estimated time remaining: 00d 00h 05m
INFO 2025-05-18 17:04:42,695 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:04:42,695 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6399598315358161, 'Losses/train_all_loss_mask': 0.0006939474507817068, 'Losses/train_all_loss_dice': 0.42412771433591845, 'Losses/train_all_loss_iou': 0.20195316150784492, 'Losses/train_all_loss_class': 1.2380129321698518e-08, 'Losses/train_all_core_loss': 0.6399598315358161, 'Trainer/where': 0.919, 'Trainer/epoch': 45, 'Trainer/steps_train': 920}
INFO 2025-05-18 17:05:00,442 train_utils.py: 271: Train Epoch: [46][ 0/20] | Batch Time: 14.85 (14.85) | Data Time: 10.28 (10.28) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 7.14e-01 (7.14e-01)
INFO 2025-05-18 17:05:34,204 train_utils.py: 271: Train Epoch: [46][10/20] | Batch Time: 2.81 (4.42) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 6.09e-01 (6.35e-01)
INFO 2025-05-18 17:06:05,404 trainer.py: 950: Estimated time remaining: 00d 00h 03m
INFO 2025-05-18 17:06:05,404 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:06:05,405 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6753719389438629, 'Losses/train_all_loss_mask': 0.0008190870838006958, 'Losses/train_all_loss_dice': 0.4484794646501541, 'Losses/train_all_loss_iou': 0.21051072403788568, 'Losses/train_all_loss_class': 1.0816542928004936e-08, 'Losses/train_all_core_loss': 0.6753719389438629, 'Trainer/where': 0.9390000000000001, 'Trainer/epoch': 46, 'Trainer/steps_train': 940}
INFO 2025-05-18 17:06:22,855 train_utils.py: 271: Train Epoch: [47][ 0/20] | Batch Time: 15.00 (15.00) | Data Time: 10.50 (10.50) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 5.19e-01 (5.19e-01)
INFO 2025-05-18 17:06:56,007 train_utils.py: 271: Train Epoch: [47][10/20] | Batch Time: 4.14 (4.38) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 5.86e-01 (6.88e-01)
INFO 2025-05-18 17:07:28,698 trainer.py: 950: Estimated time remaining: 00d 00h 02m
INFO 2025-05-18 17:07:28,699 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:07:28,699 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.686765331029892, 'Losses/train_all_loss_mask': 0.0008218789385864511, 'Losses/train_all_loss_dice': 0.4533451542258263, 'Losses/train_all_loss_iou': 0.21698260828852653, 'Losses/train_all_loss_class': 1.073283802943692e-08, 'Losses/train_all_core_loss': 0.686765331029892, 'Trainer/where': 0.9590000000000001, 'Trainer/epoch': 47, 'Trainer/steps_train': 960}
INFO 2025-05-18 17:07:47,042 train_utils.py: 271: Train Epoch: [48][ 0/20] | Batch Time: 15.28 (15.28) | Data Time: 10.57 (10.57) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 4.91e-01 (4.91e-01)
INFO 2025-05-18 17:08:19,274 train_utils.py: 271: Train Epoch: [48][10/20] | Batch Time: 2.82 (4.32) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 09m | Losses/train_all_loss: 7.83e-01 (8.02e-01)
INFO 2025-05-18 17:08:50,348 trainer.py: 950: Estimated time remaining: 00d 00h 01m
INFO 2025-05-18 17:08:50,348 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:08:50,349 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7370067268610001, 'Losses/train_all_loss_mask': 0.0012653646088438108, 'Losses/train_all_loss_dice': 0.48401166349649427, 'Losses/train_all_loss_iou': 0.22768776640295982, 'Losses/train_all_loss_class': 1.2589071274327069e-08, 'Losses/train_all_core_loss': 0.7370067268610001, 'Trainer/where': 0.9790000000000001, 'Trainer/epoch': 48, 'Trainer/steps_train': 980}
INFO 2025-05-18 17:09:08,377 train_utils.py: 271: Train Epoch: [49][ 0/20] | Batch Time: 14.96 (14.96) | Data Time: 10.35 (10.35) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 5.77e-01 (5.77e-01)
INFO 2025-05-18 17:09:41,685 train_utils.py: 271: Train Epoch: [49][10/20] | Batch Time: 2.80 (4.39) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 5.94e-01 (6.43e-01)
INFO 2025-05-18 17:10:13,140 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-05-18 17:10:13,141 trainer.py: 892: Synchronizing meters
INFO 2025-05-18 17:10:13,141 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6674824208021164, 'Losses/train_all_loss_mask': 0.0007507555244956165, 'Losses/train_all_loss_dice': 0.4434158757328987, 'Losses/train_all_loss_iou': 0.20905143097043039, 'Losses/train_all_loss_class': 1.2710101082724634e-08, 'Losses/train_all_core_loss': 0.6674824208021164, 'Trainer/where': 0.9990000000000001, 'Trainer/epoch': 49, 'Trainer/steps_train': 1000}
INFO 2025-05-19 11:48:38,655 train_utils.py: 108: MACHINE SEED: 24600
INFO 2025-05-19 11:48:38,668 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-19 11:48:38,668 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_28048_HBWVQLJHHNQMOXKA
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_20160_1262719628=1
EFC_20160_1592913036=1
EFC_20160_2283032206=1
EFC_20160_2775293581=1
EFC_20160_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=2672
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=47444
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=28048
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-19 11:48:38,668 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:48:38,669 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-19 11:48:39,955 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-19 11:48:39,958 trainer.py:1059: ====================
INFO 2025-05-19 11:48:39,959 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-19 11:48:39,963 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-19 11:48:39,964 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-19 11:48:39,964 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-19 11:48:39,965 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-19 11:48:39,965 trainer.py:1069: ====================
INFO 2025-05-19 11:48:39,971 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:48:39,971 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:48:40,077 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:48:40,101 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight'}
INFO 2025-05-19 11:48:40,104 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.10.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'memory_attention.layers.0.linear1.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.norm.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'obj_ptr_proj.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'memory_encoder.out_proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'memory_attention.layers.2.linear2.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_attention.layers.0.linear2.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.conv_s1.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias'}
INFO 2025-05-19 11:48:40,104 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'memory_attention.layers.3.norm2.weight', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'memory_attention.layers.0.norm2.weight', 'memory_attention.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias'} 
INFO 2025-05-19 11:48:43,412 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-19 11:48:43,416 trainer.py: 423: Resuming training from C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/checkpoints\checkpoint.pt
INFO 2025-05-19 11:50:24,465 train_utils.py: 108: MACHINE SEED: 24600
INFO 2025-05-19 11:50:24,474 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-19 11:50:24,474 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_28048_HBWVQLJHHNQMOXKA
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_20160_1262719628=1
EFC_20160_1592913036=1
EFC_20160_2283032206=1
EFC_20160_2775293581=1
EFC_20160_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=2672
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=51181
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=28048
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-19 11:50:24,475 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:50:24,476 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-19 11:50:25,247 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-19 11:50:25,251 trainer.py:1059: ====================
INFO 2025-05-19 11:50:25,251 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-19 11:50:25,255 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-19 11:50:25,255 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-19 11:50:25,255 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-19 11:50:25,256 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-19 11:50:25,256 trainer.py:1069: ====================
INFO 2025-05-19 11:50:25,260 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:50:25,260 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:50:25,360 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:50:25,385 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.10.norm2.bias'}
INFO 2025-05-19 11:50:25,389 optimizer.py: 248: Matches for param_name [*bias*]: {'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'obj_ptr_proj.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'memory_attention.layers.2.norm3.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'memory_encoder.pix_feat_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'memory_attention.layers.0.norm1.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'memory_attention.layers.2.linear1.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.1.linear1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'obj_ptr_proj.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'memory_attention.layers.3.norm2.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.conv_s0.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'memory_attention.norm.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.10.norm2.bias'}
INFO 2025-05-19 11:50:25,389 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.15.norm2.bias', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.3.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'memory_attention.layers.2.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'memory_attention.layers.3.norm2.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.0.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'memory_attention.layers.2.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'memory_attention.layers.1.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.bias'} 
INFO 2025-05-19 11:50:27,361 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-19 11:50:27,362 trainer.py: 423: Resuming training from C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/checkpoints\checkpoint.pt
INFO 2025-05-19 11:53:21,026 train_utils.py: 108: MACHINE SEED: 24600
INFO 2025-05-19 11:53:21,036 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-19 11:53:21,036 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_28048_HBWVQLJHHNQMOXKA
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_20160_1262719628=1
EFC_20160_1592913036=1
EFC_20160_2283032206=1
EFC_20160_2775293581=1
EFC_20160_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=2672
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=54078
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=28048
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-19 11:53:21,036 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:53:21,037 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-19 11:53:21,821 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-19 11:53:21,824 trainer.py:1059: ====================
INFO 2025-05-19 11:53:21,824 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-19 11:53:21,827 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-19 11:53:21,828 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-19 11:53:21,828 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-19 11:53:21,828 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-19 11:53:21,828 trainer.py:1069: ====================
INFO 2025-05-19 11:53:21,833 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:53:21,833 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:53:21,930 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:53:21,955 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.neck.convs.1.conv.bias'}
INFO 2025-05-19 11:53:21,958 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'obj_ptr_proj.layers.0.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.1.linear2.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_encoder.out_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'memory_attention.layers.3.linear1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'memory_attention.layers.1.linear1.bias', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.2.linear1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'memory_attention.layers.2.linear2.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'obj_ptr_proj.layers.1.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'obj_ptr_tpos_proj.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'memory_attention.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'sam_mask_decoder.conv_s1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.neck.convs.1.conv.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias'}
INFO 2025-05-19 11:53:21,958 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.norm.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.2.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'memory_attention.layers.0.norm2.weight', 'memory_attention.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_attention.layers.0.norm3.weight'} 
INFO 2025-05-19 11:53:23,627 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-19 11:53:23,628 trainer.py: 423: Resuming training from C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/checkpoints\checkpoint.pt
INFO 2025-05-19 11:54:31,114 train_utils.py: 271: Train Epoch: [50][ 0/20] | Batch Time: 65.34 (65.34) | Data Time: 10.37 (10.37) | Mem (GB): 19.00 (19.00/19.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 5.41e-01 (5.41e-01)
INFO 2025-05-19 11:55:14,648 train_utils.py: 108: MACHINE SEED: 24600
INFO 2025-05-19 11:55:14,657 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-05-19 11:55:14,657 train_utils.py: 155: ALLUSERSPROFILE=C:\ProgramData
AMDRMPATH=C:\Program Files\AMD\RyzenMaster\
APPDATA=C:\Users\Micha\AppData\Roaming
CHROME_CRASHPAD_PIPE_NAME=\\.\pipe\crashpad_28048_HBWVQLJHHNQMOXKA
CLICOLOR=1
CLICOLOR_FORCE=1
COMMONPROGRAMFILES=C:\Program Files\Common Files
COMMONPROGRAMFILES(X86)=C:\Program Files (x86)\Common Files
COMMONPROGRAMW6432=C:\Program Files\Common Files
COMPUTERNAME=DESKTOP-SJKAOIV
COMSPEC=C:\WINDOWS\system32\cmd.exe
CUDA_MODULE_LOADING=LAZY
CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
CUDA_PATH_V12_9=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9
DRIVERDATA=C:\Windows\System32\Drivers\DriverData
EFC_20160_1262719628=1
EFC_20160_1592913036=1
EFC_20160_2283032206=1
EFC_20160_2775293581=1
EFC_20160_3789132940=1
ELECTRON_RUN_AS_NODE=1
FORCE_COLOR=1
FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer
FPS_BROWSER_USER_PROFILE_STRING=Default
GIT_PAGER=cat
HOMEDRIVE=C:
HOMEPATH=\Users\Micha
HYDRA_FULL_ERROR=1
JPY_INTERRUPT_EVENT=2672
LOCALAPPDATA=C:\Users\Micha\AppData\Local
LOCAL_RANK=0
LOGONSERVER=\\DESKTOP-SJKAOIV
MASTER_ADDR=localhost
MASTER_PORT=18549
MPLBACKEND=module://matplotlib_inline.backend_inline
NUMBER_OF_PROCESSORS=12
ONEDRIVE=C:\Users\Micha\OneDrive
ORIGINAL_XDG_CURRENT_DESKTOP=undefined
OS=Windows_NT
PAGER=cat
PATH=c:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC
PROCESSOR_ARCHITECTURE=AMD64
PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD
PROCESSOR_LEVEL=23
PROCESSOR_REVISION=7100
PROGRAMDATA=C:\ProgramData
PROGRAMFILES=C:\Program Files
PROGRAMFILES(X86)=C:\Program Files (x86)
PROGRAMW6432=C:\Program Files
PROMPT=(ai-powered-biosensing) $P$G
PSMODULEPATH=C:\Program Files\WindowsPowerShell\Modules;C:\WINDOWS\system32\WindowsPowerShell\v1.0\Modules
PUBLIC=C:\Users\Public
PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1
PYDEVD_USE_FRAME_EVAL=NO
PYTHONIOENCODING=utf-8
PYTHONUNBUFFERED=1
PYTHONUSERBASE=C:\Users\Micha\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages
PYTHON_FROZEN_MODULES=on
RANK=0
SESSIONNAME=Console
SYSTEMDRIVE=C:
SYSTEMROOT=C:\WINDOWS
TEMP=C:\Users\Micha\AppData\Local\Temp
TERM=xterm-color
TMP=C:\Users\Micha\AppData\Local\Temp
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USERDOMAIN=DESKTOP-SJKAOIV
USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV
USERNAME=Micha
USERPROFILE=C:\Users\Micha
VBOX_MSI_INSTALL_PATH=C:\Program Files\Oracle\VirtualBox\
VIRTUAL_ENV=C:\Users\Micha\Desktop\BachelorProject\AI-Powered-Biosensing\.venv
VIRTUAL_ENV_PROMPT=ai-powered-biosensing
VSCODE_CODE_CACHE_PATH=C:\Users\Micha\AppData\Roaming\Code\CachedData\848b80aeb52026648a8ff9f7c45a9b0a80641e2e
VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost
VSCODE_CWD=C:\Microsoft VS Code
VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess
VSCODE_HANDLES_UNCAUGHT_ERRORS=true
VSCODE_IPC_HOOK=\\.\pipe\24d3f695-1.100.2-main-sock
VSCODE_NLS_CONFIG={"userLocale":"en-us","osLocale":"en-de","resolvedLanguage":"en","defaultMessagesFile":"C:\\Microsoft VS Code\\resources\\app\\out\\nls.messages.json","locale":"en-us","availableLanguages":{}}
VSCODE_PID=28048
WINDIR=C:\WINDOWS
WORLD_SIZE=1
_OLD_VIRTUAL_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.9\libnvvp;C:\mingw64\bin;C:\jdk-18.0.2\bin;C:\Program Files (x86)\Razer Chroma SDK\bin;C:\Program Files\Razer Chroma SDK\bin;C:\Program Files (x86)\Razer\ChromaBroadcast\bin;C:\Program Files\Razer\ChromaBroadcast\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\WINDOWS\system32\config\systemprofile\AppData\Local\Microsoft\WindowsApps;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\apache-maven-3.9.6\bin;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\Micha\.local\bin;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.2.0\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\Micha\.local\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\Micha\AppData\Local\Microsoft\WindowsApps;C:\Microsoft VS Code\bin;C:\Gradle\gradle-8.4\bin;
_OLD_VIRTUAL_PROMPT=$P$G
__PSLOCKDOWNPOLICY=0

INFO 2025-05-19 11:55:14,657 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:55:14,659 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/tensorboard
INFO 2025-05-19 11:55:15,435 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-05-19 11:55:15,439 trainer.py:1059: ====================
INFO 2025-05-19 11:55:15,439 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-05-19 11:55:15,443 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (1): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=112, out_features=336, bias=True)
            (proj): Linear(in_features=112, out_features=112, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=112, out_features=448, bias=True)
              (1): Linear(in_features=448, out_features=112, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=112, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=112, out_features=224, bias=True)
        )
        (3-4): 2 x MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=224, out_features=672, bias=True)
            (proj): Linear(in_features=224, out_features=224, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=224, out_features=896, bias=True)
              (1): Linear(in_features=896, out_features=224, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (5): MultiScaleBlock(
          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=224, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=224, out_features=448, bias=True)
        )
        (6-20): 15 x MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=448, out_features=1344, bias=True)
            (proj): Linear(in_features=448, out_features=448, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=448, out_features=1792, bias=True)
              (1): Linear(in_features=1792, out_features=448, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (21): MultiScaleBlock(
          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=448, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=448, out_features=896, bias=True)
        )
        (22-23): 2 x MultiScaleBlock(
          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=896, out_features=2688, bias=True)
            (proj): Linear(in_features=896, out_features=896, bias=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=896, out_features=3584, bias=True)
              (1): Linear(in_features=3584, out_features=896, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-05-19 11:55:15,444 trainer.py:1062: 	Total parameters 80.9 M
INFO 2025-05-19 11:55:15,444 trainer.py:1063: 	Trainable parameters 80.9 M
INFO 2025-05-19 11:55:15,444 trainer.py:1066: 	Non-Trainable parameters 0  
INFO 2025-05-19 11:55:15,444 trainer.py:1069: ====================
INFO 2025-05-19 11:55:15,449 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-05-19 11:55:15,449 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:55:15,552 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-05-19 11:55:15,577 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.norm1.bias'}
INFO 2025-05-19 11:55:15,579 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.16.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'image_encoder.neck.convs.1.conv.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'memory_attention.layers.3.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'memory_encoder.out_proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'memory_attention.layers.3.linear1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_encoder.pix_feat_proj.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'obj_ptr_proj.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.neck.convs.2.conv.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'sam_mask_decoder.conv_s1.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'memory_attention.layers.1.linear2.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias'}
INFO 2025-05-19 11:55:15,580 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'memory_attention.layers.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'memory_attention.layers.3.norm1.bias', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.2.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'memory_attention.norm.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'memory_attention.layers.2.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'memory_attention.layers.2.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.0.norm1.bias', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.15.norm1.bias'} 
INFO 2025-05-19 11:55:17,477 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-05-19 11:55:17,478 trainer.py: 423: Resuming training from C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_like_sa1b/checkpoints\checkpoint.pt
INFO 2025-05-19 11:55:34,888 train_utils.py: 271: Train Epoch: [50][ 0/20] | Batch Time: 15.16 (15.16) | Data Time: 9.98 (9.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 5.12e-01 (5.12e-01)
INFO 2025-05-19 11:56:07,922 train_utils.py: 271: Train Epoch: [50][10/20] | Batch Time: 2.89 (4.38) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 7.16e-01 (6.50e-01)
INFO 2025-05-19 11:56:34,802 trainer.py: 950: Estimated time remaining: 00d 03h 04m
INFO 2025-05-19 11:56:34,803 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 11:56:34,803 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6535725563764572, 'Losses/train_all_loss_mask': 0.0008304490649607033, 'Losses/train_all_loss_dice': 0.4380688451230526, 'Losses/train_all_loss_iou': 0.19889472983777523, 'Losses/train_all_loss_class': 1.216036746853888e-08, 'Losses/train_all_core_loss': 0.6535725563764572, 'Trainer/where': 0.25475000000000003, 'Trainer/epoch': 50, 'Trainer/steps_train': 1020}
INFO 2025-05-19 11:56:50,422 train_utils.py: 271: Train Epoch: [51][ 0/20] | Batch Time: 13.24 (13.24) | Data Time: 10.03 (10.03) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 7.29e-01 (7.29e-01)
INFO 2025-05-19 11:57:19,233 train_utils.py: 271: Train Epoch: [51][10/20] | Batch Time: 2.90 (3.82) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 6.56e-01 (6.71e-01)
INFO 2025-05-19 11:57:45,534 trainer.py: 950: Estimated time remaining: 00d 02h 46m
INFO 2025-05-19 11:57:45,535 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 11:57:45,535 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6760249018669129, 'Losses/train_all_loss_mask': 0.0007265431486302987, 'Losses/train_all_loss_dice': 0.44681386202573775, 'Losses/train_all_loss_iou': 0.2146801695227623, 'Losses/train_all_loss_class': 1.3475493354508928e-08, 'Losses/train_all_core_loss': 0.6760249018669129, 'Trainer/where': 0.25975000000000004, 'Trainer/epoch': 51, 'Trainer/steps_train': 1040}
INFO 2025-05-19 11:58:01,082 train_utils.py: 271: Train Epoch: [52][ 0/20] | Batch Time: 13.41 (13.41) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 6.81e-01 (6.81e-01)
INFO 2025-05-19 11:58:29,560 train_utils.py: 271: Train Epoch: [52][10/20] | Batch Time: 2.80 (3.81) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 8.26e-01 (7.16e-01)
INFO 2025-05-19 11:58:55,825 trainer.py: 950: Estimated time remaining: 00d 02h 45m
INFO 2025-05-19 11:58:55,825 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 11:58:55,825 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7000956356525421, 'Losses/train_all_loss_mask': 0.000794882801710628, 'Losses/train_all_loss_dice': 0.4650863826274872, 'Losses/train_all_loss_iou': 0.2191115915775299, 'Losses/train_all_loss_class': 1.381052170401631e-08, 'Losses/train_all_core_loss': 0.7000956356525421, 'Trainer/where': 0.26475000000000004, 'Trainer/epoch': 52, 'Trainer/steps_train': 1060}
INFO 2025-05-19 11:59:11,190 train_utils.py: 271: Train Epoch: [53][ 0/20] | Batch Time: 13.31 (13.31) | Data Time: 10.13 (10.13) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 7.92e-01 (7.92e-01)
INFO 2025-05-19 11:59:39,795 train_utils.py: 271: Train Epoch: [53][10/20] | Batch Time: 2.79 (3.81) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 8.05e-01 (7.09e-01)
INFO 2025-05-19 12:00:06,070 trainer.py: 950: Estimated time remaining: 00d 02h 43m
INFO 2025-05-19 12:00:06,070 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:00:06,071 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6830161780118942, 'Losses/train_all_loss_mask': 0.0007585150611703284, 'Losses/train_all_loss_dice': 0.44691822975873946, 'Losses/train_all_loss_iou': 0.22092765048146248, 'Losses/train_all_loss_class': 1.0789327564708629e-08, 'Losses/train_all_core_loss': 0.6830161780118942, 'Trainer/where': 0.26975, 'Trainer/epoch': 53, 'Trainer/steps_train': 1080}
INFO 2025-05-19 12:00:21,622 train_utils.py: 271: Train Epoch: [54][ 0/20] | Batch Time: 13.38 (13.38) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 6.50e-01 (6.50e-01)
INFO 2025-05-19 12:00:50,216 train_utils.py: 271: Train Epoch: [54][10/20] | Batch Time: 2.90 (3.82) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 5.78e-01 (6.70e-01)
INFO 2025-05-19 12:01:16,501 trainer.py: 950: Estimated time remaining: 00d 02h 43m
INFO 2025-05-19 12:01:16,502 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:01:16,502 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6798117443919182, 'Losses/train_all_loss_mask': 0.0008110637791105546, 'Losses/train_all_loss_dice': 0.44266427308321, 'Losses/train_all_loss_iou': 0.22092619463801383, 'Losses/train_all_loss_class': 1.2754521916402694e-08, 'Losses/train_all_core_loss': 0.6798117443919182, 'Trainer/where': 0.27475, 'Trainer/epoch': 54, 'Trainer/steps_train': 1100}
INFO 2025-05-19 12:01:32,447 train_utils.py: 271: Train Epoch: [55][ 0/20] | Batch Time: 13.50 (13.50) | Data Time: 10.15 (10.15) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 5.15e-01 (5.15e-01)
INFO 2025-05-19 12:02:00,493 train_utils.py: 271: Train Epoch: [55][10/20] | Batch Time: 2.82 (3.78) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 5.59e-01 (8.44e-01)
INFO 2025-05-19 12:02:27,400 trainer.py: 950: Estimated time remaining: 00d 02h 42m
INFO 2025-05-19 12:02:27,401 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:02:27,401 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7186160832643509, 'Losses/train_all_loss_mask': 0.0009704913769382984, 'Losses/train_all_loss_dice': 0.47106469720602034, 'Losses/train_all_loss_iou': 0.22814154699444772, 'Losses/train_all_loss_class': 1.6802812408123203e-08, 'Losses/train_all_core_loss': 0.7186160832643509, 'Trainer/where': 0.27975, 'Trainer/epoch': 55, 'Trainer/steps_train': 1120}
INFO 2025-05-19 12:02:42,555 train_utils.py: 271: Train Epoch: [56][ 0/20] | Batch Time: 13.18 (13.18) | Data Time: 10.02 (10.02) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 7.72e-01 (7.72e-01)
INFO 2025-05-19 12:03:11,454 train_utils.py: 271: Train Epoch: [56][10/20] | Batch Time: 2.80 (3.83) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 6.90e-01 (6.63e-01)
INFO 2025-05-19 12:03:38,054 trainer.py: 950: Estimated time remaining: 00d 02h 41m
INFO 2025-05-19 12:03:38,054 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:03:38,055 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.686681255698204, 'Losses/train_all_loss_mask': 0.0008040470536798238, 'Losses/train_all_loss_dice': 0.44987564384937284, 'Losses/train_all_loss_iou': 0.22072466015815734, 'Losses/train_all_loss_class': 1.4418169613783504e-08, 'Losses/train_all_core_loss': 0.686681255698204, 'Trainer/where': 0.28475, 'Trainer/epoch': 56, 'Trainer/steps_train': 1140}
INFO 2025-05-19 12:03:53,728 train_utils.py: 271: Train Epoch: [57][ 0/20] | Batch Time: 13.32 (13.32) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 4.87e-01 (4.87e-01)
INFO 2025-05-19 12:04:22,378 train_utils.py: 271: Train Epoch: [57][10/20] | Batch Time: 2.82 (3.82) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 5.62e-01 (6.12e-01)
INFO 2025-05-19 12:04:48,937 trainer.py: 950: Estimated time remaining: 00d 02h 40m
INFO 2025-05-19 12:04:48,938 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:04:48,938 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6527757689356803, 'Losses/train_all_loss_mask': 0.0007927296566776932, 'Losses/train_all_loss_dice': 0.43316100984811784, 'Losses/train_all_loss_iou': 0.20376016721129417, 'Losses/train_all_loss_class': 1.4825997962653048e-08, 'Losses/train_all_core_loss': 0.6527757689356803, 'Trainer/where': 0.28975, 'Trainer/epoch': 57, 'Trainer/steps_train': 1160}
INFO 2025-05-19 12:05:04,367 train_utils.py: 271: Train Epoch: [58][ 0/20] | Batch Time: 13.32 (13.32) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 4.78e-01 (4.78e-01)
INFO 2025-05-19 12:05:32,710 train_utils.py: 271: Train Epoch: [58][10/20] | Batch Time: 2.94 (3.79) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 4.51e-01 (7.32e-01)
INFO 2025-05-19 12:05:58,870 trainer.py: 950: Estimated time remaining: 00d 02h 37m
INFO 2025-05-19 12:05:58,871 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:05:58,871 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7351540774106979, 'Losses/train_all_loss_mask': 0.0008181169949239119, 'Losses/train_all_loss_dice': 0.49171582609415054, 'Losses/train_all_loss_iou': 0.22707587741315366, 'Losses/train_all_loss_class': 4.896575542812087e-08, 'Losses/train_all_core_loss': 0.7351540774106979, 'Trainer/where': 0.29475, 'Trainer/epoch': 58, 'Trainer/steps_train': 1180}
INFO 2025-05-19 12:06:14,360 train_utils.py: 271: Train Epoch: [59][ 0/20] | Batch Time: 13.39 (13.39) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 22m | Losses/train_all_loss: 8.42e-01 (8.42e-01)
INFO 2025-05-19 12:06:42,961 train_utils.py: 271: Train Epoch: [59][10/20] | Batch Time: 2.87 (3.82) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 22m | Losses/train_all_loss: 5.91e-01 (7.20e-01)
INFO 2025-05-19 12:07:09,458 trainer.py: 950: Estimated time remaining: 00d 02h 37m
INFO 2025-05-19 12:07:09,459 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:07:09,459 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6783523961901665, 'Losses/train_all_loss_mask': 0.0008897704115952365, 'Losses/train_all_loss_dice': 0.4395838871598244, 'Losses/train_all_loss_iou': 0.2209730979055166, 'Losses/train_all_loss_class': 1.1813040268204844e-08, 'Losses/train_all_core_loss': 0.6783523961901665, 'Trainer/where': 0.29975, 'Trainer/epoch': 59, 'Trainer/steps_train': 1200}
INFO 2025-05-19 12:07:24,908 train_utils.py: 271: Train Epoch: [60][ 0/20] | Batch Time: 13.39 (13.39) | Data Time: 10.09 (10.09) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 9.82e-01 (9.82e-01)
INFO 2025-05-19 12:07:53,465 train_utils.py: 271: Train Epoch: [60][10/20] | Batch Time: 2.83 (3.81) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 7.65e-01 (6.76e-01)
INFO 2025-05-19 12:08:19,409 trainer.py: 950: Estimated time remaining: 00d 02h 35m
INFO 2025-05-19 12:08:19,410 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:08:19,410 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6777544274926186, 'Losses/train_all_loss_mask': 0.0008019240805879236, 'Losses/train_all_loss_dice': 0.44356794059276583, 'Losses/train_all_loss_iou': 0.21814800947904586, 'Losses/train_all_loss_class': 1.2133669180514062e-08, 'Losses/train_all_core_loss': 0.6777544274926186, 'Trainer/where': 0.30475, 'Trainer/epoch': 60, 'Trainer/steps_train': 1220}
INFO 2025-05-19 12:08:35,123 train_utils.py: 271: Train Epoch: [61][ 0/20] | Batch Time: 13.64 (13.64) | Data Time: 10.39 (10.39) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 24m | Losses/train_all_loss: 4.68e-01 (4.68e-01)
INFO 2025-05-19 12:09:03,545 train_utils.py: 271: Train Epoch: [61][10/20] | Batch Time: 2.88 (3.82) | Data Time: 0.00 (0.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 24m | Losses/train_all_loss: 6.29e-01 (6.87e-01)
INFO 2025-05-19 12:09:30,119 trainer.py: 950: Estimated time remaining: 00d 02h 35m
INFO 2025-05-19 12:09:30,119 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:09:30,119 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6740573585033417, 'Losses/train_all_loss_mask': 0.0008448494627373293, 'Losses/train_all_loss_dice': 0.44218156635761263, 'Losses/train_all_loss_iou': 0.2149787936359644, 'Losses/train_all_loss_class': 1.4375134660404854e-08, 'Losses/train_all_core_loss': 0.6740573585033417, 'Trainer/where': 0.30975, 'Trainer/epoch': 61, 'Trainer/steps_train': 1240}
INFO 2025-05-19 12:09:45,686 train_utils.py: 271: Train Epoch: [62][ 0/20] | Batch Time: 13.55 (13.55) | Data Time: 10.25 (10.25) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 25m | Losses/train_all_loss: 5.77e-01 (5.77e-01)
INFO 2025-05-19 12:10:14,175 train_utils.py: 271: Train Epoch: [62][10/20] | Batch Time: 2.80 (3.82) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 6.26e-01 (7.31e-01)
INFO 2025-05-19 12:10:40,294 trainer.py: 950: Estimated time remaining: 00d 02h 33m
INFO 2025-05-19 12:10:40,294 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:10:40,294 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6653867945075035, 'Losses/train_all_loss_mask': 0.0007518176920711994, 'Losses/train_all_loss_dice': 0.4409381300210953, 'Losses/train_all_loss_iou': 0.20941230282187462, 'Losses/train_all_loss_class': 1.3458999814641714e-08, 'Losses/train_all_core_loss': 0.6653867945075035, 'Trainer/where': 0.31475000000000003, 'Trainer/epoch': 62, 'Trainer/steps_train': 1260}
INFO 2025-05-19 12:10:55,964 train_utils.py: 271: Train Epoch: [63][ 0/20] | Batch Time: 13.42 (13.42) | Data Time: 10.18 (10.18) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 6.33e-01 (6.33e-01)
INFO 2025-05-19 12:11:24,218 train_utils.py: 271: Train Epoch: [63][10/20] | Batch Time: 2.79 (3.79) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 7.83e-01 (6.95e-01)
INFO 2025-05-19 12:11:50,321 trainer.py: 950: Estimated time remaining: 00d 02h 31m
INFO 2025-05-19 12:11:50,322 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:11:50,322 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6689104661345482, 'Losses/train_all_loss_mask': 0.000808065984165296, 'Losses/train_all_loss_dice': 0.4287591278553009, 'Losses/train_all_loss_iou': 0.22399001903831958, 'Losses/train_all_loss_class': 1.2199800880630108e-08, 'Losses/train_all_core_loss': 0.6689104661345482, 'Trainer/where': 0.31975000000000003, 'Trainer/epoch': 63, 'Trainer/steps_train': 1280}
INFO 2025-05-19 12:12:05,742 train_utils.py: 271: Train Epoch: [64][ 0/20] | Batch Time: 13.29 (13.29) | Data Time: 10.15 (10.15) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 5.84e-01 (5.84e-01)
INFO 2025-05-19 12:12:34,455 train_utils.py: 271: Train Epoch: [64][10/20] | Batch Time: 2.79 (3.82) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 28m | Losses/train_all_loss: 5.86e-01 (6.28e-01)
INFO 2025-05-19 12:13:00,494 trainer.py: 950: Estimated time remaining: 00d 02h 31m
INFO 2025-05-19 12:13:00,494 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:13:00,494 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6843359842896461, 'Losses/train_all_loss_mask': 0.0008589396340539679, 'Losses/train_all_loss_dice': 0.4437630772590637, 'Losses/train_all_loss_iou': 0.22339410930871964, 'Losses/train_all_loss_class': 1.2868346388472673e-08, 'Losses/train_all_core_loss': 0.6843359842896461, 'Trainer/where': 0.32475000000000004, 'Trainer/epoch': 64, 'Trainer/steps_train': 1300}
INFO 2025-05-19 12:13:15,495 train_utils.py: 271: Train Epoch: [65][ 0/20] | Batch Time: 12.88 (12.88) | Data Time: 9.63 (9.63) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 4.81e-01 (4.81e-01)
INFO 2025-05-19 12:13:44,128 train_utils.py: 271: Train Epoch: [65][10/20] | Batch Time: 2.95 (3.77) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 4.53e-01 (6.41e-01)
INFO 2025-05-19 12:14:10,508 trainer.py: 950: Estimated time remaining: 00d 02h 29m
INFO 2025-05-19 12:14:10,508 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:14:10,508 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.647876289486885, 'Losses/train_all_loss_mask': 0.0008250229220720939, 'Losses/train_all_loss_dice': 0.42394232749938965, 'Losses/train_all_loss_iou': 0.20743349976837636, 'Losses/train_all_loss_class': 1.3128730946831978e-08, 'Losses/train_all_core_loss': 0.647876289486885, 'Trainer/where': 0.32975, 'Trainer/epoch': 65, 'Trainer/steps_train': 1320}
INFO 2025-05-19 12:14:25,554 train_utils.py: 271: Train Epoch: [66][ 0/20] | Batch Time: 12.99 (12.99) | Data Time: 9.73 (9.73) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 30m | Losses/train_all_loss: 6.06e-01 (6.06e-01)
INFO 2025-05-19 12:14:54,160 train_utils.py: 271: Train Epoch: [66][10/20] | Batch Time: 2.76 (3.78) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 30m | Losses/train_all_loss: 1.21e+00 (6.84e-01)
INFO 2025-05-19 12:15:20,286 trainer.py: 950: Estimated time remaining: 00d 02h 28m
INFO 2025-05-19 12:15:20,286 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:15:20,286 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.714290463924408, 'Losses/train_all_loss_mask': 0.0008728914282983169, 'Losses/train_all_loss_dice': 0.46747739613056183, 'Losses/train_all_loss_iou': 0.22935522422194482, 'Losses/train_all_loss_class': 3.2329304056055716e-08, 'Losses/train_all_core_loss': 0.714290463924408, 'Trainer/where': 0.33475, 'Trainer/epoch': 66, 'Trainer/steps_train': 1340}
INFO 2025-05-19 12:15:35,803 train_utils.py: 271: Train Epoch: [67][ 0/20] | Batch Time: 13.43 (13.43) | Data Time: 10.13 (10.13) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 7.55e-01 (7.55e-01)
INFO 2025-05-19 12:16:05,334 train_utils.py: 271: Train Epoch: [67][10/20] | Batch Time: 3.02 (3.91) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 6.52e-01 (6.89e-01)
INFO 2025-05-19 12:16:31,806 trainer.py: 950: Estimated time remaining: 00d 02h 30m
INFO 2025-05-19 12:16:31,806 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:16:31,806 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6996666967868805, 'Losses/train_all_loss_mask': 0.0008361637737834826, 'Losses/train_all_loss_dice': 0.46297807395458224, 'Losses/train_all_loss_iou': 0.21996534392237663, 'Losses/train_all_loss_class': 1.4267049008864774e-08, 'Losses/train_all_core_loss': 0.6996666967868805, 'Trainer/where': 0.33975, 'Trainer/epoch': 67, 'Trainer/steps_train': 1360}
INFO 2025-05-19 12:16:48,231 train_utils.py: 271: Train Epoch: [68][ 0/20] | Batch Time: 13.58 (13.58) | Data Time: 10.27 (10.27) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 32m | Losses/train_all_loss: 8.39e-01 (8.39e-01)
INFO 2025-05-19 12:17:15,820 train_utils.py: 271: Train Epoch: [68][10/20] | Batch Time: 2.79 (3.74) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 5.92e-01 (7.35e-01)
INFO 2025-05-19 12:17:40,126 trainer.py: 950: Estimated time remaining: 00d 02h 21m
INFO 2025-05-19 12:17:40,127 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:17:40,127 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.707261897623539, 'Losses/train_all_loss_mask': 0.0007956843037391081, 'Losses/train_all_loss_dice': 0.4683870360255241, 'Losses/train_all_loss_iou': 0.2229611746966839, 'Losses/train_all_loss_class': 1.4421058924796171e-08, 'Losses/train_all_core_loss': 0.707261897623539, 'Trainer/where': 0.34475, 'Trainer/epoch': 68, 'Trainer/steps_train': 1380}
INFO 2025-05-19 12:17:55,292 train_utils.py: 271: Train Epoch: [69][ 0/20] | Batch Time: 12.96 (12.96) | Data Time: 9.91 (9.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 6.74e-01 (6.74e-01)
INFO 2025-05-19 12:18:21,523 train_utils.py: 271: Train Epoch: [69][10/20] | Batch Time: 2.58 (3.56) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 34m | Losses/train_all_loss: 9.00e-01 (7.71e-01)
INFO 2025-05-19 12:18:45,865 trainer.py: 950: Estimated time remaining: 00d 02h 15m
INFO 2025-05-19 12:18:45,866 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:18:45,866 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7227919906377792, 'Losses/train_all_loss_mask': 0.000770878029288724, 'Losses/train_all_loss_dice': 0.47160435616970064, 'Losses/train_all_loss_iou': 0.23577006831765174, 'Losses/train_all_loss_class': 2.017682794175357e-08, 'Losses/train_all_core_loss': 0.7227919906377792, 'Trainer/where': 0.34975, 'Trainer/epoch': 69, 'Trainer/steps_train': 1400}
INFO 2025-05-19 12:19:00,854 train_utils.py: 271: Train Epoch: [70][ 0/20] | Batch Time: 12.94 (12.94) | Data Time: 9.77 (9.77) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 34m | Losses/train_all_loss: 6.42e-01 (6.42e-01)
INFO 2025-05-19 12:19:27,298 train_utils.py: 271: Train Epoch: [70][10/20] | Batch Time: 2.59 (3.58) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 35m | Losses/train_all_loss: 6.78e-01 (6.36e-01)
INFO 2025-05-19 12:19:51,465 trainer.py: 950: Estimated time remaining: 00d 02h 14m
INFO 2025-05-19 12:19:51,465 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:19:51,465 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6572595730423927, 'Losses/train_all_loss_mask': 0.0007279192563146353, 'Losses/train_all_loss_dice': 0.4214726597070694, 'Losses/train_all_loss_iou': 0.22122851833701135, 'Losses/train_all_loss_class': 1.6420280157802834e-08, 'Losses/train_all_core_loss': 0.6572595730423927, 'Trainer/where': 0.35475, 'Trainer/epoch': 70, 'Trainer/steps_train': 1420}
INFO 2025-05-19 12:20:06,343 train_utils.py: 271: Train Epoch: [71][ 0/20] | Batch Time: 12.88 (12.88) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 35m | Losses/train_all_loss: 6.48e-01 (6.48e-01)
INFO 2025-05-19 12:20:32,986 train_utils.py: 271: Train Epoch: [71][10/20] | Batch Time: 2.68 (3.59) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 36m | Losses/train_all_loss: 5.81e-01 (6.18e-01)
INFO 2025-05-19 12:20:57,185 trainer.py: 950: Estimated time remaining: 00d 02h 14m
INFO 2025-05-19 12:20:57,186 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:20:57,186 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6721201941370964, 'Losses/train_all_loss_mask': 0.000789455980702769, 'Losses/train_all_loss_dice': 0.4329168930649757, 'Losses/train_all_loss_iou': 0.22341418266296387, 'Losses/train_all_loss_class': 1.692447177958911e-08, 'Losses/train_all_core_loss': 0.6721201941370964, 'Trainer/where': 0.35975, 'Trainer/epoch': 71, 'Trainer/steps_train': 1440}
INFO 2025-05-19 12:21:12,432 train_utils.py: 271: Train Epoch: [72][ 0/20] | Batch Time: 13.15 (13.15) | Data Time: 9.98 (9.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 6.48e-01 (6.48e-01)
INFO 2025-05-19 12:21:38,682 train_utils.py: 271: Train Epoch: [72][10/20] | Batch Time: 2.59 (3.58) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 5.59e-01 (6.35e-01)
INFO 2025-05-19 12:22:03,041 trainer.py: 950: Estimated time remaining: 00d 02h 13m
INFO 2025-05-19 12:22:03,041 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:22:03,041 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6825361832976341, 'Losses/train_all_loss_mask': 0.0008432591217570007, 'Losses/train_all_loss_dice': 0.44044137597084043, 'Losses/train_all_loss_iou': 0.2252296194434166, 'Losses/train_all_loss_class': 1.545892978072061e-08, 'Losses/train_all_core_loss': 0.6825361832976341, 'Trainer/where': 0.36475, 'Trainer/epoch': 72, 'Trainer/steps_train': 1460}
INFO 2025-05-19 12:22:18,112 train_utils.py: 271: Train Epoch: [73][ 0/20] | Batch Time: 12.78 (12.78) | Data Time: 9.82 (9.82) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 38m | Losses/train_all_loss: 1.12e+00 (1.12e+00)
INFO 2025-05-19 12:22:44,630 train_utils.py: 271: Train Epoch: [73][10/20] | Batch Time: 2.64 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 38m | Losses/train_all_loss: 5.86e-01 (6.70e-01)
INFO 2025-05-19 12:23:08,946 trainer.py: 950: Estimated time remaining: 00d 02h 11m
INFO 2025-05-19 12:23:08,946 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:23:08,948 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6846312269568443, 'Losses/train_all_loss_mask': 0.0007292082926142029, 'Losses/train_all_loss_dice': 0.44162501990795133, 'Losses/train_all_loss_iou': 0.22842203378677367, 'Losses/train_all_loss_class': 2.1433235053436307e-08, 'Losses/train_all_core_loss': 0.6846312269568443, 'Trainer/where': 0.36975, 'Trainer/epoch': 73, 'Trainer/steps_train': 1480}
INFO 2025-05-19 12:23:23,629 train_utils.py: 271: Train Epoch: [74][ 0/20] | Batch Time: 12.68 (12.68) | Data Time: 9.80 (9.80) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 5.39e-01 (5.39e-01)
INFO 2025-05-19 12:23:49,991 train_utils.py: 271: Train Epoch: [74][10/20] | Batch Time: 2.68 (3.55) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 5.31e-01 (6.97e-01)
INFO 2025-05-19 12:24:14,733 trainer.py: 950: Estimated time remaining: 00d 02h 11m
INFO 2025-05-19 12:24:14,734 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:24:14,734 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6515526831150055, 'Losses/train_all_loss_mask': 0.0008265116004622542, 'Losses/train_all_loss_dice': 0.41901508122682574, 'Losses/train_all_loss_iou': 0.21600735411047936, 'Losses/train_all_loss_class': 1.5111758666641607e-08, 'Losses/train_all_core_loss': 0.6515526831150055, 'Trainer/where': 0.37475, 'Trainer/epoch': 74, 'Trainer/steps_train': 1500}
INFO 2025-05-19 12:24:29,744 train_utils.py: 271: Train Epoch: [75][ 0/20] | Batch Time: 12.91 (12.91) | Data Time: 9.78 (9.78) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 5.51e-01 (5.51e-01)
INFO 2025-05-19 12:24:56,110 train_utils.py: 271: Train Epoch: [75][10/20] | Batch Time: 2.69 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 6.41e-01 (6.80e-01)
INFO 2025-05-19 12:25:20,550 trainer.py: 950: Estimated time remaining: 00d 02h 10m
INFO 2025-05-19 12:25:20,551 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:25:20,551 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6447787150740624, 'Losses/train_all_loss_mask': 0.0007677422036067583, 'Losses/train_all_loss_dice': 0.41655502319335935, 'Losses/train_all_loss_iou': 0.2128688506782055, 'Losses/train_all_loss_class': 1.6423802473575223e-08, 'Losses/train_all_core_loss': 0.6447787150740624, 'Trainer/where': 0.37975000000000003, 'Trainer/epoch': 75, 'Trainer/steps_train': 1520}
INFO 2025-05-19 12:25:35,533 train_utils.py: 271: Train Epoch: [76][ 0/20] | Batch Time: 12.96 (12.96) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 41m | Losses/train_all_loss: 4.95e-01 (4.95e-01)
INFO 2025-05-19 12:26:01,973 train_utils.py: 271: Train Epoch: [76][10/20] | Batch Time: 2.70 (3.58) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 41m | Losses/train_all_loss: 5.25e-01 (6.65e-01)
INFO 2025-05-19 12:26:26,414 trainer.py: 950: Estimated time remaining: 00d 02h 09m
INFO 2025-05-19 12:26:26,414 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:26:26,414 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6558695495128631, 'Losses/train_all_loss_mask': 0.0007307537933229468, 'Losses/train_all_loss_dice': 0.422250472009182, 'Losses/train_all_loss_iou': 0.2190040022134781, 'Losses/train_all_loss_class': 1.606092294714756e-08, 'Losses/train_all_core_loss': 0.6558695495128631, 'Trainer/where': 0.38475000000000004, 'Trainer/epoch': 76, 'Trainer/steps_train': 1540}
INFO 2025-05-19 12:26:41,418 train_utils.py: 271: Train Epoch: [77][ 0/20] | Batch Time: 12.89 (12.89) | Data Time: 9.94 (9.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 42m | Losses/train_all_loss: 6.40e-01 (6.40e-01)
INFO 2025-05-19 12:27:07,676 train_utils.py: 271: Train Epoch: [77][10/20] | Batch Time: 2.59 (3.56) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 43m | Losses/train_all_loss: 6.26e-01 (6.09e-01)
INFO 2025-05-19 12:27:32,147 trainer.py: 950: Estimated time remaining: 00d 02h 07m
INFO 2025-05-19 12:27:32,148 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:27:32,148 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6224823832511902, 'Losses/train_all_loss_mask': 0.0007474347381503321, 'Losses/train_all_loss_dice': 0.401663513481617, 'Losses/train_all_loss_iou': 0.2058701578527689, 'Losses/train_all_loss_class': 1.884908631399895e-08, 'Losses/train_all_core_loss': 0.6224823832511902, 'Trainer/where': 0.38975000000000004, 'Trainer/epoch': 77, 'Trainer/steps_train': 1560}
INFO 2025-05-19 12:27:47,154 train_utils.py: 271: Train Epoch: [78][ 0/20] | Batch Time: 13.01 (13.01) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 43m | Losses/train_all_loss: 6.71e-01 (6.71e-01)
INFO 2025-05-19 12:28:13,717 train_utils.py: 271: Train Epoch: [78][10/20] | Batch Time: 2.68 (3.60) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 44m | Losses/train_all_loss: 1.02e+00 (6.20e-01)
INFO 2025-05-19 12:28:38,013 trainer.py: 950: Estimated time remaining: 00d 02h 07m
INFO 2025-05-19 12:28:38,014 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:28:38,014 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6846298098564148, 'Losses/train_all_loss_mask': 0.0008898249245248735, 'Losses/train_all_loss_dice': 0.44103579968214035, 'Losses/train_all_loss_iou': 0.22579750716686248, 'Losses/train_all_loss_class': 1.8287629388602512e-08, 'Losses/train_all_core_loss': 0.6846298098564148, 'Trainer/where': 0.39475, 'Trainer/epoch': 78, 'Trainer/steps_train': 1580}
INFO 2025-05-19 12:28:52,832 train_utils.py: 271: Train Epoch: [79][ 0/20] | Batch Time: 12.75 (12.75) | Data Time: 9.80 (9.80) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 44m | Losses/train_all_loss: 1.22e+00 (1.22e+00)
INFO 2025-05-19 12:29:19,111 train_utils.py: 271: Train Epoch: [79][10/20] | Batch Time: 2.68 (3.55) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 45m | Losses/train_all_loss: 4.85e-01 (6.32e-01)
INFO 2025-05-19 12:29:43,413 trainer.py: 950: Estimated time remaining: 00d 02h 05m
INFO 2025-05-19 12:29:43,413 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:29:43,414 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6535977497696877, 'Losses/train_all_loss_mask': 0.0007648299462744035, 'Losses/train_all_loss_dice': 0.4245960861444473, 'Losses/train_all_loss_iou': 0.2137050647288561, 'Losses/train_all_loss_class': 1.3303561430255683e-08, 'Losses/train_all_core_loss': 0.6535977497696877, 'Trainer/where': 0.39975, 'Trainer/epoch': 79, 'Trainer/steps_train': 1600}
INFO 2025-05-19 12:29:58,479 train_utils.py: 271: Train Epoch: [80][ 0/20] | Batch Time: 13.07 (13.07) | Data Time: 9.97 (9.97) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 45m | Losses/train_all_loss: 6.53e-01 (6.53e-01)
INFO 2025-05-19 12:30:25,032 train_utils.py: 271: Train Epoch: [80][10/20] | Batch Time: 2.53 (3.60) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 6.26e-01 (6.52e-01)
INFO 2025-05-19 12:30:49,560 trainer.py: 950: Estimated time remaining: 00d 02h 05m
INFO 2025-05-19 12:30:49,561 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:30:49,561 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6621765345335007, 'Losses/train_all_loss_mask': 0.0007480114378267899, 'Losses/train_all_loss_dice': 0.4296425864100456, 'Losses/train_all_loss_iou': 0.21757370717823504, 'Losses/train_all_loss_class': 1.9011499330368053e-08, 'Losses/train_all_core_loss': 0.6621765345335007, 'Trainer/where': 0.40475, 'Trainer/epoch': 80, 'Trainer/steps_train': 1620}
INFO 2025-05-19 12:31:04,232 train_utils.py: 271: Train Epoch: [81][ 0/20] | Batch Time: 12.65 (12.65) | Data Time: 9.60 (9.60) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 4.80e-01 (4.80e-01)
INFO 2025-05-19 12:31:30,578 train_utils.py: 271: Train Epoch: [81][10/20] | Batch Time: 2.60 (3.55) | Data Time: 0.00 (0.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 47m | Losses/train_all_loss: 7.61e-01 (6.07e-01)
INFO 2025-05-19 12:31:54,574 trainer.py: 950: Estimated time remaining: 00d 02h 02m
INFO 2025-05-19 12:31:54,574 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:31:54,574 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6620648741722107, 'Losses/train_all_loss_mask': 0.0007920609205029905, 'Losses/train_all_loss_dice': 0.429428531229496, 'Losses/train_all_loss_iou': 0.2167951263487339, 'Losses/train_all_loss_class': 1.29636525958432e-08, 'Losses/train_all_core_loss': 0.6620648741722107, 'Trainer/where': 0.40975, 'Trainer/epoch': 81, 'Trainer/steps_train': 1640}
INFO 2025-05-19 12:32:09,314 train_utils.py: 271: Train Epoch: [82][ 0/20] | Batch Time: 12.75 (12.75) | Data Time: 9.78 (9.78) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 48m | Losses/train_all_loss: 6.15e-01 (6.15e-01)
INFO 2025-05-19 12:32:35,805 train_utils.py: 271: Train Epoch: [82][10/20] | Batch Time: 2.81 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 48m | Losses/train_all_loss: 1.06e+00 (7.01e-01)
INFO 2025-05-19 12:33:03,102 trainer.py: 950: Estimated time remaining: 00d 02h 08m
INFO 2025-05-19 12:33:03,103 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:33:03,103 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6357948586344719, 'Losses/train_all_loss_mask': 0.000774724867369514, 'Losses/train_all_loss_dice': 0.4135421201586723, 'Losses/train_all_loss_iou': 0.20675823837518692, 'Losses/train_all_loss_class': 1.5817948528784596e-08, 'Losses/train_all_core_loss': 0.6357948586344719, 'Trainer/where': 0.41475, 'Trainer/epoch': 82, 'Trainer/steps_train': 1660}
INFO 2025-05-19 12:33:18,140 train_utils.py: 271: Train Epoch: [83][ 0/20] | Batch Time: 12.90 (12.90) | Data Time: 9.91 (9.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 49m | Losses/train_all_loss: 7.58e-01 (7.58e-01)
INFO 2025-05-19 12:33:45,115 train_utils.py: 271: Train Epoch: [83][10/20] | Batch Time: 2.69 (3.62) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 49m | Losses/train_all_loss: 6.16e-01 (6.09e-01)
INFO 2025-05-19 12:34:09,405 trainer.py: 950: Estimated time remaining: 00d 02h 02m
INFO 2025-05-19 12:34:09,406 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:34:09,406 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6686391070485115, 'Losses/train_all_loss_mask': 0.0007915187467006035, 'Losses/train_all_loss_dice': 0.4231017932295799, 'Losses/train_all_loss_iou': 0.2297069363296032, 'Losses/train_all_loss_class': 1.5850532508743242e-08, 'Losses/train_all_core_loss': 0.6686391070485115, 'Trainer/where': 0.41975, 'Trainer/epoch': 83, 'Trainer/steps_train': 1680}
INFO 2025-05-19 12:34:24,377 train_utils.py: 271: Train Epoch: [84][ 0/20] | Batch Time: 12.92 (12.92) | Data Time: 9.85 (9.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 50m | Losses/train_all_loss: 5.02e-01 (5.02e-01)
INFO 2025-05-19 12:34:51,133 train_utils.py: 271: Train Epoch: [84][10/20] | Batch Time: 2.64 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 50m | Losses/train_all_loss: 6.75e-01 (6.01e-01)
INFO 2025-05-19 12:35:15,572 trainer.py: 950: Estimated time remaining: 00d 02h 01m
INFO 2025-05-19 12:35:15,572 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:35:15,572 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6233205407857895, 'Losses/train_all_loss_mask': 0.0007680480746785178, 'Losses/train_all_loss_dice': 0.40540017932653427, 'Losses/train_all_loss_iou': 0.2025593440979719, 'Losses/train_all_loss_class': 6.480547694032169e-08, 'Losses/train_all_core_loss': 0.6233205407857895, 'Trainer/where': 0.42475, 'Trainer/epoch': 84, 'Trainer/steps_train': 1700}
INFO 2025-05-19 12:35:30,553 train_utils.py: 271: Train Epoch: [85][ 0/20] | Batch Time: 12.94 (12.94) | Data Time: 9.83 (9.83) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 51m | Losses/train_all_loss: 5.37e-01 (5.37e-01)
INFO 2025-05-19 12:35:57,131 train_utils.py: 271: Train Epoch: [85][10/20] | Batch Time: 2.64 (3.59) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 51m | Losses/train_all_loss: 7.84e-01 (7.09e-01)
INFO 2025-05-19 12:36:21,751 trainer.py: 950: Estimated time remaining: 00d 02h 00m
INFO 2025-05-19 12:36:21,752 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:36:21,752 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6651160985231399, 'Losses/train_all_loss_mask': 0.0007204023451777176, 'Losses/train_all_loss_dice': 0.4338798314332962, 'Losses/train_all_loss_iou': 0.21682821363210678, 'Losses/train_all_loss_class': 1.2591014120211241e-08, 'Losses/train_all_core_loss': 0.6651160985231399, 'Trainer/where': 0.42975, 'Trainer/epoch': 85, 'Trainer/steps_train': 1720}
INFO 2025-05-19 12:36:36,744 train_utils.py: 271: Train Epoch: [86][ 0/20] | Batch Time: 13.02 (13.02) | Data Time: 9.88 (9.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 52m | Losses/train_all_loss: 4.83e-01 (4.83e-01)
INFO 2025-05-19 12:37:03,653 train_utils.py: 271: Train Epoch: [86][10/20] | Batch Time: 2.61 (3.63) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 52m | Losses/train_all_loss: 6.60e-01 (6.79e-01)
INFO 2025-05-19 12:37:28,105 trainer.py: 950: Estimated time remaining: 00d 01h 59m
INFO 2025-05-19 12:37:28,106 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:37:28,106 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.669617335498333, 'Losses/train_all_loss_mask': 0.0008194229594664648, 'Losses/train_all_loss_dice': 0.4274120062589645, 'Losses/train_all_loss_iou': 0.22581686228513717, 'Losses/train_all_loss_class': 1.5935098929276136e-08, 'Losses/train_all_core_loss': 0.669617335498333, 'Trainer/where': 0.43475, 'Trainer/epoch': 86, 'Trainer/steps_train': 1740}
INFO 2025-05-19 12:37:43,026 train_utils.py: 271: Train Epoch: [87][ 0/20] | Batch Time: 12.92 (12.92) | Data Time: 9.84 (9.84) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 53m | Losses/train_all_loss: 7.08e-01 (7.08e-01)
INFO 2025-05-19 12:38:09,873 train_utils.py: 271: Train Epoch: [87][10/20] | Batch Time: 2.71 (3.61) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 54m | Losses/train_all_loss: 6.78e-01 (7.05e-01)
INFO 2025-05-19 12:38:34,540 trainer.py: 950: Estimated time remaining: 00d 01h 58m
INFO 2025-05-19 12:38:34,540 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:38:34,541 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7263198986649513, 'Losses/train_all_loss_mask': 0.0007756873543257825, 'Losses/train_all_loss_dice': 0.45496358573436735, 'Losses/train_all_loss_iou': 0.2558425724506378, 'Losses/train_all_loss_class': 1.6187920870436302e-08, 'Losses/train_all_core_loss': 0.7263198986649513, 'Trainer/where': 0.43975000000000003, 'Trainer/epoch': 87, 'Trainer/steps_train': 1760}
INFO 2025-05-19 12:38:49,436 train_utils.py: 271: Train Epoch: [88][ 0/20] | Batch Time: 12.86 (12.86) | Data Time: 9.84 (9.84) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 54m | Losses/train_all_loss: 6.18e-01 (6.18e-01)
INFO 2025-05-19 12:39:15,955 train_utils.py: 271: Train Epoch: [88][10/20] | Batch Time: 2.55 (3.58) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 55m | Losses/train_all_loss: 4.53e-01 (5.81e-01)
INFO 2025-05-19 12:39:40,396 trainer.py: 950: Estimated time remaining: 00d 01h 56m
INFO 2025-05-19 12:39:40,397 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:39:40,397 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6497891008853912, 'Losses/train_all_loss_mask': 0.0008240457333158702, 'Losses/train_all_loss_dice': 0.41705049872398375, 'Losses/train_all_loss_iou': 0.21625768542289733, 'Losses/train_all_loss_class': 1.6233198030235484e-08, 'Losses/train_all_core_loss': 0.6497891008853912, 'Trainer/where': 0.44475000000000003, 'Trainer/epoch': 88, 'Trainer/steps_train': 1780}
INFO 2025-05-19 12:39:55,210 train_utils.py: 271: Train Epoch: [89][ 0/20] | Batch Time: 12.84 (12.84) | Data Time: 9.85 (9.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 55m | Losses/train_all_loss: 5.55e-01 (5.55e-01)
INFO 2025-05-19 12:40:21,779 train_utils.py: 271: Train Epoch: [89][10/20] | Batch Time: 2.65 (3.58) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 56m | Losses/train_all_loss: 7.11e-01 (7.27e-01)
INFO 2025-05-19 12:40:46,436 trainer.py: 950: Estimated time remaining: 00d 01h 56m
INFO 2025-05-19 12:40:46,437 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:40:46,437 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7079478666186333, 'Losses/train_all_loss_mask': 0.0008922807872295379, 'Losses/train_all_loss_dice': 0.45266795456409453, 'Losses/train_all_loss_iou': 0.237434296682477, 'Losses/train_all_loss_class': 1.2102705926331225e-08, 'Losses/train_all_core_loss': 0.7079478666186333, 'Trainer/where': 0.44975000000000004, 'Trainer/epoch': 89, 'Trainer/steps_train': 1800}
INFO 2025-05-19 12:41:01,463 train_utils.py: 271: Train Epoch: [90][ 0/20] | Batch Time: 12.97 (12.97) | Data Time: 9.85 (9.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 56m | Losses/train_all_loss: 8.13e-01 (8.13e-01)
INFO 2025-05-19 12:41:28,080 train_utils.py: 271: Train Epoch: [90][10/20] | Batch Time: 2.71 (3.60) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 57m | Losses/train_all_loss: 4.98e-01 (6.23e-01)
INFO 2025-05-19 12:41:52,681 trainer.py: 950: Estimated time remaining: 00d 01h 55m
INFO 2025-05-19 12:41:52,682 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:41:52,682 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6209983885288238, 'Losses/train_all_loss_mask': 0.0007362391450442373, 'Losses/train_all_loss_dice': 0.40454151928424836, 'Losses/train_all_loss_iou': 0.20173208154737948, 'Losses/train_all_loss_class': 1.4554326654980798e-08, 'Losses/train_all_core_loss': 0.6209983885288238, 'Trainer/where': 0.45475, 'Trainer/epoch': 90, 'Trainer/steps_train': 1820}
INFO 2025-05-19 12:42:07,635 train_utils.py: 271: Train Epoch: [91][ 0/20] | Batch Time: 12.87 (12.87) | Data Time: 9.84 (9.84) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 58m | Losses/train_all_loss: 6.94e-01 (6.94e-01)
INFO 2025-05-19 12:42:34,176 train_utils.py: 271: Train Epoch: [91][10/20] | Batch Time: 2.62 (3.58) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 58m | Losses/train_all_loss: 9.88e-01 (7.18e-01)
INFO 2025-05-19 12:42:58,624 trainer.py: 950: Estimated time remaining: 00d 01h 53m
INFO 2025-05-19 12:42:58,625 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:42:58,625 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7096288561820984, 'Losses/train_all_loss_mask': 0.0008095792523818091, 'Losses/train_all_loss_dice': 0.45196966230869295, 'Losses/train_all_loss_iou': 0.2414676085114479, 'Losses/train_all_loss_class': 1.56409611595798e-08, 'Losses/train_all_core_loss': 0.7096288561820984, 'Trainer/where': 0.45975, 'Trainer/epoch': 91, 'Trainer/steps_train': 1840}
INFO 2025-05-19 12:43:13,593 train_utils.py: 271: Train Epoch: [92][ 0/20] | Batch Time: 12.90 (12.90) | Data Time: 9.83 (9.83) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 59m | Losses/train_all_loss: 5.28e-01 (5.28e-01)
INFO 2025-05-19 12:43:40,139 train_utils.py: 271: Train Epoch: [92][10/20] | Batch Time: 2.73 (3.59) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 59m | Losses/train_all_loss: 5.34e-01 (6.82e-01)
INFO 2025-05-19 12:44:04,747 trainer.py: 950: Estimated time remaining: 00d 01h 52m
INFO 2025-05-19 12:44:04,747 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:44:04,748 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7045406416058541, 'Losses/train_all_loss_mask': 0.0009181889035971835, 'Losses/train_all_loss_dice': 0.45013847574591637, 'Losses/train_all_loss_iou': 0.23603837341070175, 'Losses/train_all_loss_class': 1.8515042576883188e-08, 'Losses/train_all_core_loss': 0.7045406416058541, 'Trainer/where': 0.46475, 'Trainer/epoch': 92, 'Trainer/steps_train': 1860}
INFO 2025-05-19 12:44:19,773 train_utils.py: 271: Train Epoch: [93][ 0/20] | Batch Time: 12.98 (12.98) | Data Time: 9.82 (9.82) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 00m | Losses/train_all_loss: 4.72e-01 (4.72e-01)
INFO 2025-05-19 12:44:46,161 train_utils.py: 271: Train Epoch: [93][10/20] | Batch Time: 2.58 (3.58) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 00m | Losses/train_all_loss: 8.89e-01 (6.64e-01)
INFO 2025-05-19 12:45:10,908 trainer.py: 950: Estimated time remaining: 00d 01h 51m
INFO 2025-05-19 12:45:10,908 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:45:10,908 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6709522247314453, 'Losses/train_all_loss_mask': 0.0007754082238534465, 'Losses/train_all_loss_dice': 0.4303137190639973, 'Losses/train_all_loss_iou': 0.22513032965362073, 'Losses/train_all_loss_class': 1.4056520192262667e-08, 'Losses/train_all_core_loss': 0.6709522247314453, 'Trainer/where': 0.46975, 'Trainer/epoch': 93, 'Trainer/steps_train': 1880}
INFO 2025-05-19 12:45:25,745 train_utils.py: 271: Train Epoch: [94][ 0/20] | Batch Time: 12.85 (12.85) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 01m | Losses/train_all_loss: 8.54e-01 (8.54e-01)
INFO 2025-05-19 12:45:52,204 train_utils.py: 271: Train Epoch: [94][10/20] | Batch Time: 2.56 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 01m | Losses/train_all_loss: 8.56e-01 (6.83e-01)
INFO 2025-05-19 12:46:16,786 trainer.py: 950: Estimated time remaining: 00d 01h 50m
INFO 2025-05-19 12:46:16,786 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:46:16,786 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6688868910074234, 'Losses/train_all_loss_mask': 0.0008319341839523986, 'Losses/train_all_loss_dice': 0.42513643205165863, 'Losses/train_all_loss_iou': 0.22711177505552768, 'Losses/train_all_loss_class': 1.5481061821365216e-08, 'Losses/train_all_core_loss': 0.6688868910074234, 'Trainer/where': 0.47475, 'Trainer/epoch': 94, 'Trainer/steps_train': 1900}
INFO 2025-05-19 12:46:31,997 train_utils.py: 271: Train Epoch: [95][ 0/20] | Batch Time: 13.12 (13.12) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 02m | Losses/train_all_loss: 4.76e-01 (4.76e-01)
INFO 2025-05-19 12:46:58,595 train_utils.py: 271: Train Epoch: [95][10/20] | Batch Time: 2.62 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 02m | Losses/train_all_loss: 5.60e-01 (6.40e-01)
INFO 2025-05-19 12:47:23,059 trainer.py: 950: Estimated time remaining: 00d 01h 49m
INFO 2025-05-19 12:47:23,059 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:47:23,059 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6277114018797875, 'Losses/train_all_loss_mask': 0.000762237013259437, 'Losses/train_all_loss_dice': 0.40695681124925615, 'Losses/train_all_loss_iou': 0.20550984889268875, 'Losses/train_all_loss_class': 1.1782172459895435e-08, 'Losses/train_all_core_loss': 0.6277114018797875, 'Trainer/where': 0.47975, 'Trainer/epoch': 95, 'Trainer/steps_train': 1920}
INFO 2025-05-19 12:47:38,047 train_utils.py: 271: Train Epoch: [96][ 0/20] | Batch Time: 12.90 (12.90) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 03m | Losses/train_all_loss: 7.14e-01 (7.14e-01)
INFO 2025-05-19 12:48:04,648 train_utils.py: 271: Train Epoch: [96][10/20] | Batch Time: 2.62 (3.59) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 03m | Losses/train_all_loss: 6.07e-01 (6.69e-01)
INFO 2025-05-19 12:48:29,059 trainer.py: 950: Estimated time remaining: 00d 01h 48m
INFO 2025-05-19 12:48:29,059 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:48:29,060 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6381695672869683, 'Losses/train_all_loss_mask': 0.0007294728275155649, 'Losses/train_all_loss_dice': 0.4115451581776142, 'Losses/train_all_loss_iou': 0.2120349496603012, 'Losses/train_all_loss_class': 1.276863870192102e-08, 'Losses/train_all_core_loss': 0.6381695672869683, 'Trainer/where': 0.48475, 'Trainer/epoch': 96, 'Trainer/steps_train': 1940}
INFO 2025-05-19 12:48:44,227 train_utils.py: 271: Train Epoch: [97][ 0/20] | Batch Time: 13.04 (13.04) | Data Time: 9.94 (9.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 04m | Losses/train_all_loss: 9.87e-01 (9.87e-01)
INFO 2025-05-19 12:49:10,667 train_utils.py: 271: Train Epoch: [97][10/20] | Batch Time: 2.61 (3.59) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 05m | Losses/train_all_loss: 8.76e-01 (7.64e-01)
INFO 2025-05-19 12:49:35,279 trainer.py: 950: Estimated time remaining: 00d 01h 47m
INFO 2025-05-19 12:49:35,280 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:49:35,280 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7205877870321273, 'Losses/train_all_loss_mask': 0.0008005678857443855, 'Losses/train_all_loss_dice': 0.4611593455076218, 'Losses/train_all_loss_iou': 0.24341707453131675, 'Losses/train_all_loss_class': 1.826233942958666e-08, 'Losses/train_all_core_loss': 0.7205877870321273, 'Trainer/where': 0.48975, 'Trainer/epoch': 97, 'Trainer/steps_train': 1960}
INFO 2025-05-19 12:49:50,224 train_utils.py: 271: Train Epoch: [98][ 0/20] | Batch Time: 12.85 (12.85) | Data Time: 9.85 (9.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 05m | Losses/train_all_loss: 6.16e-01 (6.16e-01)
INFO 2025-05-19 12:50:16,849 train_utils.py: 271: Train Epoch: [98][10/20] | Batch Time: 2.61 (3.59) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 06m | Losses/train_all_loss: 1.17e+00 (7.21e-01)
INFO 2025-05-19 12:50:41,504 trainer.py: 950: Estimated time remaining: 00d 01h 46m
INFO 2025-05-19 12:50:41,504 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:50:41,504 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6738546475768089, 'Losses/train_all_loss_mask': 0.0007832227056496777, 'Losses/train_all_loss_dice': 0.4420443385839462, 'Losses/train_all_loss_iou': 0.21614585295319558, 'Losses/train_all_loss_class': 1.315052005068651e-08, 'Losses/train_all_core_loss': 0.6738546475768089, 'Trainer/where': 0.49475, 'Trainer/epoch': 98, 'Trainer/steps_train': 1980}
INFO 2025-05-19 12:50:56,094 train_utils.py: 271: Train Epoch: [99][ 0/20] | Batch Time: 12.44 (12.44) | Data Time: 9.35 (9.35) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 06m | Losses/train_all_loss: 5.47e-01 (5.47e-01)
INFO 2025-05-19 12:51:22,723 train_utils.py: 271: Train Epoch: [99][10/20] | Batch Time: 2.59 (3.55) | Data Time: 0.00 (0.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 07m | Losses/train_all_loss: 1.09e+00 (6.68e-01)
INFO 2025-05-19 12:51:47,536 trainer.py: 950: Estimated time remaining: 00d 01h 45m
INFO 2025-05-19 12:51:47,537 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:51:47,537 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6400269269943237, 'Losses/train_all_loss_mask': 0.0006890233227750287, 'Losses/train_all_loss_dice': 0.4056158348917961, 'Losses/train_all_loss_iou': 0.22063062377274037, 'Losses/train_all_loss_class': 1.5245166506971942e-08, 'Losses/train_all_core_loss': 0.6400269269943237, 'Trainer/where': 0.49975, 'Trainer/epoch': 99, 'Trainer/steps_train': 2000}
INFO 2025-05-19 12:52:02,658 train_utils.py: 271: Train Epoch: [100][ 0/20] | Batch Time: 13.05 (13.05) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 07m | Losses/train_all_loss: 5.59e-01 (5.59e-01)
INFO 2025-05-19 12:52:29,331 train_utils.py: 271: Train Epoch: [100][10/20] | Batch Time: 2.61 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 08m | Losses/train_all_loss: 4.47e-01 (5.87e-01)
INFO 2025-05-19 12:52:53,868 trainer.py: 950: Estimated time remaining: 00d 01h 44m
INFO 2025-05-19 12:52:53,868 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:52:53,868 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6528125628829002, 'Losses/train_all_loss_mask': 0.0008722899103304372, 'Losses/train_all_loss_dice': 0.42889508977532387, 'Losses/train_all_loss_iou': 0.20647166296839714, 'Losses/train_all_loss_class': 1.4763167355269502e-08, 'Losses/train_all_core_loss': 0.6528125628829002, 'Trainer/where': 0.50475, 'Trainer/epoch': 100, 'Trainer/steps_train': 2020}
INFO 2025-05-19 12:53:08,607 train_utils.py: 271: Train Epoch: [101][ 0/20] | Batch Time: 12.61 (12.61) | Data Time: 9.49 (9.49) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 09m | Losses/train_all_loss: 4.26e-01 (4.26e-01)
INFO 2025-05-19 12:53:35,382 train_utils.py: 271: Train Epoch: [101][10/20] | Batch Time: 2.59 (3.58) | Data Time: 0.00 (0.86) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 09m | Losses/train_all_loss: 5.48e-01 (5.81e-01)
INFO 2025-05-19 12:53:59,669 trainer.py: 950: Estimated time remaining: 00d 01h 42m
INFO 2025-05-19 12:53:59,669 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:53:59,669 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.616519433259964, 'Losses/train_all_loss_mask': 0.0006680089441942983, 'Losses/train_all_loss_dice': 0.4062202960252762, 'Losses/train_all_loss_iou': 0.1969389535486698, 'Losses/train_all_loss_class': 1.575964334588065e-08, 'Losses/train_all_core_loss': 0.616519433259964, 'Trainer/where': 0.50975, 'Trainer/epoch': 101, 'Trainer/steps_train': 2040}
INFO 2025-05-19 12:54:14,594 train_utils.py: 271: Train Epoch: [102][ 0/20] | Batch Time: 12.86 (12.86) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 10m | Losses/train_all_loss: 4.73e-01 (4.73e-01)
INFO 2025-05-19 12:54:41,057 train_utils.py: 271: Train Epoch: [102][10/20] | Batch Time: 2.68 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 10m | Losses/train_all_loss: 5.14e-01 (6.08e-01)
INFO 2025-05-19 12:55:05,370 trainer.py: 950: Estimated time remaining: 00d 01h 41m
INFO 2025-05-19 12:55:05,370 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:55:05,370 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6402983665466309, 'Losses/train_all_loss_mask': 0.0007459451342583634, 'Losses/train_all_loss_dice': 0.41787168085575105, 'Losses/train_all_loss_iou': 0.20750778391957284, 'Losses/train_all_loss_class': 1.8963566628116267e-08, 'Losses/train_all_core_loss': 0.6402983665466309, 'Trainer/where': 0.51475, 'Trainer/epoch': 102, 'Trainer/steps_train': 2060}
INFO 2025-05-19 12:55:19,645 train_utils.py: 271: Train Epoch: [103][ 0/20] | Batch Time: 12.24 (12.24) | Data Time: 9.35 (9.35) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 11m | Losses/train_all_loss: 5.49e-01 (5.49e-01)
INFO 2025-05-19 12:55:46,124 train_utils.py: 271: Train Epoch: [103][10/20] | Batch Time: 2.58 (3.52) | Data Time: 0.00 (0.85) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 11m | Losses/train_all_loss: 7.45e-01 (7.02e-01)
INFO 2025-05-19 12:56:10,353 trainer.py: 950: Estimated time remaining: 00d 01h 39m
INFO 2025-05-19 12:56:10,353 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:56:10,353 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6743215098977089, 'Losses/train_all_loss_mask': 0.0008300197892822325, 'Losses/train_all_loss_dice': 0.4278341084718704, 'Losses/train_all_loss_iou': 0.22988700419664382, 'Losses/train_all_loss_class': 1.4395039205084004e-08, 'Losses/train_all_core_loss': 0.6743215098977089, 'Trainer/where': 0.51975, 'Trainer/epoch': 103, 'Trainer/steps_train': 2080}
INFO 2025-05-19 12:56:25,250 train_utils.py: 271: Train Epoch: [104][ 0/20] | Batch Time: 12.86 (12.86) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 12m | Losses/train_all_loss: 8.87e-01 (8.87e-01)
INFO 2025-05-19 12:56:51,633 train_utils.py: 271: Train Epoch: [104][10/20] | Batch Time: 2.68 (3.57) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 12m | Losses/train_all_loss: 5.45e-01 (6.56e-01)
INFO 2025-05-19 12:57:16,078 trainer.py: 950: Estimated time remaining: 00d 01h 39m
INFO 2025-05-19 12:57:16,079 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:57:16,079 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6557840749621391, 'Losses/train_all_loss_mask': 0.000791686242155265, 'Losses/train_all_loss_dice': 0.4158869758248329, 'Losses/train_all_loss_iou': 0.22406335547566414, 'Losses/train_all_loss_class': 1.8613637786657478e-08, 'Losses/train_all_core_loss': 0.6557840749621391, 'Trainer/where': 0.52475, 'Trainer/epoch': 104, 'Trainer/steps_train': 2100}
INFO 2025-05-19 12:57:30,928 train_utils.py: 271: Train Epoch: [105][ 0/20] | Batch Time: 12.80 (12.80) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 13m | Losses/train_all_loss: 5.91e-01 (5.91e-01)
INFO 2025-05-19 12:57:57,448 train_utils.py: 271: Train Epoch: [105][10/20] | Batch Time: 2.71 (3.57) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 13m | Losses/train_all_loss: 4.45e-01 (6.24e-01)
INFO 2025-05-19 12:58:24,306 trainer.py: 950: Estimated time remaining: 00d 01h 42m
INFO 2025-05-19 12:58:24,306 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:58:24,307 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6389990538358689, 'Losses/train_all_loss_mask': 0.0007180175452958792, 'Losses/train_all_loss_dice': 0.41318330615758897, 'Losses/train_all_loss_iou': 0.2114553950726986, 'Losses/train_all_loss_class': 1.8608334495517908e-08, 'Losses/train_all_core_loss': 0.6389990538358689, 'Trainer/where': 0.52975, 'Trainer/epoch': 105, 'Trainer/steps_train': 2120}
INFO 2025-05-19 12:58:40,230 train_utils.py: 271: Train Epoch: [106][ 0/20] | Batch Time: 13.78 (13.78) | Data Time: 10.44 (10.44) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 14m | Losses/train_all_loss: 6.51e-01 (6.51e-01)
INFO 2025-05-19 12:59:12,138 train_utils.py: 271: Train Epoch: [106][10/20] | Batch Time: 2.96 (4.15) | Data Time: 0.00 (0.95) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 15m | Losses/train_all_loss: 6.28e-01 (7.02e-01)
INFO 2025-05-19 12:59:39,723 trainer.py: 950: Estimated time remaining: 00d 01h 52m
INFO 2025-05-19 12:59:39,723 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 12:59:39,724 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.719260323047638, 'Losses/train_all_loss_mask': 0.000821001673466526, 'Losses/train_all_loss_dice': 0.46840453445911406, 'Losses/train_all_loss_iou': 0.23443574085831642, 'Losses/train_all_loss_class': 1.690574162882541e-08, 'Losses/train_all_core_loss': 0.719260323047638, 'Trainer/where': 0.5347500000000001, 'Trainer/epoch': 106, 'Trainer/steps_train': 2140}
INFO 2025-05-19 12:59:56,067 train_utils.py: 271: Train Epoch: [107][ 0/20] | Batch Time: 14.20 (14.20) | Data Time: 10.17 (10.17) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 15m | Losses/train_all_loss: 6.76e-01 (6.76e-01)
INFO 2025-05-19 13:00:32,170 train_utils.py: 271: Train Epoch: [107][10/20] | Batch Time: 3.69 (4.57) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 16m | Losses/train_all_loss: 4.49e-01 (6.18e-01)
INFO 2025-05-19 13:01:05,041 trainer.py: 950: Estimated time remaining: 00d 02h 06m
INFO 2025-05-19 13:01:05,042 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:01:05,042 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.689524433016777, 'Losses/train_all_loss_mask': 0.0008288773417007179, 'Losses/train_all_loss_dice': 0.44535944163799285, 'Losses/train_all_loss_iou': 0.22758743837475776, 'Losses/train_all_loss_class': 1.9882452129138528e-08, 'Losses/train_all_core_loss': 0.689524433016777, 'Trainer/where': 0.5397500000000001, 'Trainer/epoch': 107, 'Trainer/steps_train': 2160}
INFO 2025-05-19 13:01:21,446 train_utils.py: 271: Train Epoch: [108][ 0/20] | Batch Time: 14.31 (14.31) | Data Time: 10.13 (10.13) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 17m | Losses/train_all_loss: 6.66e-01 (6.66e-01)
INFO 2025-05-19 13:01:57,477 train_utils.py: 271: Train Epoch: [108][10/20] | Batch Time: 3.63 (4.58) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 17m | Losses/train_all_loss: 5.77e-01 (6.82e-01)
INFO 2025-05-19 13:02:30,143 trainer.py: 950: Estimated time remaining: 00d 02h 04m
INFO 2025-05-19 13:02:30,145 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:02:30,145 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6954293757677078, 'Losses/train_all_loss_mask': 0.0007257120669237338, 'Losses/train_all_loss_dice': 0.44957794398069384, 'Losses/train_all_loss_iou': 0.23133718147873877, 'Losses/train_all_loss_class': 1.5641597361781833e-08, 'Losses/train_all_core_loss': 0.6954293757677078, 'Trainer/where': 0.5447500000000001, 'Trainer/epoch': 108, 'Trainer/steps_train': 2180}
INFO 2025-05-19 13:02:46,608 train_utils.py: 271: Train Epoch: [109][ 0/20] | Batch Time: 14.29 (14.29) | Data Time: 10.19 (10.19) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 18m | Losses/train_all_loss: 5.41e-01 (5.41e-01)
INFO 2025-05-19 13:03:22,658 train_utils.py: 271: Train Epoch: [109][10/20] | Batch Time: 3.61 (4.58) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 19m | Losses/train_all_loss: 6.32e-01 (6.92e-01)
INFO 2025-05-19 13:03:55,429 trainer.py: 950: Estimated time remaining: 00d 02h 03m
INFO 2025-05-19 13:03:55,430 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:03:55,430 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6868859067559242, 'Losses/train_all_loss_mask': 0.0008475210459437221, 'Losses/train_all_loss_dice': 0.4476551964879036, 'Losses/train_all_loss_iou': 0.2222802795469761, 'Losses/train_all_loss_class': 3.0179729759716165e-08, 'Losses/train_all_core_loss': 0.6868859067559242, 'Trainer/where': 0.54975, 'Trainer/epoch': 109, 'Trainer/steps_train': 2200}
INFO 2025-05-19 13:04:11,683 train_utils.py: 271: Train Epoch: [110][ 0/20] | Batch Time: 14.08 (14.08) | Data Time: 10.15 (10.15) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 20m | Losses/train_all_loss: 6.27e-01 (6.27e-01)
INFO 2025-05-19 13:04:47,543 train_utils.py: 271: Train Epoch: [110][10/20] | Batch Time: 3.62 (4.54) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 20m | Losses/train_all_loss: 5.66e-01 (6.13e-01)
INFO 2025-05-19 13:05:20,381 trainer.py: 950: Estimated time remaining: 00d 02h 01m
INFO 2025-05-19 13:05:20,382 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:05:20,382 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7004920244216919, 'Losses/train_all_loss_mask': 0.0008563435054384172, 'Losses/train_all_loss_dice': 0.4569132745265961, 'Losses/train_all_loss_iou': 0.22645187824964524, 'Losses/train_all_loss_class': 1.746555999826427e-08, 'Losses/train_all_core_loss': 0.7004920244216919, 'Trainer/where': 0.55475, 'Trainer/epoch': 110, 'Trainer/steps_train': 2220}
INFO 2025-05-19 13:05:36,513 train_utils.py: 271: Train Epoch: [111][ 0/20] | Batch Time: 14.00 (14.00) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 21m | Losses/train_all_loss: 5.40e-01 (5.40e-01)
INFO 2025-05-19 13:06:12,180 train_utils.py: 271: Train Epoch: [111][10/20] | Batch Time: 3.55 (4.52) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 22m | Losses/train_all_loss: 5.82e-01 (6.26e-01)
INFO 2025-05-19 13:06:44,657 trainer.py: 950: Estimated time remaining: 00d 01h 59m
INFO 2025-05-19 13:06:44,658 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:06:44,658 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6150026544928551, 'Losses/train_all_loss_mask': 0.0007041101533104665, 'Losses/train_all_loss_dice': 0.40391436517238616, 'Losses/train_all_loss_iou': 0.19700607806444168, 'Losses/train_all_loss_class': 1.924254851015661e-08, 'Losses/train_all_core_loss': 0.6150026544928551, 'Trainer/where': 0.55975, 'Trainer/epoch': 111, 'Trainer/steps_train': 2240}
INFO 2025-05-19 13:07:01,265 train_utils.py: 271: Train Epoch: [112][ 0/20] | Batch Time: 14.11 (14.11) | Data Time: 10.03 (10.03) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 22m | Losses/train_all_loss: 4.64e-01 (4.64e-01)
INFO 2025-05-19 13:07:36,785 train_utils.py: 271: Train Epoch: [112][10/20] | Batch Time: 3.48 (4.51) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 23m | Losses/train_all_loss: 7.33e-01 (5.86e-01)
INFO 2025-05-19 13:08:09,114 trainer.py: 950: Estimated time remaining: 00d 01h 57m
INFO 2025-05-19 13:08:09,115 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:08:09,115 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6680625781416893, 'Losses/train_all_loss_mask': 0.0008032962534343824, 'Losses/train_all_loss_dice': 0.42094114869832994, 'Losses/train_all_loss_iou': 0.23105549737811087, 'Losses/train_all_loss_class': 1.65161850196327e-08, 'Losses/train_all_core_loss': 0.6680625781416893, 'Trainer/where': 0.56475, 'Trainer/epoch': 112, 'Trainer/steps_train': 2260}
INFO 2025-05-19 13:08:25,542 train_utils.py: 271: Train Epoch: [113][ 0/20] | Batch Time: 14.13 (14.13) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 24m | Losses/train_all_loss: 5.90e-01 (5.90e-01)
INFO 2025-05-19 13:09:00,965 train_utils.py: 271: Train Epoch: [113][10/20] | Batch Time: 3.58 (4.51) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 24m | Losses/train_all_loss: 4.94e-01 (6.22e-01)
INFO 2025-05-19 13:09:33,364 trainer.py: 950: Estimated time remaining: 00d 01h 56m
INFO 2025-05-19 13:09:33,364 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:09:33,364 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7589971527457238, 'Losses/train_all_loss_mask': 0.0007962390154716559, 'Losses/train_all_loss_dice': 0.4945330873131752, 'Losses/train_all_loss_iou': 0.24853926226496698, 'Losses/train_all_loss_class': 1.853975052368284e-08, 'Losses/train_all_core_loss': 0.7589971527457238, 'Trainer/where': 0.56975, 'Trainer/epoch': 113, 'Trainer/steps_train': 2280}
INFO 2025-05-19 13:09:49,381 train_utils.py: 271: Train Epoch: [114][ 0/20] | Batch Time: 13.97 (13.97) | Data Time: 10.12 (10.12) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 25m | Losses/train_all_loss: 5.52e-01 (5.52e-01)
INFO 2025-05-19 13:10:24,800 train_utils.py: 271: Train Epoch: [114][10/20] | Batch Time: 3.45 (4.49) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 26m | Losses/train_all_loss: 5.21e-01 (6.39e-01)
INFO 2025-05-19 13:10:57,329 trainer.py: 950: Estimated time remaining: 00d 01h 54m
INFO 2025-05-19 13:10:57,330 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:10:57,330 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6370048612356186, 'Losses/train_all_loss_mask': 0.0007085829711286351, 'Losses/train_all_loss_dice': 0.4132143571972847, 'Losses/train_all_loss_iou': 0.20961882993578912, 'Losses/train_all_loss_class': 1.7439536326158133e-08, 'Losses/train_all_core_loss': 0.6370048612356186, 'Trainer/where': 0.57475, 'Trainer/epoch': 114, 'Trainer/steps_train': 2300}
INFO 2025-05-19 13:11:12,930 train_utils.py: 271: Train Epoch: [115][ 0/20] | Batch Time: 13.56 (13.56) | Data Time: 9.56 (9.56) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 27m | Losses/train_all_loss: 4.39e-01 (4.39e-01)
INFO 2025-05-19 13:11:48,181 train_utils.py: 271: Train Epoch: [115][10/20] | Batch Time: 3.44 (4.44) | Data Time: 0.00 (0.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 27m | Losses/train_all_loss: 7.28e-01 (7.51e-01)
INFO 2025-05-19 13:12:20,543 trainer.py: 950: Estimated time remaining: 00d 01h 52m
INFO 2025-05-19 13:12:20,544 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:12:20,544 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.682231317460537, 'Losses/train_all_loss_mask': 0.0008730229688808322, 'Losses/train_all_loss_dice': 0.4302204668521881, 'Losses/train_all_loss_iou': 0.23455037884414195, 'Losses/train_all_loss_class': 1.1578009329049621e-08, 'Losses/train_all_core_loss': 0.682231317460537, 'Trainer/where': 0.57975, 'Trainer/epoch': 115, 'Trainer/steps_train': 2320}
INFO 2025-05-19 13:12:36,607 train_utils.py: 271: Train Epoch: [116][ 0/20] | Batch Time: 13.96 (13.96) | Data Time: 10.14 (10.14) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 28m | Losses/train_all_loss: 7.60e-01 (7.60e-01)
INFO 2025-05-19 13:13:12,287 train_utils.py: 271: Train Epoch: [116][10/20] | Batch Time: 3.59 (4.51) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 29m | Losses/train_all_loss: 7.95e-01 (6.71e-01)
INFO 2025-05-19 13:13:44,746 trainer.py: 950: Estimated time remaining: 00d 01h 52m
INFO 2025-05-19 13:13:44,747 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:13:44,747 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6413536816835403, 'Losses/train_all_loss_mask': 0.0007590666209580377, 'Losses/train_all_loss_dice': 0.4148261725902557, 'Losses/train_all_loss_iou': 0.21134616509079934, 'Losses/train_all_loss_class': 1.6708786643171435e-08, 'Losses/train_all_core_loss': 0.6413536816835403, 'Trainer/where': 0.58475, 'Trainer/epoch': 116, 'Trainer/steps_train': 2340}
INFO 2025-05-19 13:14:00,933 train_utils.py: 271: Train Epoch: [117][ 0/20] | Batch Time: 13.98 (13.98) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 29m | Losses/train_all_loss: 5.48e-01 (5.48e-01)
INFO 2025-05-19 13:14:36,294 train_utils.py: 271: Train Epoch: [117][10/20] | Batch Time: 3.51 (4.49) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 30m | Losses/train_all_loss: 5.62e-01 (6.13e-01)
INFO 2025-05-19 13:15:08,894 trainer.py: 950: Estimated time remaining: 00d 01h 50m
INFO 2025-05-19 13:15:08,894 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:15:08,894 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6168313503265381, 'Losses/train_all_loss_mask': 0.00073849945620168, 'Losses/train_all_loss_dice': 0.40657650828361513, 'Losses/train_all_loss_iou': 0.19548484720289708, 'Losses/train_all_loss_class': 1.7861380929851123e-08, 'Losses/train_all_core_loss': 0.6168313503265381, 'Trainer/where': 0.58975, 'Trainer/epoch': 117, 'Trainer/steps_train': 2360}
INFO 2025-05-19 13:15:25,125 train_utils.py: 271: Train Epoch: [118][ 0/20] | Batch Time: 14.02 (14.02) | Data Time: 10.06 (10.06) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 31m | Losses/train_all_loss: 6.05e-01 (6.05e-01)
INFO 2025-05-19 13:16:00,281 train_utils.py: 271: Train Epoch: [118][10/20] | Batch Time: 3.45 (4.47) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 31m | Losses/train_all_loss: 9.27e-01 (6.10e-01)
INFO 2025-05-19 13:16:32,711 trainer.py: 950: Estimated time remaining: 00d 01h 49m
INFO 2025-05-19 13:16:32,711 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:16:32,712 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6090268701314926, 'Losses/train_all_loss_mask': 0.0006980236939853057, 'Losses/train_all_loss_dice': 0.4002023309469223, 'Losses/train_all_loss_iou': 0.19486405253410338, 'Losses/train_all_loss_class': 1.668167959323341e-08, 'Losses/train_all_core_loss': 0.6090268701314926, 'Trainer/where': 0.59475, 'Trainer/epoch': 118, 'Trainer/steps_train': 2380}
INFO 2025-05-19 13:16:49,060 train_utils.py: 271: Train Epoch: [119][ 0/20] | Batch Time: 14.23 (14.23) | Data Time: 10.23 (10.23) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 32m | Losses/train_all_loss: 7.17e-01 (7.17e-01)
INFO 2025-05-19 13:17:24,854 train_utils.py: 271: Train Epoch: [119][10/20] | Batch Time: 3.60 (4.55) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 33m | Losses/train_all_loss: 7.83e-01 (6.48e-01)
INFO 2025-05-19 13:17:57,036 trainer.py: 950: Estimated time remaining: 00d 01h 48m
INFO 2025-05-19 13:17:57,036 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:17:57,036 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6419144392013549, 'Losses/train_all_loss_mask': 0.0008365156565560028, 'Losses/train_all_loss_dice': 0.407490973174572, 'Losses/train_all_loss_iou': 0.21769314706325532, 'Losses/train_all_loss_class': 1.728129348510521e-08, 'Losses/train_all_core_loss': 0.6419144392013549, 'Trainer/where': 0.59975, 'Trainer/epoch': 119, 'Trainer/steps_train': 2400}
INFO 2025-05-19 13:18:13,420 train_utils.py: 271: Train Epoch: [120][ 0/20] | Batch Time: 14.14 (14.14) | Data Time: 10.11 (10.11) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 34m | Losses/train_all_loss: 7.80e-01 (7.80e-01)
INFO 2025-05-19 13:18:48,950 train_utils.py: 271: Train Epoch: [120][10/20] | Batch Time: 3.53 (4.52) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 34m | Losses/train_all_loss: 8.45e-01 (7.03e-01)
INFO 2025-05-19 13:19:16,994 trainer.py: 950: Estimated time remaining: 00d 01h 41m
INFO 2025-05-19 13:19:16,994 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:19:16,994 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6616517648100853, 'Losses/train_all_loss_mask': 0.0007300160490558482, 'Losses/train_all_loss_dice': 0.4381896823644638, 'Losses/train_all_loss_iou': 0.2088617604225874, 'Losses/train_all_loss_class': 1.75411336122977e-08, 'Losses/train_all_core_loss': 0.6616517648100853, 'Trainer/where': 0.60475, 'Trainer/epoch': 120, 'Trainer/steps_train': 2420}
INFO 2025-05-19 13:19:32,512 train_utils.py: 271: Train Epoch: [121][ 0/20] | Batch Time: 13.47 (13.47) | Data Time: 10.12 (10.12) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 35m | Losses/train_all_loss: 9.90e-01 (9.90e-01)
INFO 2025-05-19 13:20:01,603 train_utils.py: 271: Train Epoch: [121][10/20] | Batch Time: 2.98 (3.87) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 35m | Losses/train_all_loss: 6.08e-01 (6.57e-01)
INFO 2025-05-19 13:20:28,373 trainer.py: 950: Estimated time remaining: 00d 01h 29m
INFO 2025-05-19 13:20:28,373 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:20:28,374 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6475367367267608, 'Losses/train_all_loss_mask': 0.0007417020096909255, 'Losses/train_all_loss_dice': 0.4175891190767288, 'Losses/train_all_loss_iou': 0.215113565325737, 'Losses/train_all_loss_class': 1.734621135618397e-08, 'Losses/train_all_core_loss': 0.6475367367267608, 'Trainer/where': 0.60975, 'Trainer/epoch': 121, 'Trainer/steps_train': 2440}
INFO 2025-05-19 13:20:43,690 train_utils.py: 271: Train Epoch: [122][ 0/20] | Batch Time: 13.25 (13.25) | Data Time: 10.01 (10.01) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 36m | Losses/train_all_loss: 1.02e+00 (1.02e+00)
INFO 2025-05-19 13:21:12,945 train_utils.py: 271: Train Epoch: [122][10/20] | Batch Time: 2.87 (3.86) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 37m | Losses/train_all_loss: 6.25e-01 (6.06e-01)
INFO 2025-05-19 13:21:39,724 trainer.py: 950: Estimated time remaining: 00d 01h 27m
INFO 2025-05-19 13:21:39,725 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:21:39,725 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.617738527059555, 'Losses/train_all_loss_mask': 0.0007040834883810021, 'Losses/train_all_loss_dice': 0.4049728363752365, 'Losses/train_all_loss_iou': 0.1986840061843395, 'Losses/train_all_loss_class': 1.962900193497319e-08, 'Losses/train_all_core_loss': 0.617738527059555, 'Trainer/where': 0.61475, 'Trainer/epoch': 122, 'Trainer/steps_train': 2460}
INFO 2025-05-19 13:21:55,117 train_utils.py: 271: Train Epoch: [123][ 0/20] | Batch Time: 13.36 (13.36) | Data Time: 10.06 (10.06) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 37m | Losses/train_all_loss: 5.72e-01 (5.72e-01)
INFO 2025-05-19 13:22:24,351 train_utils.py: 271: Train Epoch: [123][10/20] | Batch Time: 2.85 (3.87) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 38m | Losses/train_all_loss: 6.05e-01 (6.26e-01)
INFO 2025-05-19 13:22:51,187 trainer.py: 950: Estimated time remaining: 00d 01h 26m
INFO 2025-05-19 13:22:51,187 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:22:51,188 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6036643013358116, 'Losses/train_all_loss_mask': 0.0006840833520982414, 'Losses/train_all_loss_dice': 0.4013677805662155, 'Losses/train_all_loss_iou': 0.18861484304070472, 'Losses/train_all_loss_class': 2.4609797943941912e-08, 'Losses/train_all_core_loss': 0.6036643013358116, 'Trainer/where': 0.61975, 'Trainer/epoch': 123, 'Trainer/steps_train': 2480}
INFO 2025-05-19 13:23:06,700 train_utils.py: 271: Train Epoch: [124][ 0/20] | Batch Time: 13.49 (13.49) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 39m | Losses/train_all_loss: 5.11e-01 (5.11e-01)
INFO 2025-05-19 13:23:36,022 train_utils.py: 271: Train Epoch: [124][10/20] | Batch Time: 2.99 (3.89) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 39m | Losses/train_all_loss: 5.81e-01 (5.58e-01)
INFO 2025-05-19 13:24:03,078 trainer.py: 950: Estimated time remaining: 00d 01h 26m
INFO 2025-05-19 13:24:03,079 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:24:03,079 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.5927923738956451, 'Losses/train_all_loss_mask': 0.0006881180248456076, 'Losses/train_all_loss_dice': 0.38757405877113343, 'Losses/train_all_loss_iou': 0.19145593903958796, 'Losses/train_all_loss_class': 2.1300932440126986e-08, 'Losses/train_all_core_loss': 0.5927923738956451, 'Trainer/where': 0.62475, 'Trainer/epoch': 124, 'Trainer/steps_train': 2500}
INFO 2025-05-19 13:24:18,499 train_utils.py: 271: Train Epoch: [125][ 0/20] | Batch Time: 13.40 (13.40) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 40m | Losses/train_all_loss: 4.80e-01 (4.80e-01)
INFO 2025-05-19 13:24:47,423 train_utils.py: 271: Train Epoch: [125][10/20] | Batch Time: 2.87 (3.85) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 40m | Losses/train_all_loss: 6.35e-01 (6.30e-01)
INFO 2025-05-19 13:25:14,445 trainer.py: 950: Estimated time remaining: 00d 01h 24m
INFO 2025-05-19 13:25:14,446 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:25:14,446 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6186522290110588, 'Losses/train_all_loss_mask': 0.000736425984359812, 'Losses/train_all_loss_dice': 0.40320640057325363, 'Losses/train_all_loss_iou': 0.20071729868650437, 'Losses/train_all_loss_class': 1.733823125071865e-08, 'Losses/train_all_core_loss': 0.6186522290110588, 'Trainer/where': 0.62975, 'Trainer/epoch': 125, 'Trainer/steps_train': 2520}
INFO 2025-05-19 13:25:30,071 train_utils.py: 271: Train Epoch: [126][ 0/20] | Batch Time: 13.51 (13.51) | Data Time: 10.10 (10.10) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 41m | Losses/train_all_loss: 8.36e-01 (8.36e-01)
INFO 2025-05-19 13:25:59,202 train_utils.py: 271: Train Epoch: [126][10/20] | Batch Time: 2.99 (3.88) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 41m | Losses/train_all_loss: 4.57e-01 (6.16e-01)
INFO 2025-05-19 13:26:28,390 trainer.py: 950: Estimated time remaining: 00d 01h 26m
INFO 2025-05-19 13:26:28,390 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:26:28,390 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6365101665258408, 'Losses/train_all_loss_mask': 0.0007518349870224483, 'Losses/train_all_loss_dice': 0.40935455113649366, 'Losses/train_all_loss_iou': 0.2121189098805189, 'Losses/train_all_loss_class': 2.3764227252698333e-08, 'Losses/train_all_core_loss': 0.6365101665258408, 'Trainer/where': 0.63475, 'Trainer/epoch': 126, 'Trainer/steps_train': 2540}
INFO 2025-05-19 13:26:44,328 train_utils.py: 271: Train Epoch: [127][ 0/20] | Batch Time: 13.70 (13.70) | Data Time: 9.67 (9.67) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 42m | Losses/train_all_loss: 6.49e-01 (6.49e-01)
INFO 2025-05-19 13:27:20,216 train_utils.py: 271: Train Epoch: [127][10/20] | Batch Time: 3.58 (4.51) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 43m | Losses/train_all_loss: 5.20e-01 (6.15e-01)
INFO 2025-05-19 13:27:52,947 trainer.py: 950: Estimated time remaining: 00d 01h 37m
INFO 2025-05-19 13:27:52,947 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:27:52,947 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6548409625887871, 'Losses/train_all_loss_mask': 0.0007829622103599831, 'Losses/train_all_loss_dice': 0.41854374259710314, 'Losses/train_all_loss_iou': 0.22063795998692512, 'Losses/train_all_loss_class': 1.6543433511984063e-08, 'Losses/train_all_core_loss': 0.6548409625887871, 'Trainer/where': 0.63975, 'Trainer/epoch': 127, 'Trainer/steps_train': 2560}
INFO 2025-05-19 13:28:09,106 train_utils.py: 271: Train Epoch: [128][ 0/20] | Batch Time: 14.13 (14.13) | Data Time: 10.14 (10.14) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 44m | Losses/train_all_loss: 5.13e-01 (5.13e-01)
INFO 2025-05-19 13:28:45,324 train_utils.py: 271: Train Epoch: [128][10/20] | Batch Time: 3.57 (4.58) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 44m | Losses/train_all_loss: 7.31e-01 (5.81e-01)
INFO 2025-05-19 13:29:17,843 trainer.py: 950: Estimated time remaining: 00d 01h 37m
INFO 2025-05-19 13:29:17,843 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:29:17,844 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6025124207139015, 'Losses/train_all_loss_mask': 0.000685431674355641, 'Losses/train_all_loss_dice': 0.3976934254169464, 'Losses/train_all_loss_iou': 0.19111035913228988, 'Losses/train_all_loss_class': 1.600520913580539e-08, 'Losses/train_all_core_loss': 0.6025124207139015, 'Trainer/where': 0.6447499999999999, 'Trainer/epoch': 128, 'Trainer/steps_train': 2580}
INFO 2025-05-19 13:29:34,072 train_utils.py: 271: Train Epoch: [129][ 0/20] | Batch Time: 14.18 (14.18) | Data Time: 10.10 (10.10) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 45m | Losses/train_all_loss: 6.16e-01 (6.16e-01)
INFO 2025-05-19 13:30:09,848 train_utils.py: 271: Train Epoch: [129][10/20] | Batch Time: 3.59 (4.54) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 46m | Losses/train_all_loss: 4.94e-01 (5.95e-01)
INFO 2025-05-19 13:30:42,848 trainer.py: 950: Estimated time remaining: 00d 01h 35m
INFO 2025-05-19 13:30:42,848 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:30:42,849 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.624830812215805, 'Losses/train_all_loss_mask': 0.0007988294411916286, 'Losses/train_all_loss_dice': 0.4103414058685303, 'Losses/train_all_loss_iou': 0.1985128026455641, 'Losses/train_all_loss_class': 1.974067869170426e-08, 'Losses/train_all_core_loss': 0.624830812215805, 'Trainer/where': 0.6497499999999999, 'Trainer/epoch': 129, 'Trainer/steps_train': 2600}
INFO 2025-05-19 13:30:59,074 train_utils.py: 271: Train Epoch: [130][ 0/20] | Batch Time: 14.23 (14.23) | Data Time: 10.12 (10.12) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 46m | Losses/train_all_loss: 4.36e-01 (4.36e-01)
INFO 2025-05-19 13:31:34,816 train_utils.py: 271: Train Epoch: [130][10/20] | Batch Time: 3.51 (4.54) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 47m | Losses/train_all_loss: 7.73e-01 (6.29e-01)
INFO 2025-05-19 13:32:07,241 trainer.py: 950: Estimated time remaining: 00d 01h 33m
INFO 2025-05-19 13:32:07,242 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:32:07,242 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6245546072721482, 'Losses/train_all_loss_mask': 0.00072453370958101, 'Losses/train_all_loss_dice': 0.4109769076108932, 'Losses/train_all_loss_iou': 0.19908702112734317, 'Losses/train_all_loss_class': 1.5837509992344677e-08, 'Losses/train_all_core_loss': 0.6245546072721482, 'Trainer/where': 0.6547499999999999, 'Trainer/epoch': 130, 'Trainer/steps_train': 2620}
INFO 2025-05-19 13:32:23,710 train_utils.py: 271: Train Epoch: [131][ 0/20] | Batch Time: 14.07 (14.07) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 48m | Losses/train_all_loss: 6.70e-01 (6.70e-01)
INFO 2025-05-19 13:32:58,025 train_utils.py: 271: Train Epoch: [131][10/20] | Batch Time: 3.57 (4.40) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 48m | Losses/train_all_loss: 5.34e-01 (7.02e-01)
INFO 2025-05-19 13:33:29,433 trainer.py: 950: Estimated time remaining: 00d 01h 29m
INFO 2025-05-19 13:33:29,434 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:33:29,434 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.643059928715229, 'Losses/train_all_loss_mask': 0.0007529103459091857, 'Losses/train_all_loss_dice': 0.4131987035274506, 'Losses/train_all_loss_iou': 0.2148030150681734, 'Losses/train_all_loss_class': 1.6404869618291685e-08, 'Losses/train_all_core_loss': 0.643059928715229, 'Trainer/where': 0.65975, 'Trainer/epoch': 131, 'Trainer/steps_train': 2640}
INFO 2025-05-19 13:33:45,374 train_utils.py: 271: Train Epoch: [132][ 0/20] | Batch Time: 13.91 (13.91) | Data Time: 10.11 (10.11) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 49m | Losses/train_all_loss: 5.73e-01 (5.73e-01)
INFO 2025-05-19 13:34:19,924 train_utils.py: 271: Train Epoch: [132][10/20] | Batch Time: 3.40 (4.41) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 50m | Losses/train_all_loss: 6.00e-01 (5.73e-01)
INFO 2025-05-19 13:34:51,510 trainer.py: 950: Estimated time remaining: 00d 01h 28m
INFO 2025-05-19 13:34:51,510 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:34:51,511 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6147748440504074, 'Losses/train_all_loss_mask': 0.0006619491075980477, 'Losses/train_all_loss_dice': 0.3960384979844093, 'Losses/train_all_loss_iou': 0.20549734383821489, 'Losses/train_all_loss_class': 2.068135869226495e-08, 'Losses/train_all_core_loss': 0.6147748440504074, 'Trainer/where': 0.66475, 'Trainer/epoch': 132, 'Trainer/steps_train': 2660}
INFO 2025-05-19 13:35:07,473 train_utils.py: 271: Train Epoch: [133][ 0/20] | Batch Time: 13.85 (13.85) | Data Time: 10.16 (10.16) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 51m | Losses/train_all_loss: 4.63e-01 (4.63e-01)
INFO 2025-05-19 13:35:41,783 train_utils.py: 271: Train Epoch: [133][10/20] | Batch Time: 3.47 (4.38) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 51m | Losses/train_all_loss: 4.61e-01 (6.08e-01)
INFO 2025-05-19 13:36:13,050 trainer.py: 950: Estimated time remaining: 00d 01h 26m
INFO 2025-05-19 13:36:13,050 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:36:13,050 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6911496832966805, 'Losses/train_all_loss_mask': 0.0008451885194517672, 'Losses/train_all_loss_dice': 0.43757888823747637, 'Losses/train_all_loss_iou': 0.23666702061891556, 'Losses/train_all_loss_class': 1.404755698430904e-08, 'Losses/train_all_core_loss': 0.6911496832966805, 'Trainer/where': 0.66975, 'Trainer/epoch': 133, 'Trainer/steps_train': 2680}
INFO 2025-05-19 13:36:28,561 train_utils.py: 271: Train Epoch: [134][ 0/20] | Batch Time: 13.46 (13.46) | Data Time: 9.63 (9.63) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 52m | Losses/train_all_loss: 5.27e-01 (5.27e-01)
INFO 2025-05-19 13:37:03,257 train_utils.py: 271: Train Epoch: [134][10/20] | Batch Time: 3.50 (4.38) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 52m | Losses/train_all_loss: 4.33e-01 (6.52e-01)
INFO 2025-05-19 13:37:34,878 trainer.py: 950: Estimated time remaining: 00d 01h 25m
INFO 2025-05-19 13:37:34,878 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:37:34,878 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6693755656480789, 'Losses/train_all_loss_mask': 0.0007744638453004882, 'Losses/train_all_loss_dice': 0.42825488448143006, 'Losses/train_all_loss_iou': 0.22563138231635094, 'Losses/train_all_loss_class': 1.9337871748348334e-08, 'Losses/train_all_core_loss': 0.6693755656480789, 'Trainer/where': 0.67475, 'Trainer/epoch': 134, 'Trainer/steps_train': 2700}
INFO 2025-05-19 13:37:50,769 train_utils.py: 271: Train Epoch: [135][ 0/20] | Batch Time: 13.77 (13.77) | Data Time: 9.81 (9.81) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 53m | Losses/train_all_loss: 6.02e-01 (6.02e-01)
INFO 2025-05-19 13:38:25,313 train_utils.py: 271: Train Epoch: [135][10/20] | Batch Time: 3.48 (4.39) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 54m | Losses/train_all_loss: 5.94e-01 (6.25e-01)
INFO 2025-05-19 13:38:56,905 trainer.py: 950: Estimated time remaining: 00d 01h 24m
INFO 2025-05-19 13:38:56,906 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:38:56,906 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6258288696408272, 'Losses/train_all_loss_mask': 0.0007580244811833837, 'Losses/train_all_loss_dice': 0.40607780367136004, 'Losses/train_all_loss_iou': 0.20459056198596953, 'Losses/train_all_loss_class': 2.1562805008201734e-08, 'Losses/train_all_core_loss': 0.6258288696408272, 'Trainer/where': 0.67975, 'Trainer/epoch': 135, 'Trainer/steps_train': 2720}
INFO 2025-05-19 13:39:13,216 train_utils.py: 271: Train Epoch: [136][ 0/20] | Batch Time: 14.15 (14.15) | Data Time: 10.21 (10.21) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 55m | Losses/train_all_loss: 8.49e-01 (8.49e-01)
INFO 2025-05-19 13:39:47,759 train_utils.py: 271: Train Epoch: [136][10/20] | Batch Time: 3.44 (4.43) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 55m | Losses/train_all_loss: 5.65e-01 (6.68e-01)
INFO 2025-05-19 13:40:19,943 trainer.py: 950: Estimated time remaining: 00d 01h 24m
INFO 2025-05-19 13:40:19,943 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:40:19,943 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6703436359763145, 'Losses/train_all_loss_mask': 0.0007536785371485167, 'Losses/train_all_loss_dice': 0.4347506418824196, 'Losses/train_all_loss_iou': 0.22051941677927972, 'Losses/train_all_loss_class': 1.6379664502519376e-08, 'Losses/train_all_core_loss': 0.6703436359763145, 'Trainer/where': 0.68475, 'Trainer/epoch': 136, 'Trainer/steps_train': 2740}
INFO 2025-05-19 13:40:36,532 train_utils.py: 271: Train Epoch: [137][ 0/20] | Batch Time: 14.53 (14.53) | Data Time: 10.50 (10.50) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 56m | Losses/train_all_loss: 6.35e-01 (6.35e-01)
INFO 2025-05-19 13:41:11,702 train_utils.py: 271: Train Epoch: [137][10/20] | Batch Time: 3.45 (4.52) | Data Time: 0.00 (0.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 57m | Losses/train_all_loss: 6.56e-01 (7.04e-01)
INFO 2025-05-19 13:41:43,309 trainer.py: 950: Estimated time remaining: 00d 01h 23m
INFO 2025-05-19 13:41:43,310 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:41:43,310 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6879376664757728, 'Losses/train_all_loss_mask': 0.0008244345313869417, 'Losses/train_all_loss_dice': 0.439305791258812, 'Losses/train_all_loss_iou': 0.23214318826794625, 'Losses/train_all_loss_class': 1.4900032607734203e-08, 'Losses/train_all_core_loss': 0.6879376664757728, 'Trainer/where': 0.68975, 'Trainer/epoch': 137, 'Trainer/steps_train': 2760}
INFO 2025-05-19 13:42:06,549 train_utils.py: 271: Train Epoch: [138][ 0/20] | Batch Time: 21.07 (21.07) | Data Time: 17.29 (17.29) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 57m | Losses/train_all_loss: 7.17e-01 (7.17e-01)
INFO 2025-05-19 13:42:41,448 train_utils.py: 271: Train Epoch: [138][10/20] | Batch Time: 3.52 (5.09) | Data Time: 0.00 (1.57) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 58m | Losses/train_all_loss: 5.26e-01 (6.35e-01)
INFO 2025-05-19 13:43:13,298 trainer.py: 950: Estimated time remaining: 00d 01h 28m
INFO 2025-05-19 13:43:13,298 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:43:13,298 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6338242247700692, 'Losses/train_all_loss_mask': 0.0007144645904190838, 'Losses/train_all_loss_dice': 0.41432428508996966, 'Losses/train_all_loss_iou': 0.20521064698696137, 'Losses/train_all_loss_class': 1.778497131788015e-08, 'Losses/train_all_core_loss': 0.6338242247700692, 'Trainer/where': 0.69475, 'Trainer/epoch': 138, 'Trainer/steps_train': 2780}
INFO 2025-05-19 13:43:29,249 train_utils.py: 271: Train Epoch: [139][ 0/20] | Batch Time: 13.88 (13.88) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 59m | Losses/train_all_loss: 7.88e-01 (7.88e-01)
INFO 2025-05-19 13:44:04,007 train_utils.py: 271: Train Epoch: [139][10/20] | Batch Time: 3.41 (4.42) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 02h 59m | Losses/train_all_loss: 5.61e-01 (6.88e-01)
INFO 2025-05-19 13:44:35,950 trainer.py: 950: Estimated time remaining: 00d 01h 19m
INFO 2025-05-19 13:44:35,951 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:44:35,951 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6434302613139152, 'Losses/train_all_loss_mask': 0.0007451683341059834, 'Losses/train_all_loss_dice': 0.4218342646956444, 'Losses/train_all_loss_iou': 0.20669262148439885, 'Losses/train_all_loss_class': 1.7808331453927907e-08, 'Losses/train_all_core_loss': 0.6434302613139152, 'Trainer/where': 0.69975, 'Trainer/epoch': 139, 'Trainer/steps_train': 2800}
INFO 2025-05-19 13:44:51,795 train_utils.py: 271: Train Epoch: [140][ 0/20] | Batch Time: 13.83 (13.83) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 00m | Losses/train_all_loss: 5.05e-01 (5.05e-01)
INFO 2025-05-19 13:45:26,579 train_utils.py: 271: Train Epoch: [140][10/20] | Batch Time: 3.47 (4.42) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 01m | Losses/train_all_loss: 5.52e-01 (6.80e-01)
INFO 2025-05-19 13:45:58,282 trainer.py: 950: Estimated time remaining: 00d 01h 18m
INFO 2025-05-19 13:45:58,283 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:45:58,283 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6649752199649811, 'Losses/train_all_loss_mask': 0.0007556714699603617, 'Losses/train_all_loss_dice': 0.42890910506248475, 'Losses/train_all_loss_iou': 0.22095267623662948, 'Losses/train_all_loss_class': 1.8784045652253667e-08, 'Losses/train_all_core_loss': 0.6649752199649811, 'Trainer/where': 0.70475, 'Trainer/epoch': 140, 'Trainer/steps_train': 2820}
INFO 2025-05-19 13:46:14,159 train_utils.py: 271: Train Epoch: [141][ 0/20] | Batch Time: 13.82 (13.82) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 02m | Losses/train_all_loss: 6.38e-01 (6.38e-01)
INFO 2025-05-19 13:46:49,378 train_utils.py: 271: Train Epoch: [141][10/20] | Batch Time: 3.52 (4.46) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 02m | Losses/train_all_loss: 7.10e-01 (7.20e-01)
INFO 2025-05-19 13:47:21,408 trainer.py: 950: Estimated time remaining: 00d 01h 17m
INFO 2025-05-19 13:47:21,409 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:47:21,409 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7074938118457794, 'Losses/train_all_loss_mask': 0.0007786340735037811, 'Losses/train_all_loss_dice': 0.45311634838581083, 'Losses/train_all_loss_iou': 0.23880475349724292, 'Losses/train_all_loss_class': 4.564574389576137e-08, 'Losses/train_all_core_loss': 0.7074938118457794, 'Trainer/where': 0.70975, 'Trainer/epoch': 141, 'Trainer/steps_train': 2840}
INFO 2025-05-19 13:47:37,416 train_utils.py: 271: Train Epoch: [142][ 0/20] | Batch Time: 13.86 (13.86) | Data Time: 9.99 (9.99) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 03m | Losses/train_all_loss: 5.49e-01 (5.49e-01)
INFO 2025-05-19 13:48:12,549 train_utils.py: 271: Train Epoch: [142][10/20] | Batch Time: 3.48 (4.45) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 04m | Losses/train_all_loss: 5.32e-01 (6.28e-01)
INFO 2025-05-19 13:48:44,607 trainer.py: 950: Estimated time remaining: 00d 01h 16m
INFO 2025-05-19 13:48:44,607 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:48:44,608 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6067710876464844, 'Losses/train_all_loss_mask': 0.0006674284682958387, 'Losses/train_all_loss_dice': 0.39077104479074476, 'Losses/train_all_loss_iou': 0.20265145525336264, 'Losses/train_all_loss_class': 1.972036935971033e-08, 'Losses/train_all_core_loss': 0.6067710876464844, 'Trainer/where': 0.71475, 'Trainer/epoch': 142, 'Trainer/steps_train': 2860}
INFO 2025-05-19 13:49:00,713 train_utils.py: 271: Train Epoch: [143][ 0/20] | Batch Time: 14.10 (14.10) | Data Time: 10.21 (10.21) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 04m | Losses/train_all_loss: 8.65e-01 (8.65e-01)
INFO 2025-05-19 13:49:35,500 train_utils.py: 271: Train Epoch: [143][10/20] | Batch Time: 3.44 (4.44) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 05m | Losses/train_all_loss: 6.27e-01 (6.76e-01)
INFO 2025-05-19 13:50:07,780 trainer.py: 950: Estimated time remaining: 00d 01h 14m
INFO 2025-05-19 13:50:07,781 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:50:07,781 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6395452916622162, 'Losses/train_all_loss_mask': 0.0007790330753778107, 'Losses/train_all_loss_dice': 0.418017578125, 'Losses/train_all_loss_iou': 0.20594703890383242, 'Losses/train_all_loss_class': 2.4059354886141194e-08, 'Losses/train_all_core_loss': 0.6395452916622162, 'Trainer/where': 0.7197499999999999, 'Trainer/epoch': 143, 'Trainer/steps_train': 2880}
INFO 2025-05-19 13:50:23,767 train_utils.py: 271: Train Epoch: [144][ 0/20] | Batch Time: 13.97 (13.97) | Data Time: 10.09 (10.09) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 06m | Losses/train_all_loss: 5.55e-01 (5.55e-01)
INFO 2025-05-19 13:50:58,985 train_utils.py: 271: Train Epoch: [144][10/20] | Batch Time: 3.55 (4.47) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 06m | Losses/train_all_loss: 5.96e-01 (5.75e-01)
INFO 2025-05-19 13:51:31,151 trainer.py: 950: Estimated time remaining: 00d 01h 13m
INFO 2025-05-19 13:51:31,152 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:51:31,152 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6705051198601722, 'Losses/train_all_loss_mask': 0.0008945666195359081, 'Losses/train_all_loss_dice': 0.42939511090517046, 'Losses/train_all_loss_iou': 0.22321866191923617, 'Losses/train_all_loss_class': 1.8477369589930958e-08, 'Losses/train_all_core_loss': 0.6705051198601722, 'Trainer/where': 0.7247499999999999, 'Trainer/epoch': 144, 'Trainer/steps_train': 2900}
INFO 2025-05-19 13:51:47,389 train_utils.py: 271: Train Epoch: [145][ 0/20] | Batch Time: 14.09 (14.09) | Data Time: 10.14 (10.14) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 07m | Losses/train_all_loss: 7.88e-01 (7.88e-01)
INFO 2025-05-19 13:52:22,568 train_utils.py: 271: Train Epoch: [145][10/20] | Batch Time: 3.53 (4.48) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 08m | Losses/train_all_loss: 7.52e-01 (7.59e-01)
INFO 2025-05-19 13:52:54,429 trainer.py: 950: Estimated time remaining: 00d 01h 12m
INFO 2025-05-19 13:52:54,429 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:52:54,430 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6863355740904808, 'Losses/train_all_loss_mask': 0.0008008392687770538, 'Losses/train_all_loss_dice': 0.44022316932678224, 'Losses/train_all_loss_iou': 0.23009560592472553, 'Losses/train_all_loss_class': 1.52075296355747e-08, 'Losses/train_all_core_loss': 0.6863355740904808, 'Trainer/where': 0.7297499999999999, 'Trainer/epoch': 145, 'Trainer/steps_train': 2920}
INFO 2025-05-19 13:53:10,904 train_utils.py: 271: Train Epoch: [146][ 0/20] | Batch Time: 14.06 (14.06) | Data Time: 10.11 (10.11) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 09m | Losses/train_all_loss: 7.20e-01 (7.20e-01)
INFO 2025-05-19 13:53:46,537 train_utils.py: 271: Train Epoch: [146][10/20] | Batch Time: 3.70 (4.52) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 09m | Losses/train_all_loss: 5.62e-01 (6.40e-01)
INFO 2025-05-19 13:54:19,340 trainer.py: 950: Estimated time remaining: 00d 01h 12m
INFO 2025-05-19 13:54:19,340 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:54:19,340 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6668430998921394, 'Losses/train_all_loss_mask': 0.0007175576596637256, 'Losses/train_all_loss_dice': 0.4358734577894211, 'Losses/train_all_loss_iou': 0.21661847308278084, 'Losses/train_all_loss_class': 2.111372342517015e-08, 'Losses/train_all_core_loss': 0.6668430998921394, 'Trainer/where': 0.7347499999999999, 'Trainer/epoch': 146, 'Trainer/steps_train': 2940}
INFO 2025-05-19 13:54:35,619 train_utils.py: 271: Train Epoch: [147][ 0/20] | Batch Time: 14.16 (14.16) | Data Time: 10.15 (10.15) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 10m | Losses/train_all_loss: 4.56e-01 (4.56e-01)
INFO 2025-05-19 13:55:11,654 train_utils.py: 271: Train Epoch: [147][10/20] | Batch Time: 3.64 (4.56) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 11m | Losses/train_all_loss: 4.52e-01 (5.69e-01)
INFO 2025-05-19 13:55:44,677 trainer.py: 950: Estimated time remaining: 00d 01h 11m
INFO 2025-05-19 13:55:44,677 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:55:44,677 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.607662309706211, 'Losses/train_all_loss_mask': 0.0007496180536691099, 'Losses/train_all_loss_dice': 0.39517937451601026, 'Losses/train_all_loss_iou': 0.1974905662238598, 'Losses/train_all_loss_class': 1.5810501774460307e-08, 'Losses/train_all_core_loss': 0.607662309706211, 'Trainer/where': 0.7397499999999999, 'Trainer/epoch': 147, 'Trainer/steps_train': 2960}
INFO 2025-05-19 13:56:00,862 train_utils.py: 271: Train Epoch: [148][ 0/20] | Batch Time: 14.05 (14.05) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 11m | Losses/train_all_loss: 5.77e-01 (5.77e-01)
INFO 2025-05-19 13:56:36,779 train_utils.py: 271: Train Epoch: [148][10/20] | Batch Time: 3.65 (4.54) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 12m | Losses/train_all_loss: 4.90e-01 (7.03e-01)
INFO 2025-05-19 13:57:09,653 trainer.py: 950: Estimated time remaining: 00d 01h 09m
INFO 2025-05-19 13:57:09,653 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:57:09,653 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6485622346401214, 'Losses/train_all_loss_mask': 0.0007226228786748834, 'Losses/train_all_loss_dice': 0.41381731927394866, 'Losses/train_all_loss_iou': 0.22029244787991048, 'Losses/train_all_loss_class': 1.774832540935023e-08, 'Losses/train_all_core_loss': 0.6485622346401214, 'Trainer/where': 0.7447499999999999, 'Trainer/epoch': 148, 'Trainer/steps_train': 2980}
INFO 2025-05-19 13:57:25,945 train_utils.py: 271: Train Epoch: [149][ 0/20] | Batch Time: 14.22 (14.22) | Data Time: 10.12 (10.12) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 13m | Losses/train_all_loss: 6.32e-01 (6.32e-01)
INFO 2025-05-19 13:58:02,120 train_utils.py: 271: Train Epoch: [149][10/20] | Batch Time: 3.58 (4.58) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 13m | Losses/train_all_loss: 1.01e+00 (6.63e-01)
INFO 2025-05-19 13:58:34,762 trainer.py: 950: Estimated time remaining: 00d 01h 08m
INFO 2025-05-19 13:58:34,763 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:58:34,763 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6475742101669312, 'Losses/train_all_loss_mask': 0.0007679205358726904, 'Losses/train_all_loss_dice': 0.41352727860212324, 'Losses/train_all_loss_iou': 0.21868851222097874, 'Losses/train_all_loss_class': 1.6799223390151497e-08, 'Losses/train_all_core_loss': 0.6475742101669312, 'Trainer/where': 0.7497499999999999, 'Trainer/epoch': 149, 'Trainer/steps_train': 3000}
INFO 2025-05-19 13:58:50,377 train_utils.py: 271: Train Epoch: [150][ 0/20] | Batch Time: 13.48 (13.48) | Data Time: 10.26 (10.26) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 14m | Losses/train_all_loss: 7.98e-01 (7.98e-01)
INFO 2025-05-19 13:59:19,372 train_utils.py: 271: Train Epoch: [150][10/20] | Batch Time: 2.88 (3.86) | Data Time: 0.00 (0.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 15m | Losses/train_all_loss: 1.20e+00 (7.00e-01)
INFO 2025-05-19 13:59:46,427 trainer.py: 950: Estimated time remaining: 00d 00h 56m
INFO 2025-05-19 13:59:46,427 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 13:59:46,427 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6451408088207244, 'Losses/train_all_loss_mask': 0.0008141757527482696, 'Losses/train_all_loss_dice': 0.4191492527723312, 'Losses/train_all_loss_iou': 0.20970803089439868, 'Losses/train_all_loss_class': 1.6506727273934984e-08, 'Losses/train_all_core_loss': 0.6451408088207244, 'Trainer/where': 0.7547499999999999, 'Trainer/epoch': 150, 'Trainer/steps_train': 3020}
INFO 2025-05-19 14:00:01,858 train_utils.py: 271: Train Epoch: [151][ 0/20] | Batch Time: 13.40 (13.40) | Data Time: 10.08 (10.08) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 15m | Losses/train_all_loss: 1.18e+00 (1.18e+00)
INFO 2025-05-19 14:00:31,291 train_utils.py: 271: Train Epoch: [151][10/20] | Batch Time: 2.87 (3.89) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 16m | Losses/train_all_loss: 6.33e-01 (6.71e-01)
INFO 2025-05-19 14:00:58,075 trainer.py: 950: Estimated time remaining: 00d 00h 55m
INFO 2025-05-19 14:00:58,076 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:00:58,076 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6681634113192558, 'Losses/train_all_loss_mask': 0.0007341485630604439, 'Losses/train_all_loss_dice': 0.4388762563467026, 'Losses/train_all_loss_iou': 0.21460415720939635, 'Losses/train_all_loss_class': 2.9184212801958155e-08, 'Losses/train_all_core_loss': 0.6681634113192558, 'Trainer/where': 0.7597499999999999, 'Trainer/epoch': 151, 'Trainer/steps_train': 3040}
INFO 2025-05-19 14:01:13,602 train_utils.py: 271: Train Epoch: [152][ 0/20] | Batch Time: 13.31 (13.31) | Data Time: 9.99 (9.99) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 17m | Losses/train_all_loss: 6.63e-01 (6.63e-01)
INFO 2025-05-19 14:01:42,564 train_utils.py: 271: Train Epoch: [152][10/20] | Batch Time: 2.88 (3.84) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 17m | Losses/train_all_loss: 8.86e-01 (6.64e-01)
INFO 2025-05-19 14:02:09,738 trainer.py: 950: Estimated time remaining: 00d 00h 53m
INFO 2025-05-19 14:02:09,738 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:02:09,739 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6506326749920845, 'Losses/train_all_loss_mask': 0.0007749609663733281, 'Losses/train_all_loss_dice': 0.4307422339916229, 'Losses/train_all_loss_iou': 0.2043912060558796, 'Losses/train_all_loss_class': 1.9137947160352554e-08, 'Losses/train_all_core_loss': 0.6506326749920845, 'Trainer/where': 0.7647499999999999, 'Trainer/epoch': 152, 'Trainer/steps_train': 3060}
INFO 2025-05-19 14:02:25,164 train_utils.py: 271: Train Epoch: [153][ 0/20] | Batch Time: 13.35 (13.35) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 18m | Losses/train_all_loss: 7.32e-01 (7.32e-01)
INFO 2025-05-19 14:02:54,413 train_utils.py: 271: Train Epoch: [153][10/20] | Batch Time: 2.87 (3.87) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 18m | Losses/train_all_loss: 8.52e-01 (6.49e-01)
INFO 2025-05-19 14:03:21,439 trainer.py: 950: Estimated time remaining: 00d 00h 52m
INFO 2025-05-19 14:03:21,439 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:03:21,439 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6292503848671913, 'Losses/train_all_loss_mask': 0.0007514616401749663, 'Losses/train_all_loss_dice': 0.40426052659749984, 'Losses/train_all_loss_iou': 0.20996061265468596, 'Losses/train_all_loss_class': 2.2954192546720265e-08, 'Losses/train_all_core_loss': 0.6292503848671913, 'Trainer/where': 0.7697499999999999, 'Trainer/epoch': 153, 'Trainer/steps_train': 3080}
INFO 2025-05-19 14:03:36,522 train_utils.py: 271: Train Epoch: [154][ 0/20] | Batch Time: 12.99 (12.99) | Data Time: 9.74 (9.74) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 19m | Losses/train_all_loss: 5.11e-01 (5.11e-01)
INFO 2025-05-19 14:04:05,819 train_utils.py: 271: Train Epoch: [154][10/20] | Batch Time: 2.85 (3.84) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 19m | Losses/train_all_loss: 7.32e-01 (5.88e-01)
INFO 2025-05-19 14:04:32,754 trainer.py: 950: Estimated time remaining: 00d 00h 51m
INFO 2025-05-19 14:04:32,754 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:04:32,755 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6026968076825142, 'Losses/train_all_loss_mask': 0.0006677564029814676, 'Losses/train_all_loss_dice': 0.3974331021308899, 'Losses/train_all_loss_iou': 0.19190857633948327, 'Losses/train_all_loss_class': 1.9803104689408714e-08, 'Losses/train_all_core_loss': 0.6026968076825142, 'Trainer/where': 0.7747499999999999, 'Trainer/epoch': 154, 'Trainer/steps_train': 3100}
INFO 2025-05-19 14:04:47,957 train_utils.py: 271: Train Epoch: [155][ 0/20] | Batch Time: 13.07 (13.07) | Data Time: 9.69 (9.69) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 20m | Losses/train_all_loss: 6.22e-01 (6.22e-01)
INFO 2025-05-19 14:05:17,234 train_utils.py: 271: Train Epoch: [155][10/20] | Batch Time: 2.86 (3.85) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 21m | Losses/train_all_loss: 7.19e-01 (6.65e-01)
INFO 2025-05-19 14:05:44,172 trainer.py: 950: Estimated time remaining: 00d 00h 50m
INFO 2025-05-19 14:05:44,173 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:05:44,173 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6453447371721268, 'Losses/train_all_loss_mask': 0.0007489299488952384, 'Losses/train_all_loss_dice': 0.4168533056974411, 'Losses/train_all_loss_iou': 0.21351281963288785, 'Losses/train_all_loss_class': 2.007309327645146e-08, 'Losses/train_all_core_loss': 0.6453447371721268, 'Trainer/where': 0.7797499999999999, 'Trainer/epoch': 155, 'Trainer/steps_train': 3120}
INFO 2025-05-19 14:05:59,701 train_utils.py: 271: Train Epoch: [156][ 0/20] | Batch Time: 13.48 (13.48) | Data Time: 10.06 (10.06) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 21m | Losses/train_all_loss: 5.00e-01 (5.00e-01)
INFO 2025-05-19 14:06:28,875 train_utils.py: 271: Train Epoch: [156][10/20] | Batch Time: 2.88 (3.88) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 22m | Losses/train_all_loss: 6.93e-01 (6.46e-01)
INFO 2025-05-19 14:06:55,293 trainer.py: 950: Estimated time remaining: 00d 00h 48m
INFO 2025-05-19 14:06:55,293 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:06:55,293 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6445965990424156, 'Losses/train_all_loss_mask': 0.0007461323664756491, 'Losses/train_all_loss_dice': 0.42429067492485045, 'Losses/train_all_loss_iou': 0.20538326278328894, 'Losses/train_all_loss_class': 1.5119121865581063e-08, 'Losses/train_all_core_loss': 0.6445965990424156, 'Trainer/where': 0.78475, 'Trainer/epoch': 156, 'Trainer/steps_train': 3140}
INFO 2025-05-19 14:07:10,969 train_utils.py: 271: Train Epoch: [157][ 0/20] | Batch Time: 13.60 (13.60) | Data Time: 10.10 (10.10) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 23m | Losses/train_all_loss: 6.29e-01 (6.29e-01)
INFO 2025-05-19 14:07:40,367 train_utils.py: 271: Train Epoch: [157][10/20] | Batch Time: 2.90 (3.91) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 23m | Losses/train_all_loss: 4.81e-01 (6.04e-01)
INFO 2025-05-19 14:08:07,117 trainer.py: 950: Estimated time remaining: 00d 00h 48m
INFO 2025-05-19 14:08:07,117 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:08:07,117 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6443393006920815, 'Losses/train_all_loss_mask': 0.0007736197774647735, 'Losses/train_all_loss_dice': 0.4109859481453896, 'Losses/train_all_loss_iou': 0.21788093820214272, 'Losses/train_all_loss_class': 2.2914704533860685e-08, 'Losses/train_all_core_loss': 0.6443393006920815, 'Trainer/where': 0.78975, 'Trainer/epoch': 157, 'Trainer/steps_train': 3160}
INFO 2025-05-19 14:08:22,487 train_utils.py: 271: Train Epoch: [158][ 0/20] | Batch Time: 13.25 (13.25) | Data Time: 9.94 (9.94) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 24m | Losses/train_all_loss: 5.59e-01 (5.59e-01)
INFO 2025-05-19 14:08:51,556 train_utils.py: 271: Train Epoch: [158][10/20] | Batch Time: 2.82 (3.85) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 24m | Losses/train_all_loss: 6.16e-01 (6.15e-01)
INFO 2025-05-19 14:09:18,237 trainer.py: 950: Estimated time remaining: 00d 00h 46m
INFO 2025-05-19 14:09:18,237 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:09:18,238 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.648100708425045, 'Losses/train_all_loss_mask': 0.0007636062451638282, 'Losses/train_all_loss_dice': 0.4154458522796631, 'Losses/train_all_loss_iou': 0.21738270968198775, 'Losses/train_all_loss_class': 2.5355751342992505e-08, 'Losses/train_all_core_loss': 0.648100708425045, 'Trainer/where': 0.79475, 'Trainer/epoch': 158, 'Trainer/steps_train': 3180}
INFO 2025-05-19 14:09:33,500 train_utils.py: 271: Train Epoch: [159][ 0/20] | Batch Time: 13.27 (13.27) | Data Time: 10.07 (10.07) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 25m | Losses/train_all_loss: 1.14e+00 (1.14e+00)
INFO 2025-05-19 14:10:02,678 train_utils.py: 271: Train Epoch: [159][10/20] | Batch Time: 2.92 (3.86) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 25m | Losses/train_all_loss: 5.17e-01 (7.38e-01)
INFO 2025-05-19 14:10:29,596 trainer.py: 950: Estimated time remaining: 00d 00h 45m
INFO 2025-05-19 14:10:29,596 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:10:29,596 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6966796889901161, 'Losses/train_all_loss_mask': 0.0007734573606285267, 'Losses/train_all_loss_dice': 0.4382118135690689, 'Losses/train_all_loss_iou': 0.24299872443079948, 'Losses/train_all_loss_class': 2.0385118482124653e-08, 'Losses/train_all_core_loss': 0.6966796889901161, 'Trainer/where': 0.79975, 'Trainer/epoch': 159, 'Trainer/steps_train': 3200}
INFO 2025-05-19 14:10:45,157 train_utils.py: 271: Train Epoch: [160][ 0/20] | Batch Time: 13.40 (13.40) | Data Time: 10.02 (10.02) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 26m | Losses/train_all_loss: 5.97e-01 (5.97e-01)
INFO 2025-05-19 14:11:14,464 train_utils.py: 271: Train Epoch: [160][10/20] | Batch Time: 2.88 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 27m | Losses/train_all_loss: 5.90e-01 (5.92e-01)
INFO 2025-05-19 14:11:41,370 trainer.py: 950: Estimated time remaining: 00d 00h 44m
INFO 2025-05-19 14:11:41,370 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:11:41,371 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.641780161857605, 'Losses/train_all_loss_mask': 0.0007165510309278033, 'Losses/train_all_loss_dice': 0.41384208798408506, 'Losses/train_all_loss_iou': 0.21360704824328422, 'Losses/train_all_loss_class': 1.9640818860189313e-08, 'Losses/train_all_core_loss': 0.641780161857605, 'Trainer/where': 0.80475, 'Trainer/epoch': 160, 'Trainer/steps_train': 3220}
INFO 2025-05-19 14:11:56,748 train_utils.py: 271: Train Epoch: [161][ 0/20] | Batch Time: 13.32 (13.32) | Data Time: 10.06 (10.06) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 27m | Losses/train_all_loss: 8.00e-01 (8.00e-01)
INFO 2025-05-19 14:12:26,125 train_utils.py: 271: Train Epoch: [161][10/20] | Batch Time: 2.86 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 28m | Losses/train_all_loss: 6.38e-01 (6.41e-01)
INFO 2025-05-19 14:12:52,870 trainer.py: 950: Estimated time remaining: 00d 00h 43m
INFO 2025-05-19 14:12:52,871 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:12:52,871 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6424472734332085, 'Losses/train_all_loss_mask': 0.000753471115604043, 'Losses/train_all_loss_dice': 0.4173421189188957, 'Losses/train_all_loss_iou': 0.2100357100367546, 'Losses/train_all_loss_class': 2.1506762748479958e-08, 'Losses/train_all_core_loss': 0.6424472734332085, 'Trainer/where': 0.80975, 'Trainer/epoch': 161, 'Trainer/steps_train': 3240}
INFO 2025-05-19 14:13:08,385 train_utils.py: 271: Train Epoch: [162][ 0/20] | Batch Time: 13.32 (13.32) | Data Time: 10.00 (10.00) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 29m | Losses/train_all_loss: 6.37e-01 (6.37e-01)
INFO 2025-05-19 14:13:37,445 train_utils.py: 271: Train Epoch: [162][10/20] | Batch Time: 2.88 (3.85) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 29m | Losses/train_all_loss: 4.42e-01 (6.21e-01)
INFO 2025-05-19 14:14:04,481 trainer.py: 950: Estimated time remaining: 00d 00h 42m
INFO 2025-05-19 14:14:04,481 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:14:04,481 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6071522995829582, 'Losses/train_all_loss_mask': 0.0007618722593178973, 'Losses/train_all_loss_dice': 0.4023348852992058, 'Losses/train_all_loss_iou': 0.189579963311553, 'Losses/train_all_loss_class': 1.830966869231787e-08, 'Losses/train_all_core_loss': 0.6071522995829582, 'Trainer/where': 0.81475, 'Trainer/epoch': 162, 'Trainer/steps_train': 3260}
INFO 2025-05-19 14:14:19,872 train_utils.py: 271: Train Epoch: [163][ 0/20] | Batch Time: 13.26 (13.26) | Data Time: 10.02 (10.02) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 30m | Losses/train_all_loss: 5.52e-01 (5.52e-01)
INFO 2025-05-19 14:14:48,623 train_utils.py: 271: Train Epoch: [163][10/20] | Batch Time: 2.85 (3.82) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 30m | Losses/train_all_loss: 5.01e-01 (6.47e-01)
INFO 2025-05-19 14:15:15,350 trainer.py: 950: Estimated time remaining: 00d 00h 40m
INFO 2025-05-19 14:15:15,351 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:15:15,351 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6787820115685463, 'Losses/train_all_loss_mask': 0.0007257766890688799, 'Losses/train_all_loss_dice': 0.4290116369724274, 'Losses/train_all_loss_iou': 0.2352548398077488, 'Losses/train_all_loss_class': 1.4125487912686197e-08, 'Losses/train_all_core_loss': 0.6787820115685463, 'Trainer/where': 0.81975, 'Trainer/epoch': 163, 'Trainer/steps_train': 3280}
INFO 2025-05-19 14:15:30,921 train_utils.py: 271: Train Epoch: [164][ 0/20] | Batch Time: 13.48 (13.48) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 31m | Losses/train_all_loss: 8.97e-01 (8.97e-01)
INFO 2025-05-19 14:15:59,950 train_utils.py: 271: Train Epoch: [164][10/20] | Batch Time: 2.88 (3.86) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 31m | Losses/train_all_loss: 7.84e-01 (7.08e-01)
INFO 2025-05-19 14:16:26,679 trainer.py: 950: Estimated time remaining: 00d 00h 39m
INFO 2025-05-19 14:16:26,680 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:16:26,680 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6633350506424904, 'Losses/train_all_loss_mask': 0.0007682480354560539, 'Losses/train_all_loss_dice': 0.4258778005838394, 'Losses/train_all_loss_iou': 0.22209227532148362, 'Losses/train_all_loss_class': 1.911826981171316e-08, 'Losses/train_all_core_loss': 0.6633350506424904, 'Trainer/where': 0.82475, 'Trainer/epoch': 164, 'Trainer/steps_train': 3300}
INFO 2025-05-19 14:16:41,386 train_utils.py: 271: Train Epoch: [165][ 0/20] | Batch Time: 12.67 (12.67) | Data Time: 9.52 (9.52) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 32m | Losses/train_all_loss: 6.22e-01 (6.22e-01)
INFO 2025-05-19 14:17:10,812 train_utils.py: 271: Train Epoch: [165][10/20] | Batch Time: 2.88 (3.83) | Data Time: 0.00 (0.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 33m | Losses/train_all_loss: 1.05e+00 (6.20e-01)
INFO 2025-05-19 14:17:37,590 trainer.py: 950: Estimated time remaining: 00d 00h 38m
INFO 2025-05-19 14:17:37,590 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:17:37,590 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6363499224185943, 'Losses/train_all_loss_mask': 0.0007739759574178606, 'Losses/train_all_loss_dice': 0.4225362971425056, 'Losses/train_all_loss_iou': 0.19833408929407598, 'Losses/train_all_loss_class': 1.9838476661426795e-08, 'Losses/train_all_core_loss': 0.6363499224185943, 'Trainer/where': 0.82975, 'Trainer/epoch': 165, 'Trainer/steps_train': 3320}
INFO 2025-05-19 14:17:52,978 train_utils.py: 271: Train Epoch: [166][ 0/20] | Batch Time: 13.33 (13.33) | Data Time: 10.03 (10.03) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 33m | Losses/train_all_loss: 5.30e-01 (5.30e-01)
INFO 2025-05-19 14:18:22,342 train_utils.py: 271: Train Epoch: [166][10/20] | Batch Time: 2.99 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 34m | Losses/train_all_loss: 4.45e-01 (5.66e-01)
INFO 2025-05-19 14:18:49,168 trainer.py: 950: Estimated time remaining: 00d 00h 37m
INFO 2025-05-19 14:18:49,169 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:18:49,169 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6035211235284805, 'Losses/train_all_loss_mask': 0.000764296654961072, 'Losses/train_all_loss_dice': 0.39216246604919436, 'Losses/train_all_loss_iou': 0.19607271291315556, 'Losses/train_all_loss_class': 1.9300197862115455e-08, 'Losses/train_all_core_loss': 0.6035211235284805, 'Trainer/where': 0.83475, 'Trainer/epoch': 166, 'Trainer/steps_train': 3340}
INFO 2025-05-19 14:19:04,438 train_utils.py: 271: Train Epoch: [167][ 0/20] | Batch Time: 13.25 (13.25) | Data Time: 10.02 (10.02) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 34m | Losses/train_all_loss: 5.88e-01 (5.88e-01)
INFO 2025-05-19 14:19:33,242 train_utils.py: 271: Train Epoch: [167][10/20] | Batch Time: 2.80 (3.82) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 35m | Losses/train_all_loss: 4.83e-01 (6.04e-01)
INFO 2025-05-19 14:20:00,125 trainer.py: 950: Estimated time remaining: 00d 00h 36m
INFO 2025-05-19 14:20:00,126 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:20:00,126 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6366460576653481, 'Losses/train_all_loss_mask': 0.0007638113165739924, 'Losses/train_all_loss_dice': 0.4091913938522339, 'Losses/train_all_loss_iou': 0.21217843294143676, 'Losses/train_all_loss_class': 1.9113437454976178e-08, 'Losses/train_all_core_loss': 0.6366460576653481, 'Trainer/where': 0.83975, 'Trainer/epoch': 167, 'Trainer/steps_train': 3360}
INFO 2025-05-19 14:20:15,194 train_utils.py: 271: Train Epoch: [168][ 0/20] | Batch Time: 12.98 (12.98) | Data Time: 9.71 (9.71) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 36m | Losses/train_all_loss: 9.57e-01 (9.57e-01)
INFO 2025-05-19 14:20:44,541 train_utils.py: 271: Train Epoch: [168][10/20] | Batch Time: 2.96 (3.85) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 36m | Losses/train_all_loss: 5.82e-01 (6.82e-01)
INFO 2025-05-19 14:21:11,465 trainer.py: 950: Estimated time remaining: 00d 00h 35m
INFO 2025-05-19 14:21:11,465 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:21:11,466 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6945251435041427, 'Losses/train_all_loss_mask': 0.0007778874467476271, 'Losses/train_all_loss_dice': 0.43921201676130295, 'Losses/train_all_loss_iou': 0.23975536599755287, 'Losses/train_all_loss_class': 2.136639498662163e-08, 'Losses/train_all_core_loss': 0.6945251435041427, 'Trainer/where': 0.8447499999999999, 'Trainer/epoch': 168, 'Trainer/steps_train': 3380}
INFO 2025-05-19 14:21:26,713 train_utils.py: 271: Train Epoch: [169][ 0/20] | Batch Time: 13.14 (13.14) | Data Time: 9.80 (9.80) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 37m | Losses/train_all_loss: 8.97e-01 (8.97e-01)
INFO 2025-05-19 14:21:55,591 train_utils.py: 271: Train Epoch: [169][10/20] | Batch Time: 2.88 (3.82) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 37m | Losses/train_all_loss: 5.34e-01 (6.77e-01)
INFO 2025-05-19 14:22:22,510 trainer.py: 950: Estimated time remaining: 00d 00h 34m
INFO 2025-05-19 14:22:22,511 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:22:22,511 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6508819296956062, 'Losses/train_all_loss_mask': 0.0008116858458379284, 'Losses/train_all_loss_dice': 0.41297709494829177, 'Losses/train_all_loss_iou': 0.22167111113667487, 'Losses/train_all_loss_class': 1.7411338948392084e-08, 'Losses/train_all_core_loss': 0.6508819296956062, 'Trainer/where': 0.8497499999999999, 'Trainer/epoch': 169, 'Trainer/steps_train': 3400}
INFO 2025-05-19 14:22:37,805 train_utils.py: 271: Train Epoch: [170][ 0/20] | Batch Time: 13.17 (13.17) | Data Time: 9.72 (9.72) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 38m | Losses/train_all_loss: 6.48e-01 (6.48e-01)
INFO 2025-05-19 14:23:07,280 train_utils.py: 271: Train Epoch: [170][10/20] | Batch Time: 2.96 (3.88) | Data Time: 0.00 (0.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 39m | Losses/train_all_loss: 4.96e-01 (6.06e-01)
INFO 2025-05-19 14:23:34,192 trainer.py: 950: Estimated time remaining: 00d 00h 33m
INFO 2025-05-19 14:23:34,193 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:23:34,193 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6069769963622094, 'Losses/train_all_loss_mask': 0.0007121327696950174, 'Losses/train_all_loss_dice': 0.39719501286745074, 'Losses/train_all_loss_iou': 0.19553931057453156, 'Losses/train_all_loss_class': 2.5869574571402155e-08, 'Losses/train_all_core_loss': 0.6069769963622094, 'Trainer/where': 0.8547499999999999, 'Trainer/epoch': 170, 'Trainer/steps_train': 3420}
INFO 2025-05-19 14:23:49,748 train_utils.py: 271: Train Epoch: [171][ 0/20] | Batch Time: 13.48 (13.48) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 39m | Losses/train_all_loss: 5.12e-01 (5.12e-01)
INFO 2025-05-19 14:24:18,903 train_utils.py: 271: Train Epoch: [171][10/20] | Batch Time: 2.87 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 40m | Losses/train_all_loss: 6.70e-01 (6.59e-01)
INFO 2025-05-19 14:24:45,754 trainer.py: 950: Estimated time remaining: 00d 00h 32m
INFO 2025-05-19 14:24:45,755 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:24:45,755 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6470516502857209, 'Losses/train_all_loss_mask': 0.0007626546896062792, 'Losses/train_all_loss_dice': 0.4227837324142456, 'Losses/train_all_loss_iou': 0.20901480838656425, 'Losses/train_all_loss_class': 1.7920711736785223e-08, 'Losses/train_all_core_loss': 0.6470516502857209, 'Trainer/where': 0.8597499999999999, 'Trainer/epoch': 171, 'Trainer/steps_train': 3440}
INFO 2025-05-19 14:25:01,295 train_utils.py: 271: Train Epoch: [172][ 0/20] | Batch Time: 13.37 (13.37) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 40m | Losses/train_all_loss: 8.81e-01 (8.81e-01)
INFO 2025-05-19 14:25:30,597 train_utils.py: 271: Train Epoch: [172][10/20] | Batch Time: 2.96 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 41m | Losses/train_all_loss: 6.26e-01 (6.80e-01)
INFO 2025-05-19 14:25:57,655 trainer.py: 950: Estimated time remaining: 00d 00h 31m
INFO 2025-05-19 14:25:57,656 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:25:57,656 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6535398736596107, 'Losses/train_all_loss_mask': 0.0007668142643524334, 'Losses/train_all_loss_dice': 0.4206194654107094, 'Losses/train_all_loss_iou': 0.2175841022282839, 'Losses/train_all_loss_class': 2.5624368649168615e-08, 'Losses/train_all_core_loss': 0.6535398736596107, 'Trainer/where': 0.8647499999999999, 'Trainer/epoch': 172, 'Trainer/steps_train': 3460}
INFO 2025-05-19 14:26:13,060 train_utils.py: 271: Train Epoch: [173][ 0/20] | Batch Time: 13.37 (13.37) | Data Time: 10.09 (10.09) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 42m | Losses/train_all_loss: 6.37e-01 (6.37e-01)
INFO 2025-05-19 14:26:42,383 train_utils.py: 271: Train Epoch: [173][10/20] | Batch Time: 2.96 (3.88) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 42m | Losses/train_all_loss: 4.55e-01 (5.93e-01)
INFO 2025-05-19 14:27:09,323 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-05-19 14:27:09,324 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:27:09,324 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6197118058800697, 'Losses/train_all_loss_mask': 0.0007505270521505735, 'Losses/train_all_loss_dice': 0.4003703758120537, 'Losses/train_all_loss_iou': 0.20433087274432182, 'Losses/train_all_loss_class': 2.087214141521798e-08, 'Losses/train_all_core_loss': 0.6197118058800697, 'Trainer/where': 0.8697499999999999, 'Trainer/epoch': 173, 'Trainer/steps_train': 3480}
INFO 2025-05-19 14:27:24,923 train_utils.py: 271: Train Epoch: [174][ 0/20] | Batch Time: 13.45 (13.45) | Data Time: 10.01 (10.01) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 43m | Losses/train_all_loss: 7.90e-01 (7.90e-01)
INFO 2025-05-19 14:27:54,101 train_utils.py: 271: Train Epoch: [174][10/20] | Batch Time: 2.89 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 43m | Losses/train_all_loss: 6.02e-01 (6.74e-01)
INFO 2025-05-19 14:28:20,666 trainer.py: 950: Estimated time remaining: 00d 00h 28m
INFO 2025-05-19 14:28:20,667 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:28:20,667 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6698232725262642, 'Losses/train_all_loss_mask': 0.0007271191541804, 'Losses/train_all_loss_dice': 0.4280275419354439, 'Losses/train_all_loss_iou': 0.22725334130227565, 'Losses/train_all_loss_class': 1.932700073314919e-08, 'Losses/train_all_core_loss': 0.6698232725262642, 'Trainer/where': 0.8747499999999999, 'Trainer/epoch': 174, 'Trainer/steps_train': 3500}
INFO 2025-05-19 14:28:35,941 train_utils.py: 271: Train Epoch: [175][ 0/20] | Batch Time: 13.26 (13.26) | Data Time: 9.93 (9.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 44m | Losses/train_all_loss: 5.48e-01 (5.48e-01)
INFO 2025-05-19 14:29:05,581 train_utils.py: 271: Train Epoch: [175][10/20] | Batch Time: 2.98 (3.90) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 44m | Losses/train_all_loss: 5.24e-01 (5.95e-01)
INFO 2025-05-19 14:29:32,694 trainer.py: 950: Estimated time remaining: 00d 00h 27m
INFO 2025-05-19 14:29:32,695 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:29:32,695 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6018287986516953, 'Losses/train_all_loss_mask': 0.0006990152949583716, 'Losses/train_all_loss_dice': 0.39310912787914276, 'Losses/train_all_loss_iou': 0.19473934285342692, 'Losses/train_all_loss_class': 2.386182376135082e-08, 'Losses/train_all_core_loss': 0.6018287986516953, 'Trainer/where': 0.8797499999999999, 'Trainer/epoch': 175, 'Trainer/steps_train': 3520}
INFO 2025-05-19 14:29:47,881 train_utils.py: 271: Train Epoch: [176][ 0/20] | Batch Time: 13.19 (13.19) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 45m | Losses/train_all_loss: 4.90e-01 (4.90e-01)
INFO 2025-05-19 14:30:17,194 train_utils.py: 271: Train Epoch: [176][10/20] | Batch Time: 2.97 (3.86) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 46m | Losses/train_all_loss: 5.16e-01 (6.35e-01)
INFO 2025-05-19 14:30:44,074 trainer.py: 950: Estimated time remaining: 00d 00h 26m
INFO 2025-05-19 14:30:44,075 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:30:44,075 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6453547865152359, 'Losses/train_all_loss_mask': 0.0007771145625156351, 'Losses/train_all_loss_dice': 0.40885881185531614, 'Losses/train_all_loss_iou': 0.22095368057489395, 'Losses/train_all_loss_class': 1.9386992988756903e-08, 'Losses/train_all_core_loss': 0.6453547865152359, 'Trainer/where': 0.8847499999999999, 'Trainer/epoch': 176, 'Trainer/steps_train': 3540}
INFO 2025-05-19 14:30:59,405 train_utils.py: 271: Train Epoch: [177][ 0/20] | Batch Time: 13.23 (13.23) | Data Time: 9.98 (9.98) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 46m | Losses/train_all_loss: 7.67e-01 (7.67e-01)
INFO 2025-05-19 14:31:28,596 train_utils.py: 271: Train Epoch: [177][10/20] | Batch Time: 2.83 (3.86) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 47m | Losses/train_all_loss: 8.89e-01 (6.76e-01)
INFO 2025-05-19 14:31:55,690 trainer.py: 950: Estimated time remaining: 00d 00h 25m
INFO 2025-05-19 14:31:55,690 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:31:55,690 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6746152251958847, 'Losses/train_all_loss_mask': 0.0007786064146785065, 'Losses/train_all_loss_dice': 0.4312878340482712, 'Losses/train_all_loss_iou': 0.2277552530169487, 'Losses/train_all_loss_class': 2.064970001658395e-08, 'Losses/train_all_core_loss': 0.6746152251958847, 'Trainer/where': 0.8897499999999999, 'Trainer/epoch': 177, 'Trainer/steps_train': 3560}
INFO 2025-05-19 14:32:11,207 train_utils.py: 271: Train Epoch: [178][ 0/20] | Batch Time: 13.43 (13.43) | Data Time: 10.05 (10.05) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 48m | Losses/train_all_loss: 4.99e-01 (4.99e-01)
INFO 2025-05-19 14:32:40,508 train_utils.py: 271: Train Epoch: [178][10/20] | Batch Time: 2.89 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 48m | Losses/train_all_loss: 1.31e+00 (7.15e-01)
INFO 2025-05-19 14:33:07,456 trainer.py: 950: Estimated time remaining: 00d 00h 24m
INFO 2025-05-19 14:33:07,457 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:33:07,457 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6605520263314247, 'Losses/train_all_loss_mask': 0.0008210498446715065, 'Losses/train_all_loss_dice': 0.4252463713288307, 'Losses/train_all_loss_iou': 0.2188846368342638, 'Losses/train_all_loss_class': 2.068686810741127e-08, 'Losses/train_all_core_loss': 0.6605520263314247, 'Trainer/where': 0.8947499999999999, 'Trainer/epoch': 178, 'Trainer/steps_train': 3580}
INFO 2025-05-19 14:33:22,905 train_utils.py: 271: Train Epoch: [179][ 0/20] | Batch Time: 13.39 (13.39) | Data Time: 10.03 (10.03) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 49m | Losses/train_all_loss: 5.66e-01 (5.66e-01)
INFO 2025-05-19 14:33:52,138 train_utils.py: 271: Train Epoch: [179][10/20] | Batch Time: 2.85 (3.87) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 49m | Losses/train_all_loss: 6.01e-01 (6.28e-01)
INFO 2025-05-19 14:34:18,494 trainer.py: 950: Estimated time remaining: 00d 00h 22m
INFO 2025-05-19 14:34:18,494 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:34:18,495 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.7023722499608993, 'Losses/train_all_loss_mask': 0.0007666552468435839, 'Losses/train_all_loss_dice': 0.44172397404909136, 'Losses/train_all_loss_iou': 0.2453151598572731, 'Losses/train_all_loss_class': 1.4586813068540038e-08, 'Losses/train_all_core_loss': 0.7023722499608993, 'Trainer/where': 0.8997499999999999, 'Trainer/epoch': 179, 'Trainer/steps_train': 3600}
INFO 2025-05-19 14:34:33,941 train_utils.py: 271: Train Epoch: [180][ 0/20] | Batch Time: 13.40 (13.40) | Data Time: 10.13 (10.13) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 50m | Losses/train_all_loss: 5.56e-01 (5.56e-01)
INFO 2025-05-19 14:35:03,300 train_utils.py: 271: Train Epoch: [180][10/20] | Batch Time: 2.97 (3.89) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 50m | Losses/train_all_loss: 4.49e-01 (6.26e-01)
INFO 2025-05-19 14:35:30,203 trainer.py: 950: Estimated time remaining: 00d 00h 21m
INFO 2025-05-19 14:35:30,203 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:35:30,204 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.643486961722374, 'Losses/train_all_loss_mask': 0.0007032587673165835, 'Losses/train_all_loss_dice': 0.41946077048778535, 'Losses/train_all_loss_iou': 0.20996100530028344, 'Losses/train_all_loss_class': 2.3890174372098728e-08, 'Losses/train_all_core_loss': 0.643486961722374, 'Trainer/where': 0.9047499999999999, 'Trainer/epoch': 180, 'Trainer/steps_train': 3620}
INFO 2025-05-19 14:35:45,481 train_utils.py: 271: Train Epoch: [181][ 0/20] | Batch Time: 13.23 (13.23) | Data Time: 10.00 (10.00) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 51m | Losses/train_all_loss: 1.06e+00 (1.06e+00)
INFO 2025-05-19 14:36:14,672 train_utils.py: 271: Train Epoch: [181][10/20] | Batch Time: 2.96 (3.86) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 52m | Losses/train_all_loss: 4.01e-01 (6.92e-01)
INFO 2025-05-19 14:36:41,669 trainer.py: 950: Estimated time remaining: 00d 00h 20m
INFO 2025-05-19 14:36:41,670 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:36:41,670 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6663399428129196, 'Losses/train_all_loss_mask': 0.0007555470278020948, 'Losses/train_all_loss_dice': 0.42361307740211485, 'Losses/train_all_loss_iou': 0.2276159033179283, 'Losses/train_all_loss_class': 2.6451394830040444e-08, 'Losses/train_all_core_loss': 0.6663399428129196, 'Trainer/where': 0.90975, 'Trainer/epoch': 181, 'Trainer/steps_train': 3640}
INFO 2025-05-19 14:36:57,091 train_utils.py: 271: Train Epoch: [182][ 0/20] | Batch Time: 13.34 (13.34) | Data Time: 10.08 (10.08) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 52m | Losses/train_all_loss: 5.99e-01 (5.99e-01)
INFO 2025-05-19 14:37:26,326 train_utils.py: 271: Train Epoch: [182][10/20] | Batch Time: 2.88 (3.87) | Data Time: 0.00 (0.92) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 53m | Losses/train_all_loss: 7.02e-01 (6.17e-01)
INFO 2025-05-19 14:37:53,348 trainer.py: 950: Estimated time remaining: 00d 00h 19m
INFO 2025-05-19 14:37:53,349 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:37:53,349 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.5875167846679688, 'Losses/train_all_loss_mask': 0.0006964172760490328, 'Losses/train_all_loss_dice': 0.38179755955934525, 'Losses/train_all_loss_iou': 0.19179085940122603, 'Losses/train_all_loss_class': 2.2846513614283027e-08, 'Losses/train_all_core_loss': 0.5875167846679688, 'Trainer/where': 0.91475, 'Trainer/epoch': 182, 'Trainer/steps_train': 3660}
INFO 2025-05-19 14:38:08,710 train_utils.py: 271: Train Epoch: [183][ 0/20] | Batch Time: 13.26 (13.26) | Data Time: 10.04 (10.04) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 54m | Losses/train_all_loss: 6.28e-01 (6.28e-01)
INFO 2025-05-19 14:38:38,170 train_utils.py: 271: Train Epoch: [183][10/20] | Batch Time: 3.00 (3.88) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 54m | Losses/train_all_loss: 5.23e-01 (5.98e-01)
INFO 2025-05-19 14:39:06,394 trainer.py: 950: Estimated time remaining: 00d 00h 18m
INFO 2025-05-19 14:39:06,394 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:39:06,395 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6127633288502693, 'Losses/train_all_loss_mask': 0.0007046734332107008, 'Losses/train_all_loss_dice': 0.40183903723955156, 'Losses/train_all_loss_iou': 0.19683080203831196, 'Losses/train_all_loss_class': 2.3687672645600345e-08, 'Losses/train_all_core_loss': 0.6127633288502693, 'Trainer/where': 0.91975, 'Trainer/epoch': 183, 'Trainer/steps_train': 3680}
INFO 2025-05-19 14:39:21,781 train_utils.py: 271: Train Epoch: [184][ 0/20] | Batch Time: 13.17 (13.17) | Data Time: 10.03 (10.03) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 55m | Losses/train_all_loss: 5.45e-01 (5.45e-01)
INFO 2025-05-19 14:39:48,488 train_utils.py: 271: Train Epoch: [184][10/20] | Batch Time: 2.61 (3.63) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 55m | Losses/train_all_loss: 7.07e-01 (6.28e-01)
INFO 2025-05-19 14:40:13,195 trainer.py: 950: Estimated time remaining: 00d 00h 15m
INFO 2025-05-19 14:40:13,196 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:40:13,196 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6408184990286827, 'Losses/train_all_loss_mask': 0.0007175217906478792, 'Losses/train_all_loss_dice': 0.421461720764637, 'Losses/train_all_loss_iou': 0.20500632673501967, 'Losses/train_all_loss_class': 2.3536409310409568e-08, 'Losses/train_all_core_loss': 0.6408184990286827, 'Trainer/where': 0.92475, 'Trainer/epoch': 184, 'Trainer/steps_train': 3700}
INFO 2025-05-19 14:40:28,184 train_utils.py: 271: Train Epoch: [185][ 0/20] | Batch Time: 12.92 (12.92) | Data Time: 9.78 (9.78) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 56m | Losses/train_all_loss: 6.31e-01 (6.31e-01)
INFO 2025-05-19 14:40:55,097 train_utils.py: 271: Train Epoch: [185][10/20] | Batch Time: 2.71 (3.62) | Data Time: 0.00 (0.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 56m | Losses/train_all_loss: 8.34e-01 (6.70e-01)
INFO 2025-05-19 14:41:19,634 trainer.py: 950: Estimated time remaining: 00d 00h 14m
INFO 2025-05-19 14:41:19,634 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:41:19,635 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6672253102064133, 'Losses/train_all_loss_mask': 0.0007234448392409831, 'Losses/train_all_loss_dice': 0.4309195175766945, 'Losses/train_all_loss_iou': 0.22183687686920167, 'Losses/train_all_loss_class': 2.108548857737702e-08, 'Losses/train_all_core_loss': 0.6672253102064133, 'Trainer/where': 0.92975, 'Trainer/epoch': 185, 'Trainer/steps_train': 3720}
INFO 2025-05-19 14:41:34,584 train_utils.py: 271: Train Epoch: [186][ 0/20] | Batch Time: 12.98 (12.98) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 57m | Losses/train_all_loss: 4.23e-01 (4.23e-01)
INFO 2025-05-19 14:42:01,259 train_utils.py: 271: Train Epoch: [186][10/20] | Batch Time: 2.72 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 57m | Losses/train_all_loss: 4.98e-01 (5.90e-01)
INFO 2025-05-19 14:42:25,953 trainer.py: 950: Estimated time remaining: 00d 00h 13m
INFO 2025-05-19 14:42:25,955 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:42:25,955 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.5884951427578926, 'Losses/train_all_loss_mask': 0.0006922901578946039, 'Losses/train_all_loss_dice': 0.3963508322834969, 'Losses/train_all_loss_iou': 0.17829848118126393, 'Losses/train_all_loss_class': 2.4692578848295456e-08, 'Losses/train_all_core_loss': 0.5884951427578926, 'Trainer/where': 0.93475, 'Trainer/epoch': 186, 'Trainer/steps_train': 3740}
INFO 2025-05-19 14:42:40,457 train_utils.py: 271: Train Epoch: [187][ 0/20] | Batch Time: 12.53 (12.53) | Data Time: 9.45 (9.45) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 58m | Losses/train_all_loss: 7.98e-01 (7.98e-01)
INFO 2025-05-19 14:43:06,890 train_utils.py: 271: Train Epoch: [187][10/20] | Batch Time: 2.71 (3.54) | Data Time: 0.00 (0.86) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 59m | Losses/train_all_loss: 5.77e-01 (6.85e-01)
INFO 2025-05-19 14:43:31,514 trainer.py: 950: Estimated time remaining: 00d 00h 12m
INFO 2025-05-19 14:43:31,515 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:43:31,515 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6696474716067314, 'Losses/train_all_loss_mask': 0.0007934355860925279, 'Losses/train_all_loss_dice': 0.4295269355177879, 'Losses/train_all_loss_iou': 0.2242518004029989, 'Losses/train_all_loss_class': 1.9900456615928874e-08, 'Losses/train_all_core_loss': 0.6696474716067314, 'Trainer/where': 0.93975, 'Trainer/epoch': 187, 'Trainer/steps_train': 3760}
INFO 2025-05-19 14:43:46,541 train_utils.py: 271: Train Epoch: [188][ 0/20] | Batch Time: 13.02 (13.02) | Data Time: 9.93 (9.93) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 59m | Losses/train_all_loss: 7.42e-01 (7.42e-01)
INFO 2025-05-19 14:44:13,223 train_utils.py: 271: Train Epoch: [188][10/20] | Batch Time: 2.72 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 00m | Losses/train_all_loss: 4.77e-01 (6.26e-01)
INFO 2025-05-19 14:44:37,537 trainer.py: 950: Estimated time remaining: 00d 00h 11m
INFO 2025-05-19 14:44:37,538 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:44:37,538 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6543344348669052, 'Losses/train_all_loss_mask': 0.0007030865483102389, 'Losses/train_all_loss_dice': 0.4214139446616173, 'Losses/train_all_loss_iou': 0.21885874271392822, 'Losses/train_all_loss_class': 2.0292558255974313e-08, 'Losses/train_all_core_loss': 0.6543344348669052, 'Trainer/where': 0.94475, 'Trainer/epoch': 188, 'Trainer/steps_train': 3780}
INFO 2025-05-19 14:44:52,452 train_utils.py: 271: Train Epoch: [189][ 0/20] | Batch Time: 12.93 (12.93) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 00m | Losses/train_all_loss: 6.43e-01 (6.43e-01)
INFO 2025-05-19 14:45:19,176 train_utils.py: 271: Train Epoch: [189][10/20] | Batch Time: 2.73 (3.60) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 01m | Losses/train_all_loss: 4.65e-01 (5.99e-01)
INFO 2025-05-19 14:45:44,041 trainer.py: 950: Estimated time remaining: 00d 00h 10m
INFO 2025-05-19 14:45:44,043 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:45:44,043 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.5985812440514564, 'Losses/train_all_loss_mask': 0.0006328634262899868, 'Losses/train_all_loss_dice': 0.3997520387172699, 'Losses/train_all_loss_iou': 0.18617192097008228, 'Losses/train_all_loss_class': 2.1866450139462757e-08, 'Losses/train_all_core_loss': 0.5985812440514564, 'Trainer/where': 0.94975, 'Trainer/epoch': 189, 'Trainer/steps_train': 3800}
INFO 2025-05-19 14:45:59,013 train_utils.py: 271: Train Epoch: [190][ 0/20] | Batch Time: 12.96 (12.96) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 01m | Losses/train_all_loss: 9.44e-01 (9.44e-01)
INFO 2025-05-19 14:46:25,844 train_utils.py: 271: Train Epoch: [190][10/20] | Batch Time: 2.61 (3.62) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 02m | Losses/train_all_loss: 5.91e-01 (6.43e-01)
INFO 2025-05-19 14:46:50,516 trainer.py: 950: Estimated time remaining: 00d 00h 09m
INFO 2025-05-19 14:46:50,516 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:46:50,516 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6629955723881722, 'Losses/train_all_loss_mask': 0.0007704496281803585, 'Losses/train_all_loss_dice': 0.42757080495357513, 'Losses/train_all_loss_iou': 0.22001575194299222, 'Losses/train_all_loss_class': 2.3065840593083918e-08, 'Losses/train_all_core_loss': 0.6629955723881722, 'Trainer/where': 0.95475, 'Trainer/epoch': 190, 'Trainer/steps_train': 3820}
INFO 2025-05-19 14:47:05,553 train_utils.py: 271: Train Epoch: [191][ 0/20] | Batch Time: 12.91 (12.91) | Data Time: 9.87 (9.87) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 02m | Losses/train_all_loss: 8.67e-01 (8.67e-01)
INFO 2025-05-19 14:47:31,945 train_utils.py: 271: Train Epoch: [191][10/20] | Batch Time: 2.65 (3.57) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 03m | Losses/train_all_loss: 5.56e-01 (6.51e-01)
INFO 2025-05-19 14:47:56,497 trainer.py: 950: Estimated time remaining: 00d 00h 08m
INFO 2025-05-19 14:47:56,497 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:47:56,497 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6357920184731484, 'Losses/train_all_loss_mask': 0.0007738633750705049, 'Losses/train_all_loss_dice': 0.41154265105724336, 'Losses/train_all_loss_iou': 0.20877210050821304, 'Losses/train_all_loss_class': 1.4845166873556082e-08, 'Losses/train_all_core_loss': 0.6357920184731484, 'Trainer/where': 0.95975, 'Trainer/epoch': 191, 'Trainer/steps_train': 3840}
INFO 2025-05-19 14:48:11,457 train_utils.py: 271: Train Epoch: [192][ 0/20] | Batch Time: 12.97 (12.97) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 04m | Losses/train_all_loss: 5.52e-01 (5.52e-01)
INFO 2025-05-19 14:48:37,651 train_utils.py: 271: Train Epoch: [192][10/20] | Batch Time: 2.61 (3.56) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 04m | Losses/train_all_loss: 5.25e-01 (6.78e-01)
INFO 2025-05-19 14:49:02,079 trainer.py: 950: Estimated time remaining: 00d 00h 07m
INFO 2025-05-19 14:49:02,079 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:49:02,079 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6957557797431946, 'Losses/train_all_loss_mask': 0.0007942280804854818, 'Losses/train_all_loss_dice': 0.4444396778941154, 'Losses/train_all_loss_iou': 0.23543154671788216, 'Losses/train_all_loss_class': 1.1840067282165024e-08, 'Losses/train_all_core_loss': 0.6957557797431946, 'Trainer/where': 0.96475, 'Trainer/epoch': 192, 'Trainer/steps_train': 3860}
INFO 2025-05-19 14:49:16,998 train_utils.py: 271: Train Epoch: [193][ 0/20] | Batch Time: 12.88 (12.88) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 05m | Losses/train_all_loss: 6.22e-01 (6.22e-01)
INFO 2025-05-19 14:49:43,329 train_utils.py: 271: Train Epoch: [193][10/20] | Batch Time: 2.62 (3.56) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 05m | Losses/train_all_loss: 9.27e-01 (7.01e-01)
INFO 2025-05-19 14:50:07,761 trainer.py: 950: Estimated time remaining: 00d 00h 06m
INFO 2025-05-19 14:50:07,762 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:50:07,762 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6506114795804023, 'Losses/train_all_loss_mask': 0.0007038670941255986, 'Losses/train_all_loss_dice': 0.41691870540380477, 'Losses/train_all_loss_iou': 0.21961542516946791, 'Losses/train_all_loss_class': 1.646270342270384e-08, 'Losses/train_all_core_loss': 0.6506114795804023, 'Trainer/where': 0.9697499999999999, 'Trainer/epoch': 193, 'Trainer/steps_train': 3880}
INFO 2025-05-19 14:50:22,821 train_utils.py: 271: Train Epoch: [194][ 0/20] | Batch Time: 12.95 (12.95) | Data Time: 9.91 (9.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 06m | Losses/train_all_loss: 7.61e-01 (7.61e-01)
INFO 2025-05-19 14:50:49,606 train_utils.py: 271: Train Epoch: [194][10/20] | Batch Time: 2.71 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 06m | Losses/train_all_loss: 6.00e-01 (6.14e-01)
INFO 2025-05-19 14:51:14,151 trainer.py: 950: Estimated time remaining: 00d 00h 05m
INFO 2025-05-19 14:51:14,152 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:51:14,152 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6643716305494308, 'Losses/train_all_loss_mask': 0.000790120537567418, 'Losses/train_all_loss_dice': 0.42831390649080275, 'Losses/train_all_loss_iou': 0.2202553018927574, 'Losses/train_all_loss_class': 2.393947939882679e-08, 'Losses/train_all_core_loss': 0.6643716305494308, 'Trainer/where': 0.9747499999999999, 'Trainer/epoch': 194, 'Trainer/steps_train': 3900}
INFO 2025-05-19 14:51:29,093 train_utils.py: 271: Train Epoch: [195][ 0/20] | Batch Time: 12.97 (12.97) | Data Time: 9.86 (9.86) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 07m | Losses/train_all_loss: 7.50e-01 (7.50e-01)
INFO 2025-05-19 14:51:55,769 train_utils.py: 271: Train Epoch: [195][10/20] | Batch Time: 2.63 (3.60) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 07m | Losses/train_all_loss: 5.27e-01 (6.39e-01)
INFO 2025-05-19 14:52:20,443 trainer.py: 950: Estimated time remaining: 00d 00h 04m
INFO 2025-05-19 14:52:20,443 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:52:20,444 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6170079723000527, 'Losses/train_all_loss_mask': 0.0006781185045838356, 'Losses/train_all_loss_dice': 0.3965717703104019, 'Losses/train_all_loss_iou': 0.20687382481992245, 'Losses/train_all_loss_class': 1.9720100841169596e-08, 'Losses/train_all_core_loss': 0.6170079723000527, 'Trainer/where': 0.9797499999999999, 'Trainer/epoch': 195, 'Trainer/steps_train': 3920}
INFO 2025-05-19 14:52:35,328 train_utils.py: 271: Train Epoch: [196][ 0/20] | Batch Time: 12.89 (12.89) | Data Time: 9.84 (9.84) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 08m | Losses/train_all_loss: 5.36e-01 (5.36e-01)
INFO 2025-05-19 14:53:02,247 train_utils.py: 271: Train Epoch: [196][10/20] | Batch Time: 2.72 (3.62) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 08m | Losses/train_all_loss: 4.15e-01 (5.88e-01)
INFO 2025-05-19 14:53:26,694 trainer.py: 950: Estimated time remaining: 00d 00h 03m
INFO 2025-05-19 14:53:26,694 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:53:26,695 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6150880187749863, 'Losses/train_all_loss_mask': 0.0006985255109611899, 'Losses/train_all_loss_dice': 0.40207123160362246, 'Losses/train_all_loss_iou': 0.19904626198112965, 'Losses/train_all_loss_class': 2.019713456480332e-08, 'Losses/train_all_core_loss': 0.6150880187749863, 'Trainer/where': 0.9847499999999999, 'Trainer/epoch': 196, 'Trainer/steps_train': 3940}
INFO 2025-05-19 14:53:41,554 train_utils.py: 271: Train Epoch: [197][ 0/20] | Batch Time: 12.88 (12.88) | Data Time: 9.89 (9.89) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 09m | Losses/train_all_loss: 7.04e-01 (7.04e-01)
INFO 2025-05-19 14:54:08,386 train_utils.py: 271: Train Epoch: [197][10/20] | Batch Time: 2.62 (3.61) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 10m | Losses/train_all_loss: 5.69e-01 (6.48e-01)
INFO 2025-05-19 14:54:32,841 trainer.py: 950: Estimated time remaining: 00d 00h 02m
INFO 2025-05-19 14:54:32,842 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:54:32,842 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6518778204917908, 'Losses/train_all_loss_mask': 0.0007189967538579368, 'Losses/train_all_loss_dice': 0.42334558814764023, 'Losses/train_all_loss_iou': 0.21415229514241219, 'Losses/train_all_loss_class': 1.523702553019035e-08, 'Losses/train_all_core_loss': 0.6518778204917908, 'Trainer/where': 0.9897499999999999, 'Trainer/epoch': 197, 'Trainer/steps_train': 3960}
INFO 2025-05-19 14:54:47,820 train_utils.py: 271: Train Epoch: [198][ 0/20] | Batch Time: 13.01 (13.01) | Data Time: 9.96 (9.96) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 10m | Losses/train_all_loss: 5.21e-01 (5.21e-01)
INFO 2025-05-19 14:55:14,286 train_utils.py: 271: Train Epoch: [198][10/20] | Batch Time: 2.62 (3.59) | Data Time: 0.00 (0.91) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 11m | Losses/train_all_loss: 8.87e-01 (6.06e-01)
INFO 2025-05-19 14:55:38,811 trainer.py: 950: Estimated time remaining: 00d 00h 01m
INFO 2025-05-19 14:55:38,812 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:55:38,812 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6187240973114967, 'Losses/train_all_loss_mask': 0.0007220595158287324, 'Losses/train_all_loss_dice': 0.4033037006855011, 'Losses/train_all_loss_iou': 0.2009791973978281, 'Losses/train_all_loss_class': 2.3430534490387346e-08, 'Losses/train_all_core_loss': 0.6187240973114967, 'Trainer/where': 0.9947499999999999, 'Trainer/epoch': 198, 'Trainer/steps_train': 3980}
INFO 2025-05-19 14:55:53,647 train_utils.py: 271: Train Epoch: [199][ 0/20] | Batch Time: 12.87 (12.87) | Data Time: 9.88 (9.88) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 11m | Losses/train_all_loss: 5.96e-01 (5.96e-01)
INFO 2025-05-19 14:56:20,230 train_utils.py: 271: Train Epoch: [199][10/20] | Batch Time: 2.55 (3.59) | Data Time: 0.00 (0.90) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 04h 12m | Losses/train_all_loss: 4.37e-01 (6.73e-01)
INFO 2025-05-19 14:56:44,607 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-05-19 14:56:44,607 trainer.py: 892: Synchronizing meters
INFO 2025-05-19 14:56:44,608 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 0.6788413822650909, 'Losses/train_all_loss_mask': 0.0007436424770276062, 'Losses/train_all_loss_dice': 0.42574792802333833, 'Losses/train_all_loss_iou': 0.2382205817848444, 'Losses/train_all_loss_class': 2.1247706993854364e-08, 'Losses/train_all_core_loss': 0.6788413822650909, 'Trainer/where': 0.9997499999999999, 'Trainer/epoch': 199, 'Trainer/steps_train': 4000}
