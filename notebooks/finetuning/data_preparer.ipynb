{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ef6174",
   "metadata": {},
   "source": [
    "# SAM2 Finetuning Training Data Prep\n",
    "\n",
    "### This notebook walks through the process of converting a folder of images and the corresponding label-studio ellipse annotations (.json) into the format required by the SAM2 Training framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ff49a",
   "metadata": {},
   "source": [
    "### Extract image name and create an image containing all labelled masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42730e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/Train20\"\n",
    "img_dir = os.path.join(data_dir, \"Raw\")\n",
    "\n",
    "labels = \"annotations.json\"\n",
    "\n",
    "def construct_masks_from_json(path):\n",
    "    \"\"\"\n",
    "    Construct masks from the annotations in the JSON file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        labels = json.load(f)\n",
    "        for label in labels:\n",
    "            img_name = \"-\".join(label[\"file_upload\"].split(\"-\")[1:])\n",
    "            ellipses = label[\"annotations\"]\n",
    "            canvas = np.zeros((ellipses[0][\"result\"][0][\"original_height\"], ellipses[0][\"result\"][0][\"original_width\"]), dtype=np.uint8) \n",
    "            for ellipse in ellipses[0][\"result\"]:\n",
    "                draw_mask(canvas, ellipse[\"original_height\"], ellipse[\"original_width\"],\n",
    "                        ellipse[\"value\"], ellipse[\"image_rotation\"])\n",
    "            data.append({\n",
    "                \"image\": img_name,\n",
    "                \"annotation\": canvas\n",
    "            }) \n",
    "    return data\n",
    "                \n",
    "def draw_mask(canvas, height, width, ellipse, image_rotation):\n",
    "    x = ellipse[\"x\"] / 100 * width\n",
    "    y = ellipse[\"y\"] / 100 * height\n",
    "    radius_x = ellipse[\"radiusX\"] / 100 * width\n",
    "    radius_y = ellipse[\"radiusY\"] / 100 * height\n",
    "    rotation = ellipse[\"rotation\"]\n",
    "    \n",
    "    total_rotation = rotation + image_rotation\n",
    "\n",
    "    center = (int(x), int(y))\n",
    "    axes = (int(radius_x), int(radius_y))\n",
    "\n",
    "    cv2.ellipse(canvas, center, axes, total_rotation, 0, 360, 255, -1)\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004c9df1",
   "metadata": {},
   "source": [
    "### Pair up images and masks and create dir structure for SAM2 Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_commas_and_decimals(path, name):\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            new_name = file.replace(\",\", \"\")\n",
    "            new_name = new_name.rstrip(\".jpg\").replace(\".\", \"\") + \".jpg\"\n",
    "            if new_name == name:\n",
    "                return file\n",
    "\n",
    "def create_sam2_training_data(path, data):\n",
    "    ann_path = os.path.join(path, \"Annotations\", \"placeholder-vid\") \n",
    "    img_path = os.path.join(path, \"JPEGImages\", \"placeholder-vid\")\n",
    "    raw_path = os.path.join(path, \"Raw\")\n",
    "    os.makedirs(ann_path, exist_ok=True)\n",
    "    os.makedirs(img_path, exist_ok=True)\n",
    "    \n",
    "    counter = 0\n",
    "    for item in data:\n",
    "        file = remove_commas_and_decimals(raw_path, item[\"image\"])\n",
    "        image = cv2.imread(os.path.join(raw_path, file))\n",
    "        name = f\"{'0'*(2-len(str(counter)))}{counter}.jpg\"\n",
    "        \n",
    "        cv2.imwrite(os.path.join(ann_path, name), item[\"annotation\"])\n",
    "        cv2.imwrite(os.path.join(img_path, name), image)\n",
    "        \n",
    "        counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = construct_masks_from_json(os.path.join(data_dir, labels))\n",
    "for elem in data:\n",
    "    if elem[\"image\"] == \"320-151-1x-3-5.4.jpg\":\n",
    "        elem[\"image\"] = \"320-151-1x-3-54.jpg\"\n",
    "create_sam2_training_data(data_dir, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb74b0",
   "metadata": {},
   "source": [
    "### Check that masks were created correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(os.path.join(data_dir, \"JPEGImages/placeholder-vid\", \"05.jpg\"))\t\n",
    "masks = data[5][\"annotation\"]\n",
    "\n",
    "# Create a color mask from the grayscale mask\n",
    "color_mask = cv2.merge([masks, masks, masks])  # Create a 3-channel mask\n",
    "\n",
    "# Define transparency factor (adjust as needed)\n",
    "alpha = 0.4\n",
    "\n",
    "# Add the colored mask to the original image\n",
    "result_image = cv2.addWeighted(color_mask, alpha, image, 1 - alpha, 0)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Original Image with Masks', result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38791736",
   "metadata": {},
   "source": [
    "# Experiment with new Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf28341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved '00.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\00\\00.jpg'\n",
      "Moved '01.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\01\\00.jpg'\n",
      "Moved '02.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\02\\00.jpg'\n",
      "Moved '03.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\03\\00.jpg'\n",
      "Moved '04.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\04\\00.jpg'\n",
      "Moved '05.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\05\\00.jpg'\n",
      "Moved '06.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\06\\00.jpg'\n",
      "Moved '07.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\07\\00.jpg'\n",
      "Moved '08.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\08\\00.jpg'\n",
      "Moved '09.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\09\\00.jpg'\n",
      "Moved '10.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\10\\00.jpg'\n",
      "Moved '11.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\11\\00.jpg'\n",
      "Moved '12.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\12\\00.jpg'\n",
      "Moved '13.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\13\\00.jpg'\n",
      "Moved '14.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\14\\00.jpg'\n",
      "Moved '15.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\15\\00.jpg'\n",
      "Moved '16.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\16\\00.jpg'\n",
      "Moved '17.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\17\\00.jpg'\n",
      "Moved '18.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\18\\00.jpg'\n",
      "Moved '19.jpg' to 'C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\\19\\00.jpg'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_files_into_folders(path):\n",
    "    # Ensure the provided path is valid\n",
    "    if not os.path.isdir(path):\n",
    "        print(f\"Error: {path} is not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    for entry in os.listdir(path):\n",
    "        full_path = os.path.join(path, entry)\n",
    "\n",
    "        # Skip if it's a directory\n",
    "        if os.path.isdir(full_path):\n",
    "            continue\n",
    "\n",
    "        # Create a directory with the same name as the file (excluding extension)\n",
    "        filename_without_ext = os.path.splitext(entry)[0]\n",
    "        new_dir_path = os.path.join(path, filename_without_ext)\n",
    "        os.makedirs(new_dir_path, exist_ok=True)\n",
    "\n",
    "        # Move the file into the new directory and rename it to \"00.jpg\"\n",
    "        new_file_path = os.path.join(new_dir_path, \"00.jpg\")\n",
    "        shutil.move(full_path, new_file_path)\n",
    "\n",
    "        print(f\"Moved '{entry}' to '{new_file_path}'\")\n",
    "\n",
    "# Example usage\n",
    "organize_files_into_folders(\"C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages/placeholder-vid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fa7f50",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5f72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### Train App Config ####################\n",
      "scratch:\n",
      "  resolution: 1024\n",
      "  train_batch_size: 1\n",
      "  num_train_workers: 1\n",
      "  num_frames: 1\n",
      "  max_num_objects: 3\n",
      "  base_lr: 5.0e-06\n",
      "  vision_lr: 3.0e-06\n",
      "  phases_per_epoch: 1\n",
      "  num_epochs: 50\n",
      "dataset:\n",
      "  img_folder: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/JPEGImages\n",
      "  gt_folder: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/data/Train20/Annotations\n",
      "  file_list_txt: null\n",
      "  multiplier: 2\n",
      "vos:\n",
      "  train_transforms:\n",
      "  - _target_: training.dataset.transforms.ComposeAPI\n",
      "    transforms:\n",
      "    - _target_: training.dataset.transforms.RandomHorizontalFlip\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.RandomAffine\n",
      "      degrees: 25\n",
      "      shear: 20\n",
      "      image_interpolation: bilinear\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.RandomResizeAPI\n",
      "      sizes: ${scratch.resolution}\n",
      "      square: true\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.ColorJitter\n",
      "      consistent_transform: true\n",
      "      brightness: 0.1\n",
      "      contrast: 0.03\n",
      "      saturation: 0.03\n",
      "      hue: null\n",
      "    - _target_: training.dataset.transforms.RandomGrayscale\n",
      "      p: 0.05\n",
      "      consistent_transform: true\n",
      "    - _target_: training.dataset.transforms.ColorJitter\n",
      "      consistent_transform: false\n",
      "      brightness: 0.1\n",
      "      contrast: 0.05\n",
      "      saturation: 0.05\n",
      "      hue: null\n",
      "    - _target_: training.dataset.transforms.ToTensorAPI\n",
      "    - _target_: training.dataset.transforms.NormalizeAPI\n",
      "      mean:\n",
      "      - 0.485\n",
      "      - 0.456\n",
      "      - 0.406\n",
      "      std:\n",
      "      - 0.229\n",
      "      - 0.224\n",
      "      - 0.225\n",
      "trainer:\n",
      "  _target_: training.trainer.Trainer\n",
      "  mode: train_only\n",
      "  max_epochs: ${times:${scratch.num_epochs},${scratch.phases_per_epoch}}\n",
      "  accelerator: cuda\n",
      "  seed_value: 123\n",
      "  model:\n",
      "    _target_: training.model.sam2.SAM2Train\n",
      "    image_encoder:\n",
      "      _target_: sam2.modeling.backbones.image_encoder.ImageEncoder\n",
      "      scalp: 1\n",
      "      trunk:\n",
      "        _target_: sam2.modeling.backbones.hieradet.Hiera\n",
      "        embed_dim: 112\n",
      "        num_heads: 2\n",
      "        drop_path_rate: 0.1\n",
      "      neck:\n",
      "        _target_: sam2.modeling.backbones.image_encoder.FpnNeck\n",
      "        position_encoding:\n",
      "          _target_: sam2.modeling.position_encoding.PositionEmbeddingSine\n",
      "          num_pos_feats: 256\n",
      "          normalize: true\n",
      "          scale: null\n",
      "          temperature: 10000\n",
      "        d_model: 256\n",
      "        backbone_channel_list:\n",
      "        - 896\n",
      "        - 448\n",
      "        - 224\n",
      "        - 112\n",
      "        fpn_top_down_levels:\n",
      "        - 2\n",
      "        - 3\n",
      "        fpn_interp_model: nearest\n",
      "    memory_attention:\n",
      "      _target_: sam2.modeling.memory_attention.MemoryAttention\n",
      "      d_model: 256\n",
      "      pos_enc_at_input: true\n",
      "      layer:\n",
      "        _target_: sam2.modeling.memory_attention.MemoryAttentionLayer\n",
      "        activation: relu\n",
      "        dim_feedforward: 2048\n",
      "        dropout: 0.1\n",
      "        pos_enc_at_attn: false\n",
      "        self_attention:\n",
      "          _target_: sam2.modeling.sam.transformer.RoPEAttention\n",
      "          rope_theta: 10000.0\n",
      "          feat_sizes:\n",
      "          - 64\n",
      "          - 64\n",
      "          embedding_dim: 256\n",
      "          num_heads: 1\n",
      "          downsample_rate: 1\n",
      "          dropout: 0.1\n",
      "        d_model: 256\n",
      "        pos_enc_at_cross_attn_keys: true\n",
      "        pos_enc_at_cross_attn_queries: false\n",
      "        cross_attention:\n",
      "          _target_: sam2.modeling.sam.transformer.RoPEAttention\n",
      "          rope_theta: 10000.0\n",
      "          feat_sizes:\n",
      "          - 64\n",
      "          - 64\n",
      "          rope_k_repeat: true\n",
      "          embedding_dim: 256\n",
      "          num_heads: 1\n",
      "          downsample_rate: 1\n",
      "          dropout: 0.1\n",
      "          kv_in_dim: 64\n",
      "      num_layers: 4\n",
      "    memory_encoder:\n",
      "      _target_: sam2.modeling.memory_encoder.MemoryEncoder\n",
      "      out_dim: 64\n",
      "      position_encoding:\n",
      "        _target_: sam2.modeling.position_encoding.PositionEmbeddingSine\n",
      "        num_pos_feats: 64\n",
      "        normalize: true\n",
      "        scale: null\n",
      "        temperature: 10000\n",
      "      mask_downsampler:\n",
      "        _target_: sam2.modeling.memory_encoder.MaskDownSampler\n",
      "        kernel_size: 3\n",
      "        stride: 2\n",
      "        padding: 1\n",
      "      fuser:\n",
      "        _target_: sam2.modeling.memory_encoder.Fuser\n",
      "        layer:\n",
      "          _target_: sam2.modeling.memory_encoder.CXBlock\n",
      "          dim: 256\n",
      "          kernel_size: 7\n",
      "          padding: 3\n",
      "          layer_scale_init_value: 1.0e-06\n",
      "          use_dwconv: true\n",
      "        num_layers: 2\n",
      "    num_maskmem: 7\n",
      "    image_size: ${scratch.resolution}\n",
      "    sigmoid_scale_for_mem_enc: 20.0\n",
      "    sigmoid_bias_for_mem_enc: -10.0\n",
      "    use_mask_input_as_output_without_sam: true\n",
      "    directly_add_no_mem_embed: true\n",
      "    no_obj_embed_spatial: true\n",
      "    use_high_res_features_in_sam: true\n",
      "    multimask_output_in_sam: true\n",
      "    iou_prediction_use_sigmoid: true\n",
      "    use_obj_ptrs_in_encoder: true\n",
      "    add_tpos_enc_to_obj_ptrs: true\n",
      "    proj_tpos_enc_in_obj_ptrs: true\n",
      "    use_signed_tpos_enc_to_obj_ptrs: true\n",
      "    only_obj_ptrs_in_the_past_for_eval: true\n",
      "    pred_obj_scores: true\n",
      "    pred_obj_scores_mlp: true\n",
      "    fixed_no_obj_ptr: true\n",
      "    multimask_output_for_tracking: true\n",
      "    use_multimask_token_for_obj_ptr: true\n",
      "    multimask_min_pt_num: 0\n",
      "    multimask_max_pt_num: 1\n",
      "    use_mlp_for_obj_ptr_proj: true\n",
      "    prob_to_use_pt_input_for_train: 0.5\n",
      "    prob_to_use_pt_input_for_eval: 0.0\n",
      "    prob_to_use_box_input_for_train: 0.5\n",
      "    prob_to_use_box_input_for_eval: 0.0\n",
      "    prob_to_sample_from_gt_for_train: 0.1\n",
      "    num_frames_to_correct_for_train: 2\n",
      "    num_frames_to_correct_for_eval: 1\n",
      "    rand_frames_to_correct_for_train: true\n",
      "    add_all_frames_to_correct_as_cond: true\n",
      "    num_init_cond_frames_for_train: 2\n",
      "    rand_init_cond_frames_for_train: true\n",
      "    num_correction_pt_per_frame: 7\n",
      "    use_act_ckpt_iterative_pt_sampling: false\n",
      "    num_init_cond_frames_for_eval: 1\n",
      "    forward_backbone_per_frame_for_eval: true\n",
      "  data:\n",
      "    train:\n",
      "      _target_: training.dataset.sam2_datasets.TorchTrainMixedDataset\n",
      "      phases_per_epoch: ${scratch.phases_per_epoch}\n",
      "      batch_sizes:\n",
      "      - ${scratch.train_batch_size}\n",
      "      datasets:\n",
      "      - _target_: training.dataset.utils.RepeatFactorWrapper\n",
      "        dataset:\n",
      "          _target_: training.dataset.utils.ConcatDataset\n",
      "          datasets:\n",
      "          - _target_: training.dataset.vos_dataset.VOSDataset\n",
      "            transforms: ${vos.train_transforms}\n",
      "            training: true\n",
      "            video_dataset:\n",
      "              _target_: training.dataset.vos_raw_dataset.PNGRawDataset\n",
      "              img_folder: ${dataset.img_folder}\n",
      "              gt_folder: ${dataset.gt_folder}\n",
      "              file_list_txt: ${dataset.file_list_txt}\n",
      "            sampler:\n",
      "              _target_: training.dataset.vos_sampler.RandomUniformSampler\n",
      "              num_frames: ${scratch.num_frames}\n",
      "              max_num_objects: ${scratch.max_num_objects}\n",
      "            multiplier: ${dataset.multiplier}\n",
      "      shuffle: true\n",
      "      num_workers: ${scratch.num_train_workers}\n",
      "      pin_memory: true\n",
      "      drop_last: true\n",
      "      collate_fn:\n",
      "        _target_: training.utils.data_utils.collate_fn\n",
      "        _partial_: true\n",
      "        dict_key: all\n",
      "  optim:\n",
      "    amp:\n",
      "      enabled: true\n",
      "      amp_dtype: bfloat16\n",
      "    optimizer:\n",
      "      _target_: torch.optim.AdamW\n",
      "    gradient_clip:\n",
      "      _target_: training.optimizer.GradientClipper\n",
      "      max_norm: 0.1\n",
      "      norm_type: 2\n",
      "    param_group_modifiers:\n",
      "    - _target_: training.optimizer.layer_decay_param_modifier\n",
      "      _partial_: true\n",
      "      layer_decay_value: 0.9\n",
      "      apply_to: image_encoder.trunk\n",
      "      overrides:\n",
      "      - pattern: '*pos_embed*'\n",
      "        value: 1.0\n",
      "    options:\n",
      "      lr:\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.CosineParamScheduler\n",
      "          start_value: ${scratch.base_lr}\n",
      "          end_value: ${divide:${scratch.base_lr},10}\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.CosineParamScheduler\n",
      "          start_value: ${scratch.vision_lr}\n",
      "          end_value: ${divide:${scratch.vision_lr},10}\n",
      "        param_names:\n",
      "        - image_encoder.*\n",
      "      weight_decay:\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.ConstantParamScheduler\n",
      "          value: 0.1\n",
      "      - scheduler:\n",
      "          _target_: fvcore.common.param_scheduler.ConstantParamScheduler\n",
      "          value: 0.0\n",
      "        param_names:\n",
      "        - '*bias*'\n",
      "        module_cls_names:\n",
      "        - torch.nn.LayerNorm\n",
      "  loss:\n",
      "    all:\n",
      "      _target_: training.loss_fns.MultiStepMultiMasksAndIous\n",
      "      weight_dict:\n",
      "        loss_mask: 20\n",
      "        loss_dice: 1\n",
      "        loss_iou: 1\n",
      "        loss_class: 1\n",
      "      supervise_all_iou: true\n",
      "      iou_use_l1_loss: true\n",
      "      pred_obj_scores: true\n",
      "      focal_gamma_obj_score: 0.0\n",
      "      focal_alpha_obj_score: -1.0\n",
      "  distributed:\n",
      "    backend: gloo\n",
      "    find_unused_parameters: true\n",
      "  logging:\n",
      "    tensorboard_writer:\n",
      "      _target_: training.utils.logger.make_tensorboard_logger\n",
      "      log_dir: ${launcher.experiment_log_dir}/tensorboard\n",
      "      flush_secs: 120\n",
      "      should_log: true\n",
      "    log_dir: ${launcher.experiment_log_dir}/logs\n",
      "    log_freq: 10\n",
      "  checkpoint:\n",
      "    save_dir: ${launcher.experiment_log_dir}/checkpoints\n",
      "    save_freq: 0\n",
      "    model_weight_initializer:\n",
      "      _partial_: true\n",
      "      _target_: training.utils.checkpoint_utils.load_state_dict_into_model\n",
      "      strict: true\n",
      "      ignore_unexpected_keys: null\n",
      "      ignore_missing_keys: null\n",
      "      state_dict:\n",
      "        _target_: training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels\n",
      "        checkpoint_path: ../checkpoints/sam2.1_hiera_base_plus.pt\n",
      "        ckpt_state_dict_keys:\n",
      "        - model\n",
      "launcher:\n",
      "  num_nodes: 1\n",
      "  gpus_per_node: 1\n",
      "  experiment_log_dir: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_unchangedConfig\n",
      "submitit:\n",
      "  partition: null\n",
      "  account: null\n",
      "  qos: null\n",
      "  cpus_per_task: 10\n",
      "  use_cluster: false\n",
      "  timeout_hour: 24\n",
      "  name: null\n",
      "  port_range:\n",
      "  - 10000\n",
      "  - 65000\n",
      "\n",
      "############################################################\n",
      "INFO 2025-05-06 12:10:49,389 train_utils.py: 108: MACHINE SEED: 6150\n",
      "INFO 2025-05-06 12:10:49,398 train_utils.py: 154: Logging ENV_VARIABLES\n",
      "INFO 2025-05-06 12:10:49,398 train_utils.py: 155: ALLUSERSPROFILE=C:\\ProgramData\n",
      "AMDRMPATH=C:\\Program Files\\AMD\\RyzenMaster\\\n",
      "APPDATA=C:\\Users\\Micha\\AppData\\Roaming\n",
      "CHROME_CRASHPAD_PIPE_NAME=\\\\.\\pipe\\crashpad_14132_JVCNYIYEOHPZTTWN\n",
      "CLICOLOR=1\n",
      "CLICOLOR_FORCE=1\n",
      "COMMONPROGRAMFILES=C:\\Program Files\\Common Files\n",
      "COMMONPROGRAMFILES(X86)=C:\\Program Files (x86)\\Common Files\n",
      "COMMONPROGRAMW6432=C:\\Program Files\\Common Files\n",
      "COMPUTERNAME=DESKTOP-SJKAOIV\n",
      "COMSPEC=C:\\WINDOWS\\system32\\cmd.exe\n",
      "CUDA_MODULE_LOADING=LAZY\n",
      "CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\n",
      "CUDA_PATH_V12_9=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\n",
      "DRIVERDATA=C:\\Windows\\System32\\Drivers\\DriverData\n",
      "EFC_13508_1262719628=1\n",
      "EFC_13508_1592913036=1\n",
      "EFC_13508_2775293581=1\n",
      "EFC_13508_3789132940=1\n",
      "ELECTRON_RUN_AS_NODE=1\n",
      "FORCE_COLOR=1\n",
      "FPS_BROWSER_APP_PROFILE_STRING=Internet Explorer\n",
      "FPS_BROWSER_USER_PROFILE_STRING=Default\n",
      "GIT_PAGER=cat\n",
      "HOMEDRIVE=C:\n",
      "HOMEPATH=\\Users\\Micha\n",
      "HYDRA_FULL_ERROR=1\n",
      "JPY_INTERRUPT_EVENT=1316\n",
      "LOCALAPPDATA=C:\\Users\\Micha\\AppData\\Local\n",
      "LOCAL_RANK=0\n",
      "LOGONSERVER=\\\\DESKTOP-SJKAOIV\n",
      "MASTER_ADDR=localhost\n",
      "MASTER_PORT=21781\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "NUMBER_OF_PROCESSORS=12\n",
      "ONEDRIVE=C:\\Users\\Micha\\OneDrive\n",
      "ORIGINAL_XDG_CURRENT_DESKTOP=undefined\n",
      "OS=Windows_NT\n",
      "PAGER=cat\n",
      "PATH=c:\\Users\\Micha\\Desktop\\BachelorProject\\AI-Powered-Biosensing\\.venv\\Scripts;C:\\Users\\Micha\\Desktop\\BachelorProject\\AI-Powered-Biosensing\\.venv\\Scripts;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\libnvvp;C:\\mingw64\\bin;C:\\jdk-18.0.2\\bin;C:\\Program Files (x86)\\Razer Chroma SDK\\bin;C:\\Program Files\\Razer Chroma SDK\\bin;C:\\Program Files (x86)\\Razer\\ChromaBroadcast\\bin;C:\\Program Files\\Razer\\ChromaBroadcast\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\WINDOWS\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\Git\\cmd;C:\\apache-maven-3.9.6\\bin;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Users\\Micha\\.local\\bin;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2025.2.0\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Users\\Micha\\.local\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Micha\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Microsoft VS Code\\bin;C:\\Gradle\\gradle-8.4\\bin;\n",
      "PATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC\n",
      "PROCESSOR_ARCHITECTURE=AMD64\n",
      "PROCESSOR_IDENTIFIER=AMD64 Family 23 Model 113 Stepping 0, AuthenticAMD\n",
      "PROCESSOR_LEVEL=23\n",
      "PROCESSOR_REVISION=7100\n",
      "PROGRAMDATA=C:\\ProgramData\n",
      "PROGRAMFILES=C:\\Program Files\n",
      "PROGRAMFILES(X86)=C:\\Program Files (x86)\n",
      "PROGRAMW6432=C:\\Program Files\n",
      "PROMPT=(ai-powered-biosensing) $P$G\n",
      "PSMODULEPATH=C:\\Program Files\\WindowsPowerShell\\Modules;C:\\WINDOWS\\system32\\WindowsPowerShell\\v1.0\\Modules\n",
      "PUBLIC=C:\\Users\\Public\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING=1\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "PYTHONIOENCODING=utf-8\n",
      "PYTHONUNBUFFERED=1\n",
      "PYTHONUSERBASE=C:\\Users\\Micha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\n",
      "PYTHON_FROZEN_MODULES=on\n",
      "RANK=0\n",
      "SESSIONNAME=Console\n",
      "SYSTEMDRIVE=C:\n",
      "SYSTEMROOT=C:\\WINDOWS\n",
      "TEMP=C:\\Users\\Micha\\AppData\\Local\\Temp\n",
      "TERM=xterm-color\n",
      "TMP=C:\\Users\\Micha\\AppData\\Local\\Temp\n",
      "TORCH_NCCL_ASYNC_ERROR_HANDLING=1\n",
      "USERDOMAIN=DESKTOP-SJKAOIV\n",
      "USERDOMAIN_ROAMINGPROFILE=DESKTOP-SJKAOIV\n",
      "USERNAME=Micha\n",
      "USERPROFILE=C:\\Users\\Micha\n",
      "VBOX_MSI_INSTALL_PATH=C:\\Program Files\\Oracle\\VirtualBox\\\n",
      "VIRTUAL_ENV=C:\\Users\\Micha\\Desktop\\BachelorProject\\AI-Powered-Biosensing\\.venv\n",
      "VIRTUAL_ENV_PROMPT=ai-powered-biosensing\n",
      "VSCODE_CODE_CACHE_PATH=C:\\Users\\Micha\\AppData\\Roaming\\Code\\CachedData\\17baf841131aa23349f217ca7c570c76ee87b957\n",
      "VSCODE_CRASH_REPORTER_PROCESS_TYPE=extensionHost\n",
      "VSCODE_CWD=C:\\Microsoft VS Code\n",
      "VSCODE_ESM_ENTRYPOINT=vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS=true\n",
      "VSCODE_IPC_HOOK=\\\\.\\pipe\\24d3f695-1.99.3-main-sock\n",
      "VSCODE_L10N_BUNDLE_LOCATION=\n",
      "VSCODE_NLS_CONFIG={\"userLocale\":\"en-us\",\"osLocale\":\"en-de\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"C:\\\\Microsoft VS Code\\\\resources\\\\app\\\\out\\\\nls.messages.json\",\"locale\":\"en-us\",\"availableLanguages\":{}}\n",
      "VSCODE_PID=14132\n",
      "WINDIR=C:\\WINDOWS\n",
      "WORLD_SIZE=1\n",
      "_OLD_VIRTUAL_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\libnvvp;C:\\mingw64\\bin;C:\\jdk-18.0.2\\bin;C:\\Program Files (x86)\\Razer Chroma SDK\\bin;C:\\Program Files\\Razer Chroma SDK\\bin;C:\\Program Files (x86)\\Razer\\ChromaBroadcast\\bin;C:\\Program Files\\Razer\\ChromaBroadcast\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\WINDOWS\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\Git\\cmd;C:\\apache-maven-3.9.6\\bin;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Users\\Micha\\.local\\bin;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2025.2.0\\;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Users\\Micha\\.local\\bin;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\Micha\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Microsoft VS Code\\bin;C:\\Gradle\\gradle-8.4\\bin;\n",
      "_OLD_VIRTUAL_PROMPT=$P$G\n",
      "__PSLOCKDOWNPOLICY=0\n",
      "\n",
      "INFO 2025-05-06 12:10:49,398 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.\n",
      "INFO 2025-05-06 12:10:49,399 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: C:/Users/Micha/Desktop/BachelorProject/AI-Powered-Biosensing/models/Train20_b+_unchangedConfig/tensorboard\n",
      "INFO 2025-05-06 12:10:50,324 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5\n",
      "INFO 2025-05-06 12:10:50,328 trainer.py:1059: ====================\n",
      "INFO 2025-05-06 12:10:50,329 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>\n",
      "INFO 2025-05-06 12:10:50,332 trainer.py:1061: Model is SAM2Train(\n",
      "  (image_encoder): ImageEncoder(\n",
      "    (trunk): Hiera(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 112, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
      "      )\n",
      "      (blocks): ModuleList(\n",
      "        (0): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=112, out_features=336, bias=True)\n",
      "            (proj): Linear(in_features=112, out_features=112, bias=True)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=112, out_features=448, bias=True)\n",
      "              (1): Linear(in_features=448, out_features=112, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (1): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=112, out_features=336, bias=True)\n",
      "            (proj): Linear(in_features=112, out_features=112, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=112, out_features=448, bias=True)\n",
      "              (1): Linear(in_features=448, out_features=112, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (2): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((112,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=112, out_features=672, bias=True)\n",
      "            (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=224, out_features=896, bias=True)\n",
      "              (1): Linear(in_features=896, out_features=224, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=112, out_features=224, bias=True)\n",
      "        )\n",
      "        (3-4): 2 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=224, out_features=672, bias=True)\n",
      "            (proj): Linear(in_features=224, out_features=224, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=224, out_features=896, bias=True)\n",
      "              (1): Linear(in_features=896, out_features=224, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (5): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((224,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=224, out_features=1344, bias=True)\n",
      "            (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=448, out_features=1792, bias=True)\n",
      "              (1): Linear(in_features=1792, out_features=448, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=224, out_features=448, bias=True)\n",
      "        )\n",
      "        (6-20): 15 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=448, out_features=1344, bias=True)\n",
      "            (proj): Linear(in_features=448, out_features=448, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=448, out_features=1792, bias=True)\n",
      "              (1): Linear(in_features=1792, out_features=448, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "        (21): MultiScaleBlock(\n",
      "          (norm1): LayerNorm((448,), eps=1e-06, elementwise_affine=True)\n",
      "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "            (qkv): Linear(in_features=448, out_features=2688, bias=True)\n",
      "            (proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
      "              (1): Linear(in_features=3584, out_features=896, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "          (proj): Linear(in_features=448, out_features=896, bias=True)\n",
      "        )\n",
      "        (22-23): 2 x MultiScaleBlock(\n",
      "          (norm1): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): MultiScaleAttention(\n",
      "            (qkv): Linear(in_features=896, out_features=2688, bias=True)\n",
      "            (proj): Linear(in_features=896, out_features=896, bias=True)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((896,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=896, out_features=3584, bias=True)\n",
      "              (1): Linear(in_features=3584, out_features=896, bias=True)\n",
      "            )\n",
      "            (act): GELU(approximate='none')\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): FpnNeck(\n",
      "      (position_encoding): PositionEmbeddingSine()\n",
      "      (convs): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (conv): Conv2d(224, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (3): Sequential(\n",
      "          (conv): Conv2d(112, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))\n",
      "  (memory_attention): MemoryAttention(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x MemoryAttentionLayer(\n",
      "        (self_attn): RoPEAttention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (cross_attn_image): RoPEAttention(\n",
      "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (k_proj): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (v_proj): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (memory_encoder): MemoryEncoder(\n",
      "    (mask_downsampler): MaskDownSampler(\n",
      "      (encoder): Sequential(\n",
      "        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): LayerNorm2d()\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (4): LayerNorm2d()\n",
      "        (5): GELU(approximate='none')\n",
      "        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (7): LayerNorm2d()\n",
      "        (8): GELU(approximate='none')\n",
      "        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (10): LayerNorm2d()\n",
      "        (11): GELU(approximate='none')\n",
      "        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fuser): Fuser(\n",
      "      (proj): Identity()\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x CXBlock(\n",
      "          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
      "          (norm): LayerNorm2d()\n",
      "          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (position_encoding): PositionEmbeddingSine()\n",
      "    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (sam_prompt_encoder): PromptEncoder(\n",
      "    (pe_layer): PositionEmbeddingRandom()\n",
      "    (point_embeddings): ModuleList(\n",
      "      (0-3): 4 x Embedding(1, 256)\n",
      "    )\n",
      "    (not_a_point_embed): Embedding(1, 256)\n",
      "    (mask_downscaling): Sequential(\n",
      "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): LayerNorm2d()\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (4): LayerNorm2d()\n",
      "      (5): GELU(approximate='none')\n",
      "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (no_mask_embed): Embedding(1, 256)\n",
      "  )\n",
      "  (sam_mask_decoder): MaskDecoder(\n",
      "    (transformer): TwoWayTransformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TwoWayAttentionBlock(\n",
      "          (self_attn): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_token_to_image): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "          )\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): MLP(\n",
      "            (layers): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
      "              (1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "            )\n",
      "            (act): ReLU()\n",
      "          )\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (cross_attn_image_to_token): Attention(\n",
      "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_attn_token_to_image): Attention(\n",
      "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (iou_token): Embedding(1, 256)\n",
      "    (mask_tokens): Embedding(4, 256)\n",
      "    (obj_score_token): Embedding(1, 256)\n",
      "    (output_upscaling): Sequential(\n",
      "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): LayerNorm2d()\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (4): GELU(approximate='none')\n",
      "    )\n",
      "    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (output_hypernetworks_mlps): ModuleList(\n",
      "      (0-3): 4 x MLP(\n",
      "        (layers): ModuleList(\n",
      "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
      "        )\n",
      "        (act): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (iou_prediction_head): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "      )\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (pred_obj_score_head): MLP(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "      )\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (obj_ptr_proj): MLP(\n",
      "    (layers): ModuleList(\n",
      "      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)\n",
      ")\n",
      "INFO 2025-05-06 12:10:50,332 trainer.py:1062: \tTotal parameters 80.9 M\n",
      "INFO 2025-05-06 12:10:50,333 trainer.py:1063: \tTrainable parameters 80.9 M\n",
      "INFO 2025-05-06 12:10:50,333 trainer.py:1066: \tNon-Trainable parameters 0  \n",
      "INFO 2025-05-06 12:10:50,333 trainer.py:1069: ====================\n",
      "INFO 2025-05-06 12:10:50,339 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.\n",
      "INFO 2025-05-06 12:10:50,339 trainer.py: 314: Moving components to device cuda:0 and local rank 0.\n",
      "INFO 2025-05-06 12:10:50,453 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.\n",
      "INFO 2025-05-06 12:10:50,478 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.proj.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.5.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.proj.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.weight'}\n",
      "INFO 2025-05-06 12:10:50,480 optimizer.py: 248: Matches for param_name [*bias*]: {'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'memory_attention.layers.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'memory_attention.layers.3.norm2.bias', 'memory_attention.layers.0.linear2.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'memory_attention.layers.2.linear2.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'memory_attention.layers.1.norm2.bias', 'mask_downsample.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'obj_ptr_tpos_proj.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.2.linear1.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.neck.convs.1.conv.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'memory_attention.norm.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.5.proj.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'sam_mask_decoder.conv_s1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'memory_encoder.out_proj.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.3.norm3.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.proj.bias', 'obj_ptr_proj.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias'}\n",
      "INFO 2025-05-06 12:10:50,481 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_attention.layers.3.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.2.norm2.weight', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.norm.bias', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.3.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'memory_attention.layers.2.norm3.weight', 'memory_attention.layers.1.norm1.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.19.norm1.weight'} \n",
      "Raw dataset length = 20\n",
      "INFO 2025-05-06 12:10:52,322 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]\n",
      "INFO 2025-05-06 12:10:52,583 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': True, 'ignore_unexpected_keys': None, 'ignore_missing_keys': None, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': '../checkpoints/sam2.1_hiera_base_plus.pt', 'ckpt_state_dict_keys': ['model']}}\n",
      "INFO 2025-05-06 12:11:17,678 train_utils.py: 271: Train Epoch: [0][ 0/40] | Batch Time: 24.82 (24.82) | Data Time: 11.46 (11.46) | Mem (GB): 6.00 (6.00/6.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.00e+01 (1.00e+01)\n",
      "INFO 2025-05-06 12:11:38,554 train_utils.py: 271: Train Epoch: [0][10/40] | Batch Time: 1.04 (4.15) | Data Time: 0.00 (1.05) | Mem (GB): 7.00 (6.91/7.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.22e+01 (1.58e+01)\n",
      "INFO 2025-05-06 12:11:47,125 train_utils.py: 271: Train Epoch: [0][20/40] | Batch Time: 0.83 (2.58) | Data Time: 0.00 (0.55) | Mem (GB): 7.00 (6.95/7.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.14e+01 (1.31e+01)\n",
      "INFO 2025-05-06 12:11:55,697 train_utils.py: 271: Train Epoch: [0][30/40] | Batch Time: 0.97 (2.03) | Data Time: 0.00 (0.37) | Mem (GB): 7.00 (6.97/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 5.64e+00 (1.18e+01)\n",
      "INFO 2025-05-06 12:12:05,492 trainer.py: 950: Estimated time remaining: 00d 00h 57m\n",
      "INFO 2025-05-06 12:12:05,495 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:12:05,496 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 11.070118975639343, 'Losses/train_all_loss_mask': 0.13159860795130954, 'Losses/train_all_loss_dice': 7.463248503208161, 'Losses/train_all_loss_iou': 0.9748869808390737, 'Losses/train_all_loss_class': 1.1642162432234926e-05, 'Losses/train_all_core_loss': 11.070118975639343, 'Trainer/where': 0.0195, 'Trainer/epoch': 0, 'Trainer/steps_train': 40}\n",
      "INFO 2025-05-06 12:12:27,156 train_utils.py: 271: Train Epoch: [1][ 0/40] | Batch Time: 17.84 (17.84) | Data Time: 16.70 (16.70) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 8.31e+00 (8.31e+00)\n",
      "INFO 2025-05-06 12:12:35,034 train_utils.py: 271: Train Epoch: [1][10/40] | Batch Time: 0.72 (2.34) | Data Time: 0.00 (1.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 1.33e+01 (9.51e+00)\n",
      "INFO 2025-05-06 12:12:42,737 train_utils.py: 271: Train Epoch: [1][20/40] | Batch Time: 0.77 (1.59) | Data Time: 0.00 (0.80) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 01m | Losses/train_all_loss: 8.91e+00 (8.89e+00)\n",
      "INFO 2025-05-06 12:12:50,133 train_utils.py: 271: Train Epoch: [1][30/40] | Batch Time: 0.74 (1.32) | Data Time: 0.00 (0.54) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 9.55e+00 (8.74e+00)\n",
      "INFO 2025-05-06 12:12:57,952 trainer.py: 950: Estimated time remaining: 00d 00h 37m\n",
      "INFO 2025-05-06 12:12:57,952 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:12:57,953 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 8.726571822166443, 'Losses/train_all_loss_mask': 0.03861400107343797, 'Losses/train_all_loss_dice': 7.500398433208465, 'Losses/train_all_loss_iou': 0.4536822626949288, 'Losses/train_all_loss_class': 0.00021116981601470018, 'Losses/train_all_core_loss': 8.726571822166443, 'Trainer/where': 0.0395, 'Trainer/epoch': 1, 'Trainer/steps_train': 80}\n",
      "INFO 2025-05-06 12:13:12,293 train_utils.py: 271: Train Epoch: [2][ 0/40] | Batch Time: 11.88 (11.88) | Data Time: 10.80 (10.80) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 7.93e+00 (7.93e+00)\n",
      "INFO 2025-05-06 12:13:19,880 train_utils.py: 271: Train Epoch: [2][10/40] | Batch Time: 0.80 (1.77) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.09e+00 (8.64e+00)\n",
      "INFO 2025-05-06 12:13:27,529 train_utils.py: 271: Train Epoch: [2][20/40] | Batch Time: 0.80 (1.29) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.06e+00 (8.61e+00)\n",
      "INFO 2025-05-06 12:13:35,631 train_utils.py: 271: Train Epoch: [2][30/40] | Batch Time: 0.76 (1.14) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 8.76e+00 (8.35e+00)\n",
      "INFO 2025-05-06 12:13:43,507 trainer.py: 950: Estimated time remaining: 00d 00h 32m\n",
      "INFO 2025-05-06 12:13:43,508 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:13:43,508 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 8.32911719083786, 'Losses/train_all_loss_mask': 0.03439100562536623, 'Losses/train_all_loss_dice': 7.393140453100204, 'Losses/train_all_loss_iou': 0.24703905555070377, 'Losses/train_all_loss_class': 0.0011175910406848288, 'Losses/train_all_core_loss': 8.32911719083786, 'Trainer/where': 0.059500000000000004, 'Trainer/epoch': 2, 'Trainer/steps_train': 120}\n",
      "INFO 2025-05-06 12:13:57,276 train_utils.py: 271: Train Epoch: [3][ 0/40] | Batch Time: 11.40 (11.40) | Data Time: 10.33 (10.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 7.41e+00 (7.41e+00)\n",
      "INFO 2025-05-06 12:14:05,918 train_utils.py: 271: Train Epoch: [3][10/40] | Batch Time: 0.86 (1.82) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 8.26e+00 (7.76e+00)\n",
      "INFO 2025-05-06 12:14:13,736 train_utils.py: 271: Train Epoch: [3][20/40] | Batch Time: 0.75 (1.33) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.14e+01 (7.69e+00)\n",
      "INFO 2025-05-06 12:14:21,673 train_utils.py: 271: Train Epoch: [3][30/40] | Batch Time: 0.86 (1.15) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 7.94e+00 (7.94e+00)\n",
      "INFO 2025-05-06 12:14:29,372 trainer.py: 950: Estimated time remaining: 00d 00h 32m\n",
      "INFO 2025-05-06 12:14:29,372 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:14:29,372 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.9369899988174435, 'Losses/train_all_loss_mask': 0.021272483198481497, 'Losses/train_all_loss_dice': 7.447648394107818, 'Losses/train_all_loss_iou': 0.06381208094317117, 'Losses/train_all_loss_class': 7.987330211083332e-05, 'Losses/train_all_core_loss': 7.9369899988174435, 'Trainer/where': 0.0795, 'Trainer/epoch': 3, 'Trainer/steps_train': 160}\n",
      "INFO 2025-05-06 12:14:43,688 train_utils.py: 271: Train Epoch: [4][ 0/40] | Batch Time: 11.32 (11.32) | Data Time: 10.08 (10.08) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 1.03e+01 (1.03e+01)\n",
      "INFO 2025-05-06 12:14:51,967 train_utils.py: 271: Train Epoch: [4][10/40] | Batch Time: 0.79 (1.78) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.03e+00 (8.28e+00)\n",
      "INFO 2025-05-06 12:14:59,650 train_utils.py: 271: Train Epoch: [4][20/40] | Batch Time: 0.75 (1.30) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.31e+00 (8.04e+00)\n",
      "INFO 2025-05-06 12:15:07,297 train_utils.py: 271: Train Epoch: [4][30/40] | Batch Time: 0.79 (1.13) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.85e+00 (8.02e+00)\n",
      "INFO 2025-05-06 12:15:15,205 trainer.py: 950: Estimated time remaining: 00d 00h 31m\n",
      "INFO 2025-05-06 12:15:15,206 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:15:15,206 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.955873024463654, 'Losses/train_all_loss_mask': 0.027196310719591565, 'Losses/train_all_loss_dice': 7.3713669896125795, 'Losses/train_all_loss_iou': 0.040540499775670466, 'Losses/train_all_loss_class': 3.93597102458898e-05, 'Losses/train_all_core_loss': 7.955873024463654, 'Trainer/where': 0.09949999999999999, 'Trainer/epoch': 4, 'Trainer/steps_train': 200}\n",
      "INFO 2025-05-06 12:15:28,331 train_utils.py: 271: Train Epoch: [5][ 0/40] | Batch Time: 11.28 (11.28) | Data Time: 10.35 (10.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 1.01e+01 (1.01e+01)\n",
      "INFO 2025-05-06 12:15:35,535 train_utils.py: 271: Train Epoch: [5][10/40] | Batch Time: 0.71 (1.68) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 5.46e+00 (7.67e+00)\n",
      "INFO 2025-05-06 12:15:42,783 train_utils.py: 271: Train Epoch: [5][20/40] | Batch Time: 0.75 (1.23) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 8.01e+00 (7.65e+00)\n",
      "INFO 2025-05-06 12:15:50,092 train_utils.py: 271: Train Epoch: [5][30/40] | Batch Time: 0.73 (1.07) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 7.98e+00 (7.79e+00)\n",
      "INFO 2025-05-06 12:15:57,481 trainer.py: 950: Estimated time remaining: 00d 00h 29m\n",
      "INFO 2025-05-06 12:15:57,481 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:15:57,481 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.713245296478272, 'Losses/train_all_loss_mask': 0.021138020500075072, 'Losses/train_all_loss_dice': 7.235592943429947, 'Losses/train_all_loss_iou': 0.054880560189121755, 'Losses/train_all_loss_class': 1.1419168161097559e-05, 'Losses/train_all_core_loss': 7.713245296478272, 'Trainer/where': 0.1195, 'Trainer/epoch': 5, 'Trainer/steps_train': 240}\n",
      "INFO 2025-05-06 12:16:11,355 train_utils.py: 271: Train Epoch: [6][ 0/40] | Batch Time: 11.01 (11.01) | Data Time: 10.04 (10.04) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 6.68e+00 (6.68e+00)\n",
      "INFO 2025-05-06 12:16:18,567 train_utils.py: 271: Train Epoch: [6][10/40] | Batch Time: 0.69 (1.66) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 8.09e+00 (7.35e+00)\n",
      "INFO 2025-05-06 12:16:25,843 train_utils.py: 271: Train Epoch: [6][20/40] | Batch Time: 0.72 (1.21) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 4.56e+00 (7.25e+00)\n",
      "INFO 2025-05-06 12:16:32,957 train_utils.py: 271: Train Epoch: [6][30/40] | Batch Time: 0.74 (1.05) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 8.83e+00 (7.41e+00)\n",
      "INFO 2025-05-06 12:16:40,495 trainer.py: 950: Estimated time remaining: 00d 00h 28m\n",
      "INFO 2025-05-06 12:16:40,496 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:16:40,496 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.426462268829345, 'Losses/train_all_loss_mask': 0.013435622929682723, 'Losses/train_all_loss_dice': 7.140339636802674, 'Losses/train_all_loss_iou': 0.017393272405388415, 'Losses/train_all_loss_class': 1.6959562142915274e-05, 'Losses/train_all_core_loss': 7.426462268829345, 'Trainer/where': 0.13949999999999999, 'Trainer/epoch': 6, 'Trainer/steps_train': 280}\n",
      "INFO 2025-05-06 12:16:55,018 train_utils.py: 271: Train Epoch: [7][ 0/40] | Batch Time: 11.51 (11.51) | Data Time: 10.32 (10.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.89e+00 (7.89e+00)\n",
      "INFO 2025-05-06 12:17:02,683 train_utils.py: 271: Train Epoch: [7][10/40] | Batch Time: 0.73 (1.74) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.84e+00 (7.66e+00)\n",
      "INFO 2025-05-06 12:17:10,566 train_utils.py: 271: Train Epoch: [7][20/40] | Batch Time: 0.80 (1.29) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 8.01e+00 (7.69e+00)\n",
      "INFO 2025-05-06 12:17:18,228 train_utils.py: 271: Train Epoch: [7][30/40] | Batch Time: 0.77 (1.12) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.51e+00 (7.66e+00)\n",
      "INFO 2025-05-06 12:17:25,883 trainer.py: 950: Estimated time remaining: 00d 00h 29m\n",
      "INFO 2025-05-06 12:17:25,884 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:17:25,884 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.570271575450898, 'Losses/train_all_loss_mask': 0.018155527746057488, 'Losses/train_all_loss_dice': 7.180947840213776, 'Losses/train_all_loss_iou': 0.026198733624914892, 'Losses/train_all_loss_class': 1.4512801002197761e-05, 'Losses/train_all_core_loss': 7.570271575450898, 'Trainer/where': 0.1595, 'Trainer/epoch': 7, 'Trainer/steps_train': 320}\n",
      "INFO 2025-05-06 12:17:40,579 train_utils.py: 271: Train Epoch: [8][ 0/40] | Batch Time: 11.59 (11.59) | Data Time: 10.57 (10.57) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 8.05e+00 (8.05e+00)\n",
      "INFO 2025-05-06 12:17:48,022 train_utils.py: 271: Train Epoch: [8][10/40] | Batch Time: 0.78 (1.73) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 7.50e+00 (7.32e+00)\n",
      "INFO 2025-05-06 12:17:55,663 train_utils.py: 271: Train Epoch: [8][20/40] | Batch Time: 0.72 (1.27) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 5.01e+00 (7.53e+00)\n",
      "INFO 2025-05-06 12:18:02,867 train_utils.py: 271: Train Epoch: [8][30/40] | Batch Time: 0.69 (1.09) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.59e+00 (7.47e+00)\n",
      "INFO 2025-05-06 12:18:10,255 trainer.py: 950: Estimated time remaining: 00d 00h 27m\n",
      "INFO 2025-05-06 12:18:10,255 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:18:10,255 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.546712076663971, 'Losses/train_all_loss_mask': 0.01239486394042615, 'Losses/train_all_loss_dice': 7.292927074432373, 'Losses/train_all_loss_iou': 0.005877068237168714, 'Losses/train_all_loss_class': 1.0626199967145311e-05, 'Losses/train_all_core_loss': 7.546712076663971, 'Trainer/where': 0.1795, 'Trainer/epoch': 8, 'Trainer/steps_train': 360}\n",
      "INFO 2025-05-06 12:18:23,279 train_utils.py: 271: Train Epoch: [9][ 0/40] | Batch Time: 11.19 (11.19) | Data Time: 10.17 (10.17) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 5.37e+00 (5.37e+00)\n",
      "INFO 2025-05-06 12:18:30,838 train_utils.py: 271: Train Epoch: [9][10/40] | Batch Time: 0.85 (1.70) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 7.70e+00 (7.24e+00)\n",
      "INFO 2025-05-06 12:18:38,503 train_utils.py: 271: Train Epoch: [9][20/40] | Batch Time: 0.70 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 7.72e+00 (7.42e+00)\n",
      "INFO 2025-05-06 12:18:45,696 train_utils.py: 271: Train Epoch: [9][30/40] | Batch Time: 0.68 (1.08) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 8.01e+00 (7.47e+00)\n",
      "INFO 2025-05-06 12:18:52,955 trainer.py: 950: Estimated time remaining: 00d 00h 26m\n",
      "INFO 2025-05-06 12:18:52,956 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:18:52,956 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.363995659351349, 'Losses/train_all_loss_mask': 0.01637169875757536, 'Losses/train_all_loss_dice': 7.029054290056228, 'Losses/train_all_loss_iou': 0.00749545753642451, 'Losses/train_all_loss_class': 1.1991118451959437e-05, 'Losses/train_all_core_loss': 7.363995659351349, 'Trainer/where': 0.19949999999999998, 'Trainer/epoch': 9, 'Trainer/steps_train': 400}\n",
      "INFO 2025-05-06 12:19:06,925 train_utils.py: 271: Train Epoch: [10][ 0/40] | Batch Time: 11.10 (11.10) | Data Time: 10.01 (10.01) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.86e+00 (7.86e+00)\n",
      "INFO 2025-05-06 12:19:14,151 train_utils.py: 271: Train Epoch: [10][10/40] | Batch Time: 0.71 (1.67) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.95e+00 (7.82e+00)\n",
      "INFO 2025-05-06 12:19:21,376 train_utils.py: 271: Train Epoch: [10][20/40] | Batch Time: 0.73 (1.22) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 7.33e+00 (7.74e+00)\n",
      "INFO 2025-05-06 12:19:28,626 train_utils.py: 271: Train Epoch: [10][30/40] | Batch Time: 0.74 (1.06) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 6.60e+00 (7.40e+00)\n",
      "INFO 2025-05-06 12:19:36,233 trainer.py: 950: Estimated time remaining: 00d 00h 25m\n",
      "INFO 2025-05-06 12:19:36,234 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:19:36,234 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.842531460523605, 'Losses/train_all_loss_mask': 0.028266674003680235, 'Losses/train_all_loss_dice': 7.266219466924667, 'Losses/train_all_loss_iou': 0.010966380530589959, 'Losses/train_all_loss_class': 1.2117899669306097e-05, 'Losses/train_all_core_loss': 7.842531460523605, 'Trainer/where': 0.2195, 'Trainer/epoch': 10, 'Trainer/steps_train': 440}\n",
      "INFO 2025-05-06 12:19:50,938 train_utils.py: 271: Train Epoch: [11][ 0/40] | Batch Time: 11.61 (11.61) | Data Time: 10.42 (10.42) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.97e+00 (7.97e+00)\n",
      "INFO 2025-05-06 12:19:58,535 train_utils.py: 271: Train Epoch: [11][10/40] | Batch Time: 0.75 (1.75) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.47e+00 (8.41e+00)\n",
      "INFO 2025-05-06 12:20:06,060 train_utils.py: 271: Train Epoch: [11][20/40] | Batch Time: 0.72 (1.27) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 6.16e+00 (7.87e+00)\n",
      "INFO 2025-05-06 12:20:13,257 train_utils.py: 271: Train Epoch: [11][30/40] | Batch Time: 0.74 (1.09) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 8.11e+00 (7.85e+00)\n",
      "INFO 2025-05-06 12:20:21,454 trainer.py: 950: Estimated time remaining: 00d 00h 26m\n",
      "INFO 2025-05-06 12:20:21,455 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:20:21,455 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.6230742812156675, 'Losses/train_all_loss_mask': 0.022081726275064283, 'Losses/train_all_loss_dice': 7.131791281700134, 'Losses/train_all_loss_iou': 0.049642949422559465, 'Losses/train_all_loss_class': 5.564365184085318e-06, 'Losses/train_all_core_loss': 7.6230742812156675, 'Trainer/where': 0.2395, 'Trainer/epoch': 11, 'Trainer/steps_train': 480}\n",
      "INFO 2025-05-06 12:20:36,324 train_utils.py: 271: Train Epoch: [12][ 0/40] | Batch Time: 11.85 (11.85) | Data Time: 10.73 (10.73) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 7.79e+00 (7.79e+00)\n",
      "INFO 2025-05-06 12:20:44,150 train_utils.py: 271: Train Epoch: [12][10/40] | Batch Time: 0.82 (1.79) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 5.29e+00 (7.34e+00)\n",
      "INFO 2025-05-06 12:20:52,062 train_utils.py: 271: Train Epoch: [12][20/40] | Batch Time: 0.79 (1.31) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.47e+00 (7.18e+00)\n",
      "INFO 2025-05-06 12:20:59,824 train_utils.py: 271: Train Epoch: [12][30/40] | Batch Time: 0.77 (1.14) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.72e+00 (7.27e+00)\n",
      "INFO 2025-05-06 12:21:07,685 trainer.py: 950: Estimated time remaining: 00d 00h 26m\n",
      "INFO 2025-05-06 12:21:07,686 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:21:07,686 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.25102082490921, 'Losses/train_all_loss_mask': 0.01171252755302703, 'Losses/train_all_loss_dice': 6.989954054355621, 'Losses/train_all_loss_iou': 0.02680949586138013, 'Losses/train_all_loss_class': 6.729083637679878e-06, 'Losses/train_all_core_loss': 7.25102082490921, 'Trainer/where': 0.2595, 'Trainer/epoch': 12, 'Trainer/steps_train': 520}\n",
      "INFO 2025-05-06 12:21:21,171 train_utils.py: 271: Train Epoch: [13][ 0/40] | Batch Time: 11.11 (11.11) | Data Time: 10.00 (10.00) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.90e+00 (7.90e+00)\n",
      "INFO 2025-05-06 12:21:29,164 train_utils.py: 271: Train Epoch: [13][10/40] | Batch Time: 0.79 (1.74) | Data Time: 0.00 (0.91) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 7.36e+00 (7.07e+00)\n",
      "INFO 2025-05-06 12:21:36,995 train_utils.py: 271: Train Epoch: [13][20/40] | Batch Time: 0.78 (1.28) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 5.52e+00 (7.16e+00)\n",
      "INFO 2025-05-06 12:21:44,960 train_utils.py: 271: Train Epoch: [13][30/40] | Batch Time: 0.82 (1.13) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 5.41e+00 (7.19e+00)\n",
      "INFO 2025-05-06 12:21:52,810 trainer.py: 950: Estimated time remaining: 00d 00h 25m\n",
      "INFO 2025-05-06 12:21:52,811 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:21:52,811 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.206873404979706, 'Losses/train_all_loss_mask': 0.008398232536274008, 'Losses/train_all_loss_dice': 7.021433866024017, 'Losses/train_all_loss_iou': 0.017467440287873615, 'Losses/train_all_loss_class': 7.437198032533843e-06, 'Losses/train_all_core_loss': 7.206873404979706, 'Trainer/where': 0.27949999999999997, 'Trainer/epoch': 13, 'Trainer/steps_train': 560}\n",
      "INFO 2025-05-06 12:22:07,349 train_utils.py: 271: Train Epoch: [14][ 0/40] | Batch Time: 11.50 (11.50) | Data Time: 10.32 (10.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.05e+00 (8.05e+00)\n",
      "INFO 2025-05-06 12:22:15,175 train_utils.py: 271: Train Epoch: [14][10/40] | Batch Time: 0.79 (1.76) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.03e+00 (6.62e+00)\n",
      "INFO 2025-05-06 12:22:23,058 train_utils.py: 271: Train Epoch: [14][20/40] | Batch Time: 0.78 (1.30) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 7.84e+00 (7.22e+00)\n",
      "INFO 2025-05-06 12:22:31,011 train_utils.py: 271: Train Epoch: [14][30/40] | Batch Time: 0.80 (1.13) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 8.16e+00 (7.26e+00)\n",
      "INFO 2025-05-06 12:22:38,723 trainer.py: 950: Estimated time remaining: 00d 00h 24m\n",
      "INFO 2025-05-06 12:22:38,724 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:22:38,724 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.300611937046051, 'Losses/train_all_loss_mask': 0.012035798746728688, 'Losses/train_all_loss_dice': 7.004784899950027, 'Losses/train_all_loss_iou': 0.05509790132782655, 'Losses/train_all_loss_class': 1.3149682293800425e-05, 'Losses/train_all_core_loss': 7.300611937046051, 'Trainer/where': 0.2995, 'Trainer/epoch': 14, 'Trainer/steps_train': 600}\n",
      "INFO 2025-05-06 12:22:53,153 train_utils.py: 271: Train Epoch: [15][ 0/40] | Batch Time: 11.37 (11.37) | Data Time: 10.28 (10.28) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 3.79e+00 (3.79e+00)\n",
      "INFO 2025-05-06 12:23:01,177 train_utils.py: 271: Train Epoch: [15][10/40] | Batch Time: 0.81 (1.76) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 5.20e+00 (7.04e+00)\n",
      "INFO 2025-05-06 12:23:09,455 train_utils.py: 271: Train Epoch: [15][20/40] | Batch Time: 0.80 (1.32) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 6.19e+00 (7.57e+00)\n",
      "INFO 2025-05-06 12:23:17,782 train_utils.py: 271: Train Epoch: [15][30/40] | Batch Time: 0.80 (1.16) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 7.98e+00 (7.53e+00)\n",
      "INFO 2025-05-06 12:23:25,947 trainer.py: 950: Estimated time remaining: 00d 00h 24m\n",
      "INFO 2025-05-06 12:23:25,947 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:23:25,948 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.425289410352707, 'Losses/train_all_loss_mask': 0.017450540048594122, 'Losses/train_all_loss_dice': 7.042691689729691, 'Losses/train_all_loss_iou': 0.033581233429868004, 'Losses/train_all_loss_class': 5.76396910254573e-06, 'Losses/train_all_core_loss': 7.425289410352707, 'Trainer/where': 0.3195, 'Trainer/epoch': 15, 'Trainer/steps_train': 640}\n",
      "INFO 2025-05-06 12:23:41,503 train_utils.py: 271: Train Epoch: [16][ 0/40] | Batch Time: 11.58 (11.58) | Data Time: 10.43 (10.43) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 9.20e+00 (9.20e+00)\n",
      "INFO 2025-05-06 12:23:49,578 train_utils.py: 271: Train Epoch: [16][10/40] | Batch Time: 0.81 (1.79) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.87e+00 (7.48e+00)\n",
      "INFO 2025-05-06 12:23:57,696 train_utils.py: 271: Train Epoch: [16][20/40] | Batch Time: 0.82 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 5.37e+00 (7.54e+00)\n",
      "INFO 2025-05-06 12:24:05,769 train_utils.py: 271: Train Epoch: [16][30/40] | Batch Time: 0.79 (1.16) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.02e+00 (7.40e+00)\n",
      "INFO 2025-05-06 12:24:13,798 trainer.py: 950: Estimated time remaining: 00d 00h 23m\n",
      "INFO 2025-05-06 12:24:13,798 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:24:13,798 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.515242075920105, 'Losses/train_all_loss_mask': 0.014881125573447207, 'Losses/train_all_loss_dice': 7.192204147577286, 'Losses/train_all_loss_iou': 0.025410169914721337, 'Losses/train_all_loss_class': 5.363927651558242e-06, 'Losses/train_all_core_loss': 7.515242075920105, 'Trainer/where': 0.3395, 'Trainer/epoch': 16, 'Trainer/steps_train': 680}\n",
      "INFO 2025-05-06 12:24:28,542 train_utils.py: 271: Train Epoch: [17][ 0/40] | Batch Time: 11.79 (11.79) | Data Time: 10.52 (10.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.94e+00 (7.94e+00)\n",
      "INFO 2025-05-06 12:24:36,678 train_utils.py: 271: Train Epoch: [17][10/40] | Batch Time: 0.80 (1.81) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 7.58e+00 (7.79e+00)\n",
      "INFO 2025-05-06 12:24:44,745 train_utils.py: 271: Train Epoch: [17][20/40] | Batch Time: 0.80 (1.33) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 8.11e+00 (7.57e+00)\n",
      "INFO 2025-05-06 12:24:52,877 train_utils.py: 271: Train Epoch: [17][30/40] | Batch Time: 0.82 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.56e+00 (7.50e+00)\n",
      "INFO 2025-05-06 12:25:00,927 trainer.py: 950: Estimated time remaining: 00d 00h 23m\n",
      "INFO 2025-05-06 12:25:00,928 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:25:00,928 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.4604461073875425, 'Losses/train_all_loss_mask': 0.014641078482964077, 'Losses/train_all_loss_dice': 7.140776228904724, 'Losses/train_all_loss_iou': 0.026841932014212942, 'Losses/train_all_loss_class': 6.434302503066647e-06, 'Losses/train_all_core_loss': 7.4604461073875425, 'Trainer/where': 0.35950000000000004, 'Trainer/epoch': 17, 'Trainer/steps_train': 720}\n",
      "INFO 2025-05-06 12:25:15,743 train_utils.py: 271: Train Epoch: [18][ 0/40] | Batch Time: 11.72 (11.72) | Data Time: 10.42 (10.42) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 7.53e+00 (7.53e+00)\n",
      "INFO 2025-05-06 12:25:23,745 train_utils.py: 271: Train Epoch: [18][10/40] | Batch Time: 0.79 (1.79) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 7.63e+00 (7.65e+00)\n",
      "INFO 2025-05-06 12:25:31,751 train_utils.py: 271: Train Epoch: [18][20/40] | Batch Time: 0.78 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.80e+00 (7.34e+00)\n",
      "INFO 2025-05-06 12:25:39,886 train_utils.py: 271: Train Epoch: [18][30/40] | Batch Time: 0.83 (1.16) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 6.62e+00 (7.45e+00)\n",
      "INFO 2025-05-06 12:25:47,845 trainer.py: 950: Estimated time remaining: 00d 00h 22m\n",
      "INFO 2025-05-06 12:25:47,845 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:25:47,846 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.4822596430778505, 'Losses/train_all_loss_mask': 0.009911912253301125, 'Losses/train_all_loss_dice': 7.2440059065818785, 'Losses/train_all_loss_iou': 0.04000875173242093, 'Losses/train_all_loss_class': 6.77559006057038e-06, 'Losses/train_all_core_loss': 7.4822596430778505, 'Trainer/where': 0.3795, 'Trainer/epoch': 18, 'Trainer/steps_train': 760}\n",
      "INFO 2025-05-06 12:26:02,446 train_utils.py: 271: Train Epoch: [19][ 0/40] | Batch Time: 11.47 (11.47) | Data Time: 10.44 (10.44) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.00e+00 (8.00e+00)\n",
      "INFO 2025-05-06 12:26:10,499 train_utils.py: 271: Train Epoch: [19][10/40] | Batch Time: 0.80 (1.77) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 7.68e+00 (7.86e+00)\n",
      "INFO 2025-05-06 12:26:18,598 train_utils.py: 271: Train Epoch: [19][20/40] | Batch Time: 0.80 (1.32) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 9.30e+00 (7.60e+00)\n",
      "INFO 2025-05-06 12:26:26,624 train_utils.py: 271: Train Epoch: [19][30/40] | Batch Time: 0.79 (1.15) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.24e+00 (7.45e+00)\n",
      "INFO 2025-05-06 12:26:34,666 trainer.py: 950: Estimated time remaining: 00d 00h 21m\n",
      "INFO 2025-05-06 12:26:34,667 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:26:34,667 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.375670433044434, 'Losses/train_all_loss_mask': 0.015354900644888403, 'Losses/train_all_loss_dice': 7.043369603157044, 'Losses/train_all_loss_iou': 0.025185529651935212, 'Losses/train_all_loss_class': 1.728652392927188e-05, 'Losses/train_all_core_loss': 7.375670433044434, 'Trainer/where': 0.3995, 'Trainer/epoch': 19, 'Trainer/steps_train': 800}\n",
      "INFO 2025-05-06 12:26:48,913 train_utils.py: 271: Train Epoch: [20][ 0/40] | Batch Time: 11.68 (11.68) | Data Time: 10.49 (10.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 8.00e+00 (8.00e+00)\n",
      "INFO 2025-05-06 12:26:57,179 train_utils.py: 271: Train Epoch: [20][10/40] | Batch Time: 0.81 (1.81) | Data Time: 0.00 (0.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 7.78e+00 (7.61e+00)\n",
      "INFO 2025-05-06 12:27:05,372 train_utils.py: 271: Train Epoch: [20][20/40] | Batch Time: 0.83 (1.34) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 7.90e+00 (7.58e+00)\n",
      "INFO 2025-05-06 12:27:13,554 train_utils.py: 271: Train Epoch: [20][30/40] | Batch Time: 0.83 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 8.21e+00 (7.46e+00)\n",
      "INFO 2025-05-06 12:27:22,001 trainer.py: 950: Estimated time remaining: 00d 00h 21m\n",
      "INFO 2025-05-06 12:27:22,002 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:27:22,002 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.391752350330353, 'Losses/train_all_loss_mask': 0.012452663970907451, 'Losses/train_all_loss_dice': 7.123035705089569, 'Losses/train_all_loss_iou': 0.019647458105100667, 'Losses/train_all_loss_class': 1.5798593115334824e-05, 'Losses/train_all_core_loss': 7.391752350330353, 'Trainer/where': 0.41950000000000004, 'Trainer/epoch': 20, 'Trainer/steps_train': 840}\n",
      "INFO 2025-05-06 12:27:38,088 train_utils.py: 271: Train Epoch: [21][ 0/40] | Batch Time: 11.74 (11.74) | Data Time: 10.51 (10.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 5.07e+00 (5.07e+00)\n",
      "INFO 2025-05-06 12:27:46,269 train_utils.py: 271: Train Epoch: [21][10/40] | Batch Time: 0.82 (1.81) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 4.00e+00 (6.92e+00)\n",
      "INFO 2025-05-06 12:27:54,492 train_utils.py: 271: Train Epoch: [21][20/40] | Batch Time: 0.84 (1.34) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 5.30e+00 (7.00e+00)\n",
      "INFO 2025-05-06 12:28:02,675 train_utils.py: 271: Train Epoch: [21][30/40] | Batch Time: 0.83 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 7.64e+00 (7.13e+00)\n",
      "INFO 2025-05-06 12:28:10,737 trainer.py: 950: Estimated time remaining: 00d 00h 20m\n",
      "INFO 2025-05-06 12:28:10,738 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:28:10,738 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.177791810035705, 'Losses/train_all_loss_mask': 0.009154371960903518, 'Losses/train_all_loss_dice': 6.968333232402801, 'Losses/train_all_loss_iou': 0.026313867678800305, 'Losses/train_all_loss_class': 5.726331205799795e-05, 'Losses/train_all_core_loss': 7.177791810035705, 'Trainer/where': 0.4395, 'Trainer/epoch': 21, 'Trainer/steps_train': 880}\n",
      "INFO 2025-05-06 12:28:26,063 train_utils.py: 271: Train Epoch: [22][ 0/40] | Batch Time: 11.82 (11.82) | Data Time: 10.55 (10.55) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 8.01e+00 (8.01e+00)\n",
      "INFO 2025-05-06 12:28:34,649 train_utils.py: 271: Train Epoch: [22][10/40] | Batch Time: 0.80 (1.85) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 5.34e+00 (7.37e+00)\n",
      "INFO 2025-05-06 12:28:42,511 train_utils.py: 271: Train Epoch: [22][20/40] | Batch Time: 0.79 (1.35) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 8.08e+00 (7.38e+00)\n",
      "INFO 2025-05-06 12:28:50,510 train_utils.py: 271: Train Epoch: [22][30/40] | Batch Time: 0.80 (1.17) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 7.90e+00 (7.39e+00)\n",
      "INFO 2025-05-06 12:28:58,446 trainer.py: 950: Estimated time remaining: 00d 00h 19m\n",
      "INFO 2025-05-06 12:28:58,447 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:28:58,447 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.315818053483963, 'Losses/train_all_loss_mask': 0.011092442498193123, 'Losses/train_all_loss_dice': 7.073425376415253, 'Losses/train_all_loss_iou': 0.020538441427561338, 'Losses/train_all_loss_class': 5.435138745468748e-06, 'Losses/train_all_core_loss': 7.315818053483963, 'Trainer/where': 0.4595, 'Trainer/epoch': 22, 'Trainer/steps_train': 920}\n",
      "INFO 2025-05-06 12:29:13,342 train_utils.py: 271: Train Epoch: [23][ 0/40] | Batch Time: 11.87 (11.87) | Data Time: 10.86 (10.86) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 5.36e+00 (5.36e+00)\n",
      "INFO 2025-05-06 12:29:21,408 train_utils.py: 271: Train Epoch: [23][10/40] | Batch Time: 0.79 (1.81) | Data Time: 0.00 (0.99) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 8.33e+00 (7.46e+00)\n",
      "INFO 2025-05-06 12:29:29,264 train_utils.py: 271: Train Epoch: [23][20/40] | Batch Time: 0.77 (1.32) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 8.38e+00 (7.58e+00)\n",
      "INFO 2025-05-06 12:29:37,195 train_utils.py: 271: Train Epoch: [23][30/40] | Batch Time: 0.80 (1.15) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 7.89e+00 (7.28e+00)\n",
      "INFO 2025-05-06 12:29:45,261 trainer.py: 950: Estimated time remaining: 00d 00h 18m\n",
      "INFO 2025-05-06 12:29:45,261 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:29:45,261 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.315509259700775, 'Losses/train_all_loss_mask': 0.014455714634095784, 'Losses/train_all_loss_dice': 6.982262921333313, 'Losses/train_all_loss_iou': 0.04412425321024784, 'Losses/train_all_loss_class': 7.82120185132129e-06, 'Losses/train_all_core_loss': 7.315509259700775, 'Trainer/where': 0.47950000000000004, 'Trainer/epoch': 23, 'Trainer/steps_train': 960}\n",
      "INFO 2025-05-06 12:30:00,133 train_utils.py: 271: Train Epoch: [24][ 0/40] | Batch Time: 11.79 (11.79) | Data Time: 10.70 (10.70) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.95e+00 (7.95e+00)\n",
      "INFO 2025-05-06 12:30:07,805 train_utils.py: 271: Train Epoch: [24][10/40] | Batch Time: 0.73 (1.77) | Data Time: 0.00 (0.97) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 8.06e+00 (7.24e+00)\n",
      "INFO 2025-05-06 12:30:15,490 train_utils.py: 271: Train Epoch: [24][20/40] | Batch Time: 0.78 (1.29) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.43e+00 (7.02e+00)\n",
      "INFO 2025-05-06 12:30:23,067 train_utils.py: 271: Train Epoch: [24][30/40] | Batch Time: 0.74 (1.12) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.96e+00 (7.10e+00)\n",
      "INFO 2025-05-06 12:30:30,758 trainer.py: 950: Estimated time remaining: 00d 00h 17m\n",
      "INFO 2025-05-06 12:30:30,759 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:30:30,759 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.26828578710556, 'Losses/train_all_loss_mask': 0.012859936775930692, 'Losses/train_all_loss_dice': 6.936239397525787, 'Losses/train_all_loss_iou': 0.07483694637048757, 'Losses/train_all_loss_class': 1.0758131455013142e-05, 'Losses/train_all_core_loss': 7.26828578710556, 'Trainer/where': 0.49950000000000006, 'Trainer/epoch': 24, 'Trainer/steps_train': 1000}\n",
      "INFO 2025-05-06 12:30:44,328 train_utils.py: 271: Train Epoch: [25][ 0/40] | Batch Time: 11.15 (11.15) | Data Time: 10.16 (10.16) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 7.92e+00 (7.92e+00)\n",
      "INFO 2025-05-06 12:30:51,944 train_utils.py: 271: Train Epoch: [25][10/40] | Batch Time: 0.72 (1.71) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.91e+00 (7.58e+00)\n",
      "INFO 2025-05-06 12:30:59,497 train_utils.py: 271: Train Epoch: [25][20/40] | Batch Time: 0.78 (1.25) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.49e+00 (7.39e+00)\n",
      "INFO 2025-05-06 12:31:06,991 train_utils.py: 271: Train Epoch: [25][30/40] | Batch Time: 0.73 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 5.33e+00 (7.38e+00)\n",
      "INFO 2025-05-06 12:31:14,492 trainer.py: 950: Estimated time remaining: 00d 00h 16m\n",
      "INFO 2025-05-06 12:31:14,493 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:31:14,493 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.19477424621582, 'Losses/train_all_loss_mask': 0.0107581250849762, 'Losses/train_all_loss_dice': 6.924935805797577, 'Losses/train_all_loss_iou': 0.054663771609011744, 'Losses/train_all_loss_class': 1.2196278051845865e-05, 'Losses/train_all_core_loss': 7.19477424621582, 'Trainer/where': 0.5195000000000001, 'Trainer/epoch': 25, 'Trainer/steps_train': 1040}\n",
      "INFO 2025-05-06 12:31:27,920 train_utils.py: 271: Train Epoch: [26][ 0/40] | Batch Time: 11.11 (11.11) | Data Time: 10.12 (10.12) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.94e+00 (7.94e+00)\n",
      "INFO 2025-05-06 12:31:35,551 train_utils.py: 271: Train Epoch: [26][10/40] | Batch Time: 0.76 (1.70) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 7.93e+00 (7.21e+00)\n",
      "INFO 2025-05-06 12:31:43,008 train_utils.py: 271: Train Epoch: [26][20/40] | Batch Time: 0.72 (1.25) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 8.30e+00 (7.52e+00)\n",
      "INFO 2025-05-06 12:31:50,450 train_utils.py: 271: Train Epoch: [26][30/40] | Batch Time: 0.73 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 8.00e+00 (7.51e+00)\n",
      "INFO 2025-05-06 12:31:57,964 trainer.py: 950: Estimated time remaining: 00d 00h 15m\n",
      "INFO 2025-05-06 12:31:57,964 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:31:57,964 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.456307947635651, 'Losses/train_all_loss_mask': 0.01124967420619214, 'Losses/train_all_loss_dice': 7.211522948741913, 'Losses/train_all_loss_iou': 0.019784772159255226, 'Losses/train_all_loss_class': 6.668077377725012e-06, 'Losses/train_all_core_loss': 7.456307947635651, 'Trainer/where': 0.5395, 'Trainer/epoch': 26, 'Trainer/steps_train': 1080}\n",
      "INFO 2025-05-06 12:32:12,096 train_utils.py: 271: Train Epoch: [27][ 0/40] | Batch Time: 11.18 (11.18) | Data Time: 10.15 (10.15) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.09e+00 (7.09e+00)\n",
      "INFO 2025-05-06 12:32:19,881 train_utils.py: 271: Train Epoch: [27][10/40] | Batch Time: 0.78 (1.72) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.69e+00 (7.18e+00)\n",
      "INFO 2025-05-06 12:32:27,739 train_utils.py: 271: Train Epoch: [27][20/40] | Batch Time: 0.86 (1.28) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 7.96e+00 (6.99e+00)\n",
      "INFO 2025-05-06 12:32:35,353 train_utils.py: 271: Train Epoch: [27][30/40] | Batch Time: 0.80 (1.11) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 8.03e+00 (7.31e+00)\n",
      "INFO 2025-05-06 12:32:43,110 trainer.py: 950: Estimated time remaining: 00d 00h 15m\n",
      "INFO 2025-05-06 12:32:43,111 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:32:43,111 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.320213985443115, 'Losses/train_all_loss_mask': 0.014174740976886823, 'Losses/train_all_loss_dice': 7.002888977527618, 'Losses/train_all_loss_iou': 0.03382327603612793, 'Losses/train_all_loss_class': 6.925258599110862e-06, 'Losses/train_all_core_loss': 7.320213985443115, 'Trainer/where': 0.5595, 'Trainer/epoch': 27, 'Trainer/steps_train': 1120}\n",
      "INFO 2025-05-06 12:32:57,487 train_utils.py: 271: Train Epoch: [28][ 0/40] | Batch Time: 11.42 (11.42) | Data Time: 10.26 (10.26) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.84e+00 (7.84e+00)\n",
      "INFO 2025-05-06 12:33:05,064 train_utils.py: 271: Train Epoch: [28][10/40] | Batch Time: 0.78 (1.73) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.77e+00 (8.02e+00)\n",
      "INFO 2025-05-06 12:33:12,545 train_utils.py: 271: Train Epoch: [28][20/40] | Batch Time: 0.74 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.52e+00 (7.69e+00)\n",
      "INFO 2025-05-06 12:33:20,040 train_utils.py: 271: Train Epoch: [28][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.86e+00 (7.63e+00)\n",
      "INFO 2025-05-06 12:33:27,592 trainer.py: 950: Estimated time remaining: 00d 00h 14m\n",
      "INFO 2025-05-06 12:33:27,592 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:33:27,592 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.526504611968994, 'Losses/train_all_loss_mask': 0.013473322594654747, 'Losses/train_all_loss_dice': 7.226633656024933, 'Losses/train_all_loss_iou': 0.03040109850408044, 'Losses/train_all_loss_class': 3.421383641644127e-06, 'Losses/train_all_core_loss': 7.526504611968994, 'Trainer/where': 0.5795, 'Trainer/epoch': 28, 'Trainer/steps_train': 1160}\n",
      "INFO 2025-05-06 12:33:40,680 train_utils.py: 271: Train Epoch: [29][ 0/40] | Batch Time: 11.15 (11.15) | Data Time: 10.17 (10.17) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 7.60e+00 (7.60e+00)\n",
      "INFO 2025-05-06 12:33:48,479 train_utils.py: 271: Train Epoch: [29][10/40] | Batch Time: 0.77 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 5.74e+00 (7.07e+00)\n",
      "INFO 2025-05-06 12:33:55,848 train_utils.py: 271: Train Epoch: [29][20/40] | Batch Time: 0.76 (1.25) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.87e+00 (7.19e+00)\n",
      "INFO 2025-05-06 12:34:03,404 train_utils.py: 271: Train Epoch: [29][30/40] | Batch Time: 0.75 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.57e+00 (7.29e+00)\n",
      "INFO 2025-05-06 12:34:10,936 trainer.py: 950: Estimated time remaining: 00d 00h 13m\n",
      "INFO 2025-05-06 12:34:10,936 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:34:10,936 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.417935109138488, 'Losses/train_all_loss_mask': 0.011637375975260511, 'Losses/train_all_loss_dice': 7.150033664703369, 'Losses/train_all_loss_iou': 0.03511762805737817, 'Losses/train_all_loss_class': 3.629473661312943e-05, 'Losses/train_all_core_loss': 7.417935109138488, 'Trainer/where': 0.5995, 'Trainer/epoch': 29, 'Trainer/steps_train': 1200}\n",
      "INFO 2025-05-06 12:34:24,075 train_utils.py: 271: Train Epoch: [30][ 0/40] | Batch Time: 11.30 (11.30) | Data Time: 10.10 (10.10) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.60e+00 (7.60e+00)\n",
      "INFO 2025-05-06 12:34:31,658 train_utils.py: 271: Train Epoch: [30][10/40] | Batch Time: 0.76 (1.72) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 4.96e+00 (7.28e+00)\n",
      "INFO 2025-05-06 12:34:39,187 train_utils.py: 271: Train Epoch: [30][20/40] | Batch Time: 0.78 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 6.60e+00 (7.41e+00)\n",
      "INFO 2025-05-06 12:34:46,784 train_utils.py: 271: Train Epoch: [30][30/40] | Batch Time: 0.74 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 7.72e+00 (7.43e+00)\n",
      "INFO 2025-05-06 12:34:54,280 trainer.py: 950: Estimated time remaining: 00d 00h 12m\n",
      "INFO 2025-05-06 12:34:54,280 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:34:54,280 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.424049758911133, 'Losses/train_all_loss_mask': 0.008575243993254844, 'Losses/train_all_loss_dice': 7.237179911136627, 'Losses/train_all_loss_iou': 0.01535711917495064, 'Losses/train_all_loss_class': 7.842157911319702e-06, 'Losses/train_all_core_loss': 7.424049758911133, 'Trainer/where': 0.6195, 'Trainer/epoch': 30, 'Trainer/steps_train': 1240}\n",
      "INFO 2025-05-06 12:35:08,619 train_utils.py: 271: Train Epoch: [31][ 0/40] | Batch Time: 11.41 (11.41) | Data Time: 10.28 (10.28) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.80e+00 (7.80e+00)\n",
      "INFO 2025-05-06 12:35:16,208 train_utils.py: 271: Train Epoch: [31][10/40] | Batch Time: 0.75 (1.73) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 8.06e+00 (7.16e+00)\n",
      "INFO 2025-05-06 12:35:23,730 train_utils.py: 271: Train Epoch: [31][20/40] | Batch Time: 0.77 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.86e+00 (7.38e+00)\n",
      "INFO 2025-05-06 12:35:31,171 train_utils.py: 271: Train Epoch: [31][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 7.73e+00 (7.33e+00)\n",
      "INFO 2025-05-06 12:35:38,675 trainer.py: 950: Estimated time remaining: 00d 00h 12m\n",
      "INFO 2025-05-06 12:35:38,676 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:35:38,676 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.276989865303039, 'Losses/train_all_loss_mask': 0.005445002685155487, 'Losses/train_all_loss_dice': 7.142256504297256, 'Losses/train_all_loss_iou': 0.02582859288554573, 'Losses/train_all_loss_class': 4.704470219962786e-06, 'Losses/train_all_core_loss': 7.276989865303039, 'Trainer/where': 0.6395000000000001, 'Trainer/epoch': 31, 'Trainer/steps_train': 1280}\n",
      "INFO 2025-05-06 12:35:52,081 train_utils.py: 271: Train Epoch: [32][ 0/40] | Batch Time: 11.37 (11.37) | Data Time: 10.21 (10.21) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.77e+00 (7.77e+00)\n",
      "INFO 2025-05-06 12:35:59,609 train_utils.py: 271: Train Epoch: [32][10/40] | Batch Time: 0.73 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.65e+00 (7.05e+00)\n",
      "INFO 2025-05-06 12:36:07,149 train_utils.py: 271: Train Epoch: [32][20/40] | Batch Time: 0.77 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.82e+00 (7.12e+00)\n",
      "INFO 2025-05-06 12:36:14,662 train_utils.py: 271: Train Epoch: [32][30/40] | Batch Time: 0.75 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.77e+00 (7.16e+00)\n",
      "INFO 2025-05-06 12:36:22,146 trainer.py: 950: Estimated time remaining: 00d 00h 11m\n",
      "INFO 2025-05-06 12:36:22,146 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:36:22,147 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.264893007278443, 'Losses/train_all_loss_mask': 0.005907002903404646, 'Losses/train_all_loss_dice': 7.136012673377991, 'Losses/train_all_loss_iou': 0.010729180686303153, 'Losses/train_all_loss_class': 1.1058426187293691e-05, 'Losses/train_all_core_loss': 7.264893007278443, 'Trainer/where': 0.6595, 'Trainer/epoch': 32, 'Trainer/steps_train': 1320}\n",
      "INFO 2025-05-06 12:36:35,378 train_utils.py: 271: Train Epoch: [33][ 0/40] | Batch Time: 11.31 (11.31) | Data Time: 10.20 (10.20) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.73e+00 (7.73e+00)\n",
      "INFO 2025-05-06 12:36:42,951 train_utils.py: 271: Train Epoch: [33][10/40] | Batch Time: 0.76 (1.72) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 7.96e+00 (7.49e+00)\n",
      "INFO 2025-05-06 12:36:50,538 train_utils.py: 271: Train Epoch: [33][20/40] | Batch Time: 0.75 (1.26) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 5.31e+00 (7.45e+00)\n",
      "INFO 2025-05-06 12:36:57,975 train_utils.py: 271: Train Epoch: [33][30/40] | Batch Time: 0.72 (1.09) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 4.87e+00 (7.44e+00)\n",
      "INFO 2025-05-06 12:37:05,672 trainer.py: 950: Estimated time remaining: 00d 00h 10m\n",
      "INFO 2025-05-06 12:37:05,672 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:37:05,673 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.274829393625259, 'Losses/train_all_loss_mask': 0.012328154476563213, 'Losses/train_all_loss_dice': 7.01775324344635, 'Losses/train_all_loss_iou': 0.010503313530443847, 'Losses/train_all_loss_class': 9.646610927127598e-06, 'Losses/train_all_core_loss': 7.274829393625259, 'Trainer/where': 0.6795, 'Trainer/epoch': 33, 'Trainer/steps_train': 1360}\n",
      "INFO 2025-05-06 12:37:19,056 train_utils.py: 271: Train Epoch: [34][ 0/40] | Batch Time: 11.17 (11.17) | Data Time: 10.12 (10.12) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.48e+00 (7.48e+00)\n",
      "INFO 2025-05-06 12:37:26,730 train_utils.py: 271: Train Epoch: [34][10/40] | Batch Time: 0.76 (1.71) | Data Time: 0.00 (0.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 5.26e+00 (7.24e+00)\n",
      "INFO 2025-05-06 12:37:34,285 train_utils.py: 271: Train Epoch: [34][20/40] | Batch Time: 0.76 (1.26) | Data Time: 0.00 (0.48) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.92e+00 (7.41e+00)\n",
      "INFO 2025-05-06 12:37:41,945 train_utils.py: 271: Train Epoch: [34][30/40] | Batch Time: 0.77 (1.10) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 26m | Losses/train_all_loss: 7.28e+00 (7.33e+00)\n",
      "INFO 2025-05-06 12:37:49,605 trainer.py: 950: Estimated time remaining: 00d 00h 10m\n",
      "INFO 2025-05-06 12:37:49,606 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:37:49,606 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.364873516559601, 'Losses/train_all_loss_mask': 0.012314582762337522, 'Losses/train_all_loss_dice': 7.0796364665031435, 'Losses/train_all_loss_iou': 0.038926952126075776, 'Losses/train_all_loss_class': 1.8400740428603514e-05, 'Losses/train_all_core_loss': 7.364873516559601, 'Trainer/where': 0.6995, 'Trainer/epoch': 34, 'Trainer/steps_train': 1400}\n",
      "INFO 2025-05-06 12:38:03,349 train_utils.py: 271: Train Epoch: [35][ 0/40] | Batch Time: 11.16 (11.16) | Data Time: 10.22 (10.22) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 8.80e+00 (8.80e+00)\n",
      "INFO 2025-05-06 12:38:10,863 train_utils.py: 271: Train Epoch: [35][10/40] | Batch Time: 0.72 (1.70) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 6.80e+00 (7.13e+00)\n",
      "INFO 2025-05-06 12:38:18,362 train_utils.py: 271: Train Epoch: [35][20/40] | Batch Time: 0.75 (1.25) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.20e+00 (7.17e+00)\n",
      "INFO 2025-05-06 12:38:25,823 train_utils.py: 271: Train Epoch: [35][30/40] | Batch Time: 0.76 (1.08) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.64e+00 (7.25e+00)\n",
      "INFO 2025-05-06 12:38:33,394 trainer.py: 950: Estimated time remaining: 00d 00h 09m\n",
      "INFO 2025-05-06 12:38:33,394 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:38:33,394 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.280297029018402, 'Losses/train_all_loss_mask': 0.007986364199314266, 'Losses/train_all_loss_dice': 7.1110015392303465, 'Losses/train_all_loss_iou': 0.009562968209866084, 'Losses/train_all_loss_class': 5.293044671361713e-06, 'Losses/train_all_core_loss': 7.280297029018402, 'Trainer/where': 0.7195, 'Trainer/epoch': 35, 'Trainer/steps_train': 1440}\n",
      "INFO 2025-05-06 12:38:48,572 train_utils.py: 271: Train Epoch: [36][ 0/40] | Batch Time: 11.53 (11.53) | Data Time: 10.53 (10.53) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 7.85e+00 (7.85e+00)\n",
      "INFO 2025-05-06 12:38:56,545 train_utils.py: 271: Train Epoch: [36][10/40] | Batch Time: 0.72 (1.77) | Data Time: 0.00 (0.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.97e+00 (7.98e+00)\n",
      "INFO 2025-05-06 12:39:04,171 train_utils.py: 271: Train Epoch: [36][20/40] | Batch Time: 0.73 (1.29) | Data Time: 0.00 (0.50) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.91e+00 (7.72e+00)\n",
      "INFO 2025-05-06 12:39:11,457 train_utils.py: 271: Train Epoch: [36][30/40] | Batch Time: 0.70 (1.11) | Data Time: 0.00 (0.34) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.77e+00 (7.48e+00)\n",
      "INFO 2025-05-06 12:39:18,889 trainer.py: 950: Estimated time remaining: 00d 00h 08m\n",
      "INFO 2025-05-06 12:39:18,889 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:39:18,890 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.555176150798798, 'Losses/train_all_loss_mask': 0.01288242990267463, 'Losses/train_all_loss_dice': 7.274849772453308, 'Losses/train_all_loss_iou': 0.022634643933452027, 'Losses/train_all_loss_class': 4.3146945482774866e-05, 'Losses/train_all_core_loss': 7.555176150798798, 'Trainer/where': 0.7395, 'Trainer/epoch': 36, 'Trainer/steps_train': 1480}\n",
      "INFO 2025-05-06 12:39:33,124 train_utils.py: 271: Train Epoch: [37][ 0/40] | Batch Time: 11.19 (11.19) | Data Time: 10.19 (10.19) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.65e+00 (6.65e+00)\n",
      "INFO 2025-05-06 12:39:40,443 train_utils.py: 271: Train Epoch: [37][10/40] | Batch Time: 0.73 (1.68) | Data Time: 0.00 (0.93) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 6.67e+00 (7.19e+00)\n",
      "INFO 2025-05-06 12:39:47,644 train_utils.py: 271: Train Epoch: [37][20/40] | Batch Time: 0.71 (1.22) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 28m | Losses/train_all_loss: 7.95e+00 (7.19e+00)\n",
      "INFO 2025-05-06 12:39:54,717 train_utils.py: 271: Train Epoch: [37][30/40] | Batch Time: 0.69 (1.06) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.44e+00 (7.28e+00)\n",
      "INFO 2025-05-06 12:40:02,029 trainer.py: 950: Estimated time remaining: 00d 00h 07m\n",
      "INFO 2025-05-06 12:40:02,030 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:40:02,030 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.376134437322617, 'Losses/train_all_loss_mask': 0.010417016674546175, 'Losses/train_all_loss_dice': 7.143240231275558, 'Losses/train_all_loss_iou': 0.024540197888381955, 'Losses/train_all_loss_class': 1.3603407724716021e-05, 'Losses/train_all_core_loss': 7.376134437322617, 'Trainer/where': 0.7595000000000001, 'Trainer/epoch': 37, 'Trainer/steps_train': 1520}\n",
      "INFO 2025-05-06 12:40:16,121 train_utils.py: 271: Train Epoch: [38][ 0/40] | Batch Time: 11.07 (11.07) | Data Time: 9.95 (9.95) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 8.08e+00 (8.08e+00)\n",
      "INFO 2025-05-06 12:40:23,350 train_utils.py: 271: Train Epoch: [38][10/40] | Batch Time: 0.72 (1.66) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.92e+00 (7.81e+00)\n",
      "INFO 2025-05-06 12:40:30,519 train_utils.py: 271: Train Epoch: [38][20/40] | Batch Time: 0.68 (1.21) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.94e+00 (7.48e+00)\n",
      "INFO 2025-05-06 12:40:37,622 train_utils.py: 271: Train Epoch: [38][30/40] | Batch Time: 0.69 (1.05) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 7.58e+00 (7.51e+00)\n",
      "INFO 2025-05-06 12:40:44,734 trainer.py: 950: Estimated time remaining: 00d 00h 07m\n",
      "INFO 2025-05-06 12:40:44,734 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:40:44,734 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.470002073049545, 'Losses/train_all_loss_mask': 0.011916998600645457, 'Losses/train_all_loss_dice': 7.211084812879562, 'Losses/train_all_loss_iou': 0.020568156977424222, 'Losses/train_all_loss_class': 9.049650366677042e-06, 'Losses/train_all_core_loss': 7.470002073049545, 'Trainer/where': 0.7795000000000001, 'Trainer/epoch': 38, 'Trainer/steps_train': 1560}\n",
      "INFO 2025-05-06 12:40:58,444 train_utils.py: 271: Train Epoch: [39][ 0/40] | Batch Time: 10.90 (10.90) | Data Time: 9.92 (9.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 6.92e+00 (6.92e+00)\n",
      "INFO 2025-05-06 12:41:05,656 train_utils.py: 271: Train Epoch: [39][10/40] | Batch Time: 0.70 (1.65) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 8.06e+00 (7.36e+00)\n",
      "INFO 2025-05-06 12:41:12,751 train_utils.py: 271: Train Epoch: [39][20/40] | Batch Time: 0.74 (1.20) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.85e+00 (7.49e+00)\n",
      "INFO 2025-05-06 12:41:19,910 train_utils.py: 271: Train Epoch: [39][30/40] | Batch Time: 0.74 (1.04) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.08e+00 (7.21e+00)\n",
      "INFO 2025-05-06 12:41:27,177 trainer.py: 950: Estimated time remaining: 00d 00h 06m\n",
      "INFO 2025-05-06 12:41:27,179 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:41:27,179 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.388305974006653, 'Losses/train_all_loss_mask': 0.010740681507741101, 'Losses/train_all_loss_dice': 7.151839554309845, 'Losses/train_all_loss_iou': 0.021648986059881282, 'Losses/train_all_loss_class': 3.7947830598739073e-06, 'Losses/train_all_core_loss': 7.388305974006653, 'Trainer/where': 0.7995, 'Trainer/epoch': 39, 'Trainer/steps_train': 1600}\n",
      "INFO 2025-05-06 12:41:41,374 train_utils.py: 271: Train Epoch: [40][ 0/40] | Batch Time: 11.54 (11.54) | Data Time: 10.35 (10.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 7.21e+00 (7.21e+00)\n",
      "INFO 2025-05-06 12:41:49,342 train_utils.py: 271: Train Epoch: [40][10/40] | Batch Time: 0.81 (1.77) | Data Time: 0.00 (0.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 7.76e+00 (7.30e+00)\n",
      "INFO 2025-05-06 12:41:57,857 train_utils.py: 271: Train Epoch: [40][20/40] | Batch Time: 0.92 (1.33) | Data Time: 0.00 (0.49) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 7.46e+00 (7.34e+00)\n",
      "INFO 2025-05-06 12:42:06,219 train_utils.py: 271: Train Epoch: [40][30/40] | Batch Time: 0.92 (1.17) | Data Time: 0.00 (0.33) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 4.87e+00 (7.36e+00)\n",
      "INFO 2025-05-06 12:42:15,163 trainer.py: 950: Estimated time remaining: 00d 00h 06m\n",
      "INFO 2025-05-06 12:42:15,164 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:42:15,164 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.396766662597656, 'Losses/train_all_loss_mask': 0.007179220429679845, 'Losses/train_all_loss_dice': 7.233652210235595, 'Losses/train_all_loss_iou': 0.019517217456177606, 'Losses/train_all_loss_class': 1.2794001144555977e-05, 'Losses/train_all_core_loss': 7.396766662597656, 'Trainer/where': 0.8195, 'Trainer/epoch': 40, 'Trainer/steps_train': 1640}\n",
      "INFO 2025-05-06 12:42:35,136 train_utils.py: 271: Train Epoch: [41][ 0/40] | Batch Time: 15.64 (15.64) | Data Time: 14.54 (14.54) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 8.01e+00 (8.01e+00)\n",
      "INFO 2025-05-06 12:42:43,530 train_utils.py: 271: Train Epoch: [41][10/40] | Batch Time: 0.82 (2.18) | Data Time: 0.00 (1.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 8.01e+00 (7.51e+00)\n",
      "INFO 2025-05-06 12:42:51,925 train_utils.py: 271: Train Epoch: [41][20/40] | Batch Time: 0.91 (1.54) | Data Time: 0.00 (0.69) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.92e+00 (7.40e+00)\n",
      "INFO 2025-05-06 12:43:00,348 train_utils.py: 271: Train Epoch: [41][30/40] | Batch Time: 0.85 (1.32) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 5.30e+00 (7.23e+00)\n",
      "INFO 2025-05-06 12:43:09,392 trainer.py: 950: Estimated time remaining: 00d 00h 06m\n",
      "INFO 2025-05-06 12:43:09,392 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:43:09,393 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.2961758852005, 'Losses/train_all_loss_mask': 0.009207852588588139, 'Losses/train_all_loss_dice': 7.088075745105743, 'Losses/train_all_loss_iou': 0.023938872406597513, 'Losses/train_all_loss_class': 4.232779541979426e-06, 'Losses/train_all_core_loss': 7.2961758852005, 'Trainer/where': 0.8395, 'Trainer/epoch': 41, 'Trainer/steps_train': 1680}\n",
      "INFO 2025-05-06 12:43:28,115 train_utils.py: 271: Train Epoch: [42][ 0/40] | Batch Time: 15.35 (15.35) | Data Time: 14.24 (14.24) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 7.96e+00 (7.96e+00)\n",
      "INFO 2025-05-06 12:43:36,289 train_utils.py: 271: Train Epoch: [42][10/40] | Batch Time: 0.84 (2.14) | Data Time: 0.00 (1.30) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 8.03e+00 (7.01e+00)\n",
      "INFO 2025-05-06 12:43:44,491 train_utils.py: 271: Train Epoch: [42][20/40] | Batch Time: 0.83 (1.51) | Data Time: 0.00 (0.68) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 6.66e+00 (7.22e+00)\n",
      "INFO 2025-05-06 12:43:52,708 train_utils.py: 271: Train Epoch: [42][30/40] | Batch Time: 0.82 (1.29) | Data Time: 0.00 (0.46) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.16e+00 (7.26e+00)\n",
      "INFO 2025-05-06 12:44:01,717 trainer.py: 950: Estimated time remaining: 00d 00h 05m\n",
      "INFO 2025-05-06 12:44:01,718 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:44:01,718 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.185935652256012, 'Losses/train_all_loss_mask': 0.010560710517165717, 'Losses/train_all_loss_dice': 6.972957330942154, 'Losses/train_all_loss_iou': 0.0017560172489538672, 'Losses/train_all_loss_class': 8.079020137508053e-06, 'Losses/train_all_core_loss': 7.185935652256012, 'Trainer/where': 0.8595, 'Trainer/epoch': 42, 'Trainer/steps_train': 1720}\n",
      "INFO 2025-05-06 12:44:22,965 train_utils.py: 271: Train Epoch: [43][ 0/40] | Batch Time: 17.12 (17.12) | Data Time: 15.94 (15.94) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 4.52e+00 (4.52e+00)\n",
      "INFO 2025-05-06 12:44:31,092 train_utils.py: 271: Train Epoch: [43][10/40] | Batch Time: 0.83 (2.30) | Data Time: 0.00 (1.45) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.97e+00 (6.57e+00)\n",
      "INFO 2025-05-06 12:44:39,482 train_utils.py: 271: Train Epoch: [43][20/40] | Batch Time: 0.76 (1.60) | Data Time: 0.00 (0.76) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.08e+00 (7.10e+00)\n",
      "INFO 2025-05-06 12:44:46,814 train_utils.py: 271: Train Epoch: [43][30/40] | Batch Time: 0.74 (1.32) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 7.94e+00 (7.28e+00)\n",
      "INFO 2025-05-06 12:44:54,849 trainer.py: 950: Estimated time remaining: 00d 00h 04m\n",
      "INFO 2025-05-06 12:44:54,849 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:44:54,850 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.396651554107666, 'Losses/train_all_loss_mask': 0.008120661620341706, 'Losses/train_all_loss_dice': 7.225486719608307, 'Losses/train_all_loss_iou': 0.00874031905987067, 'Losses/train_all_loss_class': 1.1299404575737527e-05, 'Losses/train_all_core_loss': 7.396651554107666, 'Trainer/where': 0.8795000000000001, 'Trainer/epoch': 43, 'Trainer/steps_train': 1760}\n",
      "INFO 2025-05-06 12:45:13,398 train_utils.py: 271: Train Epoch: [44][ 0/40] | Batch Time: 14.39 (14.39) | Data Time: 13.31 (13.31) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.69e+00 (7.69e+00)\n",
      "INFO 2025-05-06 12:45:20,825 train_utils.py: 271: Train Epoch: [44][10/40] | Batch Time: 0.73 (1.98) | Data Time: 0.00 (1.21) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.93e+00 (7.56e+00)\n",
      "INFO 2025-05-06 12:45:28,102 train_utils.py: 271: Train Epoch: [44][20/40] | Batch Time: 0.72 (1.39) | Data Time: 0.00 (0.63) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 7.92e+00 (7.46e+00)\n",
      "INFO 2025-05-06 12:45:35,377 train_utils.py: 271: Train Epoch: [44][30/40] | Batch Time: 0.69 (1.17) | Data Time: 0.00 (0.43) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 8.02e+00 (7.50e+00)\n",
      "INFO 2025-05-06 12:45:43,406 trainer.py: 950: Estimated time remaining: 00d 00h 03m\n",
      "INFO 2025-05-06 12:45:43,407 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:45:43,407 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.375905299186707, 'Losses/train_all_loss_mask': 0.014356273831799627, 'Losses/train_all_loss_dice': 7.030859804153442, 'Losses/train_all_loss_iou': 0.05791444253891313, 'Losses/train_all_loss_class': 5.6345127084966865e-06, 'Losses/train_all_core_loss': 7.375905299186707, 'Trainer/where': 0.8995000000000001, 'Trainer/epoch': 44, 'Trainer/steps_train': 1800}\n",
      "INFO 2025-05-06 12:46:01,867 train_utils.py: 271: Train Epoch: [45][ 0/40] | Batch Time: 14.94 (14.94) | Data Time: 13.89 (13.89) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 8.03e+00 (8.03e+00)\n",
      "INFO 2025-05-06 12:46:09,316 train_utils.py: 271: Train Epoch: [45][10/40] | Batch Time: 0.73 (2.04) | Data Time: 0.00 (1.26) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 7.95e+00 (7.17e+00)\n",
      "INFO 2025-05-06 12:46:16,749 train_utils.py: 271: Train Epoch: [45][20/40] | Batch Time: 0.72 (1.42) | Data Time: 0.00 (0.66) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 4.78e+00 (7.02e+00)\n",
      "INFO 2025-05-06 12:46:23,913 train_utils.py: 271: Train Epoch: [45][30/40] | Batch Time: 0.71 (1.19) | Data Time: 0.00 (0.45) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 7.92e+00 (7.08e+00)\n",
      "INFO 2025-05-06 12:46:31,770 trainer.py: 950: Estimated time remaining: 00d 00h 02m\n",
      "INFO 2025-05-06 12:46:31,771 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:46:31,771 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.128007864952087, 'Losses/train_all_loss_mask': 0.008849016736348858, 'Losses/train_all_loss_dice': 6.9343440473079685, 'Losses/train_all_loss_iou': 0.016678811999554455, 'Losses/train_all_loss_class': 4.6443563348930185e-06, 'Losses/train_all_core_loss': 7.128007864952087, 'Trainer/where': 0.9195, 'Trainer/epoch': 45, 'Trainer/steps_train': 1840}\n",
      "INFO 2025-05-06 12:46:47,836 train_utils.py: 271: Train Epoch: [46][ 0/40] | Batch Time: 13.22 (13.22) | Data Time: 12.13 (12.13) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 5.31e+00 (5.31e+00)\n",
      "INFO 2025-05-06 12:46:55,281 train_utils.py: 271: Train Epoch: [46][10/40] | Batch Time: 0.73 (1.88) | Data Time: 0.00 (1.10) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.92e+00 (7.24e+00)\n",
      "INFO 2025-05-06 12:47:02,384 train_utils.py: 271: Train Epoch: [46][20/40] | Batch Time: 0.69 (1.32) | Data Time: 0.00 (0.58) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.94e+00 (7.18e+00)\n",
      "INFO 2025-05-06 12:47:09,594 train_utils.py: 271: Train Epoch: [46][30/40] | Batch Time: 0.69 (1.13) | Data Time: 0.00 (0.39) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 8.96e+00 (7.09e+00)\n",
      "INFO 2025-05-06 12:47:16,833 trainer.py: 950: Estimated time remaining: 00d 00h 02m\n",
      "INFO 2025-05-06 12:47:16,833 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:47:16,833 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.100126564502716, 'Losses/train_all_loss_mask': 0.01252208777004853, 'Losses/train_all_loss_dice': 6.814909541606903, 'Losses/train_all_loss_iou': 0.034760635161546816, 'Losses/train_all_loss_class': 1.46248140863392e-05, 'Losses/train_all_core_loss': 7.100126564502716, 'Trainer/where': 0.9395, 'Trainer/epoch': 46, 'Trainer/steps_train': 1880}\n",
      "INFO 2025-05-06 12:47:29,940 train_utils.py: 271: Train Epoch: [47][ 0/40] | Batch Time: 11.02 (11.02) | Data Time: 9.92 (9.92) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.82e+00 (7.82e+00)\n",
      "INFO 2025-05-06 12:47:37,088 train_utils.py: 271: Train Epoch: [47][10/40] | Batch Time: 0.72 (1.65) | Data Time: 0.00 (0.90) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 8.00e+00 (7.63e+00)\n",
      "INFO 2025-05-06 12:47:44,361 train_utils.py: 271: Train Epoch: [47][20/40] | Batch Time: 0.76 (1.21) | Data Time: 0.00 (0.47) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 7.91e+00 (7.53e+00)\n",
      "INFO 2025-05-06 12:47:52,053 train_utils.py: 271: Train Epoch: [47][30/40] | Batch Time: 0.75 (1.07) | Data Time: 0.00 (0.32) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 5.70e+00 (7.61e+00)\n",
      "INFO 2025-05-06 12:47:59,667 trainer.py: 950: Estimated time remaining: 00d 00h 01m\n",
      "INFO 2025-05-06 12:47:59,667 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:47:59,667 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.5116276979446415, 'Losses/train_all_loss_mask': 0.010245646073599346, 'Losses/train_all_loss_dice': 7.27198293209076, 'Losses/train_all_loss_iou': 0.03255526575649128, 'Losses/train_all_loss_class': 0.00217662357365036, 'Losses/train_all_core_loss': 7.5116276979446415, 'Trainer/where': 0.9595, 'Trainer/epoch': 47, 'Trainer/steps_train': 1920}\n",
      "INFO 2025-05-06 12:48:14,241 train_utils.py: 271: Train Epoch: [48][ 0/40] | Batch Time: 12.02 (12.02) | Data Time: 10.96 (10.96) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 7.59e+00 (7.59e+00)\n",
      "INFO 2025-05-06 12:48:21,862 train_utils.py: 271: Train Epoch: [48][10/40] | Batch Time: 0.77 (1.79) | Data Time: 0.00 (1.00) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 8.00e+00 (7.65e+00)\n",
      "INFO 2025-05-06 12:48:29,273 train_utils.py: 271: Train Epoch: [48][20/40] | Batch Time: 0.76 (1.29) | Data Time: 0.00 (0.52) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 7.79e+00 (7.70e+00)\n",
      "INFO 2025-05-06 12:48:37,040 train_utils.py: 271: Train Epoch: [48][30/40] | Batch Time: 0.83 (1.12) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 4.65e+00 (7.23e+00)\n",
      "INFO 2025-05-06 12:48:45,510 trainer.py: 950: Estimated time remaining: 00d 00h 00m\n",
      "INFO 2025-05-06 12:48:45,511 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:48:45,511 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.180913537740707, 'Losses/train_all_loss_mask': 0.012643473758726032, 'Losses/train_all_loss_dice': 6.894251072406769, 'Losses/train_all_loss_iou': 0.033784508199505583, 'Losses/train_all_loss_class': 8.503132722381679e-06, 'Losses/train_all_core_loss': 7.180913537740707, 'Trainer/where': 0.9795, 'Trainer/epoch': 48, 'Trainer/steps_train': 1960}\n",
      "INFO 2025-05-06 12:49:00,727 train_utils.py: 271: Train Epoch: [49][ 0/40] | Batch Time: 11.97 (11.97) | Data Time: 10.77 (10.77) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 8.04e+00 (8.04e+00)\n",
      "INFO 2025-05-06 12:49:08,476 train_utils.py: 271: Train Epoch: [49][10/40] | Batch Time: 0.75 (1.79) | Data Time: 0.00 (0.98) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 7.33e+00 (7.56e+00)\n",
      "INFO 2025-05-06 12:49:15,794 train_utils.py: 271: Train Epoch: [49][20/40] | Batch Time: 0.73 (1.29) | Data Time: 0.00 (0.51) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 7.15e+00 (7.15e+00)\n",
      "INFO 2025-05-06 12:49:23,023 train_utils.py: 271: Train Epoch: [49][30/40] | Batch Time: 0.70 (1.11) | Data Time: 0.00 (0.35) | Mem (GB): 7.00 (7.00/7.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 5.31e+00 (6.96e+00)\n",
      "INFO 2025-05-06 12:49:30,273 trainer.py: 950: Estimated time remaining: 00d 00h 00m\n",
      "INFO 2025-05-06 12:49:30,274 trainer.py: 892: Synchronizing meters\n",
      "INFO 2025-05-06 12:49:30,274 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 7.011944925785064, 'Losses/train_all_loss_mask': 0.007334709151473362, 'Losses/train_all_loss_dice': 6.847940272092819, 'Losses/train_all_loss_iou': 0.01729844883830083, 'Losses/train_all_loss_class': 1.2049677670233904e-05, 'Losses/train_all_core_loss': 7.011944925785064, 'Trainer/where': 0.9995, 'Trainer/epoch': 49, 'Trainer/steps_train': 2000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Micha\\Desktop\\BachelorProject\\AI-Powered-Biosensing\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [64, 256, 1, 1], strides() = [256, 1, 256, 256]\n",
      "bucket_view.sizes() = [64, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\distributed\\c10d\\reducer.cpp:342.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n",
      "WARNING:root:Skip RandomAffine for zero-area mask in first frame after 1 tentatives\n"
     ]
    }
   ],
   "source": [
    "!cd ../sam2/training && python train.py -c configs/sam2.1_training/train_b+_base.yaml --use-cluster 0 --num-nodes 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ../sam2/training/logs --bind_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
